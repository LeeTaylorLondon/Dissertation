A monomolecular, first order reversible reaction which is close to equilibrium can be visualized by the following symbolic structure:
The displacement will then be of the form y(t)=Ae−t/Tcos⁡(μt−δ){\displaystyle y(t)=Ae^{-t/T}\cos(\mu t-\delta )}. The constant T (=2m/γ{\displaystyle =2m/\gamma }) is called the relaxation time of the system and the constant μ is the quasi-frequency.
If we say that at t=0,[A](t)=[A]0{\displaystyle t=0,{\ce {[A]}}(t)={\ce {[A]}}_{0}}, and applying the law of conservation of mass, we can say that at any time, the sum of the concentrations of A and B must be equal to the concentration of A0{\displaystyle A_{0}}, assuming the volume into which A and B are dissolved does not change:
3Chemical relaxation methods											Toggle Chemical relaxation methods subsection																					3.1Monomolecular first-order reversible reaction
Rogers, R.R.; Yau, M.K. (1989). A Short Course in Cloud Physics. International Series in Natural Philosophy. Vol. 113 (3rd ed.). Elsevier Science. ISBN 0750632151.
Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Relaxation" physics – news · newspapers · books · scholar · JSTOR
In an RC circuit containing a charged capacitor and a resistor, the voltage decays exponentially:
N = concentration (of ice crystals or water droplets) [m−3]
In the physical sciences, relaxation usually means the return of a perturbed system into equilibrium.Each relaxation process can be categorized by a relaxation time τ. The simplest theoretical description of relaxation as function of time t is an exponential law exp(−t/τ) (exponential decay).
Suppose that the test star has velocity v. As the star moves along its orbit, its motion will be randomly perturbed by the gravitational field of nearby stars. The relaxation time can be shown to be [4]
Therefore, d[A]dt=−k[A]+k′[B]{\displaystyle {d{\ce {[A]}} \over dt}=-k{\ce {[A]}}+k'{\ce {[B]}}}, where brackets around A and B indicate concentrations.
In ice clouds the concentrations are lower (just a few per liter) and the temperatures are colder (very high supersaturation rates) and so the relaxation times can be as long as several hours. Relaxation time is given as
^ Kittel, Rep. Prog. Phys. 1947; Hall, Phys. Rev. 1948; Wintner Phys. Rev. 1948.
Atkins P. and de Paula J. Atkins' Physical Chemistry (8th ed., W.H.Freeman 2006) p.805-7, .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}ISBN 0-7167-8759-8
^ Spitzer, Lyman (1987). Dynamical evolution of globular clusters. Princeton, NJ: Princeton University Press. p. 191. ISBN 0691083096.
In condensed matter physics, relaxation is usually studied as a linear response to a small external perturbation. Since the underlying microscopic processes are active even in the absence of external perturbations, one can also study "relaxation in equilibrium" instead of the usual "relaxation into equilibrium" (see fluctuation-dissipation theorem).
^ Rogers, R.R.; Yau, M.K. (1989). A Short Course in Cloud Physics. International Series in Natural Philosophy. Vol. 113 (3rd ed.). Elsevier Science. ISBN 0750632151.
In nuclear magnetic resonance (NMR), various relaxations are the properties that it measures.
In astronomy, relaxation time relates to clusters of gravitationally interacting bodies, for instance, stars in a galaxy. The relaxation time is a measure of the time it takes for one object in the system (the "test star") to be significantly perturbed by other objects in the system (the "field stars"). It is most commonly defined as the time for the test star's velocity to change by of order itself.
Spitzer, Lyman (1987). Dynamical evolution of globular clusters. Princeton, NJ: Princeton University Press. p. 191. ISBN 0691083096.
Tr=0.34σ3G2mρln⁡Λ≈0.95×1010(σ200kms−1)3(ρ106M⊙pc−3)−1(m⋆M⊙)−1(ln⁡Λ15)−1yr{\displaystyle {\begin{aligned}T_{r}&={0.34\sigma ^{3} \over G^{2}m\rho \ln \Lambda }\\&\approx 0.95\times 10^{10}\!\left({\sigma\over 200\,\mathrm {km\,s} ^{-1}}\right)^{\!3}\!\!\left({\rho\over 10^{6}\,M_{\odot }\,\mathrm {pc} ^{-3}}\right)^{\!-1}\!\!\left({m_{\star } \over M_{\odot }}\right)^{\!-1}\!\!\left({\ln \Lambda\over 15}\right)^{\!-1}\!\mathrm {yr} \end{aligned}}}
Kittel, Rep. Prog. Phys. 1947; Hall, Phys. Rev. 1948; Wintner Phys. Rev. 1948.
1In simple linear systems											Toggle In simple linear systems subsection																					1.1Mechanics: Damped unforced oscillator																											1.2Electronics: RC circuit
In continuum mechanics, stress relaxation is the gradual disappearance of stresses from a viscoelastic medium after it has been deformed.
In water clouds where the concentrations are larger (hundreds per cm3) and the temperatures are warmer (thus allowing for much lower supersaturation rates as compared to ice clouds), the relaxation times will be very low (seconds to minutes).[3]
2In condensed matter physics											Toggle In condensed matter physics subsection																					2.1Stress relaxation																											2.2Dielectric relaxation time																											2.3Liquids and amorphous solids																											2.4Spin relaxation in NMR
where ρ is the mean density, m is the test-star mass, σ is the 1d velocity dispersion of the field stars, and ln Λ is the Coulomb logarithm.
Consider a supersaturated portion of a cloud. Then shut off the updrafts, entrainment, and any other vapor sources/sinks and things that would induce the growth of the particles (ice or water). Then wait for this supersaturation to reduce and become just saturation (relative humidity = 100%), which is the equilibrium state. The time it takes for the supersaturation to dissipate is called relaxation time. It will happen as ice crystals or liquid water content grow within the cloud and will thus consume the contained moisture. The dynamics of relaxation are very important in cloud physics for accurate mathematical modelling.
The dielectric relaxation time is closely related to the electrical conductivity. In a semiconductor it is a measure of how long it takes to become neutralized by conduction process. This relaxation time is small in metals and can be large in semiconductors and insulators.
To solve for the concentration of A, recognize that the forward reaction (A→kB{\displaystyle {\ce {A ->[{k}] B}}}) causes the concentration of A to decrease over time, whereas the reverse reaction (B→k′A{\displaystyle {\ce {B ->[{k'}] A}}}) causes the concentration of A to increase over time.
This page was last edited on 13 March 2023, at 23:48 (UTC).
Substituting this value for [B] in terms of [A]0 and [A](t) yields
The constant τ=RC {\displaystyle \tau =RC\ } is called the relaxation time or RC time constant of the circuit. A nonlinear oscillator circuit which generates a repeating waveform by the repetitive discharge of a capacitor through a resistance is called a relaxation oscillator.
In dielectric materials, the dielectric polarization P depends on the electric field E. If E changes, P(t) reacts: the polarization relaxes towards a new equilibrium. It is important in dielectric spectroscopy. Very long relaxation times are responsible for dielectric absorption.
In other words, reactant A and product B are forming into one another based on reaction rate constants k and k'.
^ Atkins P. and de Paula J. Atkins' Physical Chemistry (8th ed., W.H.Freeman 2006) p.805-7, .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}ISBN 0-7167-8759-8
model damped unforced oscillations of a weight on a spring.
Various events occur on timescales relating to the relaxation time, including core collapse, energy equipartition, and formation of a Bahcall-Wolf cusp around a supermassive black hole.
Find sources: "Relaxation" physics – news · newspapers · books · scholar · JSTOR
4In atmospheric sciences											Toggle In atmospheric sciences subsection																					4.1Desaturation of clouds
An amorphous solid such as amorphous indomethacin displays a temperature dependence of molecular motion, which can be quantified as the average relaxation time for the solid in a metastable supercooled liquid or glass to approach the molecular motion characteristic of a crystal. Differential scanning calorimetry can be used to quantify enthalpy change due to molecular structural relaxation.
In chemical kinetics, relaxation methods are used for the measurement of very fast reaction rates. A system initially at equilibrium is perturbed by a rapid change in a parameter such as the temperature (most commonly), the pressure, the electric field or the pH of the solvent. The return to equilibrium is then observed, usually by spectroscopic means, and the relaxation time measured. In combination with the chemical equilibrium constant of the system, this enables the determination of the rate constants for the forward and reverse reactions.[2]
The term "structural relaxation" was introduced in the scientific literature in 1947/48 without any explanation, applied to NMR, and meaning the same as "thermal relaxation".[1]
Roland Z-120 Relax, a German ultralight aircraft design for the 120 kg class
This page was last edited on 22 August 2022, at 00:43 (UTC).
Regular Language description for XML, a specification for describing XML-based languages
"Relax", a song by Labi Siffre from The Singer and the Song
"Relax" (song), a 1983 song by Frankie Goes to Hollywood, covered, sampled and remixed by many artists
"Relax", a song by The Who from The Who Sell Out
"Relax", a song by Das Racist, title track from Relax
which corresponds to a union of intervals.We then return thesmallest interval which contains this union.
where ti{\displaystyle t_{i}} and [yi]{\displaystyle [y_{i}]} are given by the following list
Drevelle, V.; Bonnifait, Ph. (2011). "A set-membership approach for high integrity height-aided satellite positioning". GPS Solutions. 15 (4).
^ Drevelle, V.; Bonnifait, Ph. (2011). "A set-membership approach for high integrity height-aided satellite positioning". GPS Solutions. 15 (4).
.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Jaulin, L.; Walter, E.; Didrit, O. (1996). Guaranteed robust nonlinear parameter bounding (PDF). In Proceedings of CESA'96 IMACS Multiconference (Symposium on Modelling, Analysis and Simulation).
Langerwisch, M.; Wagner, B. (2012). "Guaranteed Mobile Robot Tracking Using Robust Interval Constraint Propagation". Intelligent Robotics and Applications..
⋂{q}Xi¯=⋃{m−q−1}Xi¯=⋂{m−q−1}Xi¯{\displaystyle {\overline {\bigcap \limits ^{\{q\}}X_{i}}}={\overline {{\overset {\{m-q-1\}}{\bigcup }}X_{i}}}=\bigcap ^{\{m-q-1\}}{\overline {X_{i}}}}
Jaulin, L.; Walter, E. (2002). "Guaranteed robust nonlinear minimax estimation" (PDF). IEEE Transactions on Automatic Control. 47.
The q-relaxed intersection of the m subsetsX1,…,Xm{\displaystyle X_{1},\dots ,X_{m}}of Rn{\displaystyle R^{n}},denoted byX{q}=⋂{q}Xi{\displaystyle X^{\{q\}}=\bigcap ^{\{q\}}X_{i}}is the set of allx∈Rn{\displaystyle x\in R^{n}}which belong to allXi{\displaystyle X_{i}}'s, exceptq{\displaystyle q}at most.This definition is illustrated by Figure 1.
If X¯{\displaystyle {\overline {X}}} denotes the complementary set of Xi{\displaystyle X_{i}}, we have
To compute the q-relaxed intersection of m boxes ofRn{\displaystyle R^{n}}, we project all m boxes with respect to the n axes.For each of the n groups of m intervals, we compute the q-relaxed intersection.We return Cartesian product of the n resulting intervals.[2]Figure 3 provides anillustration of the 4-relaxed intersection of 6 boxes. Each point of thered box belongs to 4 of the 6 boxes.
Consider 8 intervals:X1=[1,4],{\displaystyle X_{1}=[1,4],}X2= [2,4],{\displaystyle X_{2}=\ [2,4],}X3=[2,7],{\displaystyle X_{3}=[2,7],}X4=[6,9],{\displaystyle X_{4}=[6,9],}X5=[3,4],{\displaystyle X_{5}=[3,4],}X6=[3,7].{\displaystyle X_{6}=[3,7].}
Jaulin, L. (2009). "Robust set membership state estimation ; Application to Underwater Robotics" (PDF). Automatica. 45: 202–206. doi:10.1016/j.automatica.2008.06.013.
^ Jaulin, L.; Kieffer, M.; Walter, E.; Meizel, D. (2002). "Guaranteed robust nonlinear estimation, with application to robot localization" (PDF). IEEE Transactions on systems, man and cybernetics; Part C Applications and Reviews. 32. Archived from the original (PDF) on 2011-04-28.
Let C1,…,Cm{\displaystyle C_{1},\dots ,C_{m}} be m contractors for the sets X1,…,Xm{\displaystyle X_{1},\dots ,X_{m}},then
^ Langerwisch, M.; Wagner, B. (2012). "Guaranteed Mobile Robot Tracking Using Robust Interval Constraint Propagation". Intelligent Robotics and Applications..
^ Jaulin, L.; Walter, E. (2002). "Guaranteed robust nonlinear minimax estimation" (PDF). IEEE Transactions on Automatic Control. 47.
Kieffer, M.; Walter, E. (2013). Guaranteed characterization of exact non-asymptotic confidence regions in nonlinear parameter estimation (PDF). In Proceedings of IFAC Symposium on Nonlinear Control Systems, Toulouse : France (2013).
The q-relaxed union of X1,…,Xm{\displaystyle X_{1},\dots ,X_{m}} is defined by
Figure 2 shows the functionλ(x){\displaystyle \lambda (x)}associated to the previous example.
The sets λ−1(q){\displaystyle \lambda ^{-1}(q)} for different q{\displaystyle q} are depicted onFigure 4.
The relaxed intersection of m sets corresponds to the classicalintersection between sets except that it is allowed to relax few sets in order to avoid an empty intersection.This notion can be used to solve Constraints Satisfaction Problemsthat are inconsistent by relaxing a small number of constraints.When a bounded-error approach is considered for parameter estimation,the relaxed intersection makes it possible to be robust with respectto some outliers.
We propose here a simple example[7]to illustrate the method.Consider a model the ith model output of which is given by
"Robust set membership state estimation ; Application to Underwater Robotics"
Combined with a branch-and-bound algorithm such as SIVIA (Set Inversion Via Interval Analysis), the q-relaxedintersection of m subsets of Rn{\displaystyle R^{n}} can be computed.
^ Kieffer, M.; Walter, E. (2013). Guaranteed characterization of exact non-asymptotic confidence regions in nonlinear parameter estimation (PDF). In Proceedings of IFAC Symposium on Nonlinear Control Systems, Toulouse : France (2013).
^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Jaulin, L.; Walter, E.; Didrit, O. (1996). Guaranteed robust nonlinear parameter bounding (PDF). In Proceedings of CESA'96 IMACS Multiconference (Symposium on Modelling, Analysis and Simulation).
This page was last edited on 2 April 2020, at 12:04 (UTC).
^ Jaulin, L. (2009). "Robust set membership state estimation ; Application to Underwater Robotics" (PDF). Automatica. 45: 202–206. doi:10.1016/j.automatica.2008.06.013.
The q-relaxed intersection can be used for robust localization[3][4]or for tracking.[5]
The relaxed intersection of intervals is not necessary an interval. We thus takethe interval hull of the result. If Xi{\displaystyle X_{i}}'s are intervals, the relaxedintersection can be computed with a complexity of m.log(m) by using the Marzullo's algorithm. It suffices tosort all lower and upper bounds of the m intervals to represent thefunction λ{\displaystyle \lambda }. Then, we easily get the set
Guaranteed characterization of exact non-asymptotic confidence regions in nonlinear parameter estimation
Robust observers can also be implemented using the relaxed intersections to be robust with respect to outliers.[6]
X{0}=∅,{\displaystyle X^{\{0\}}=\emptyset ,}X{1}=[3,4],{\displaystyle X^{\{1\}}=[3,4],}X{2}=[3,4],{\displaystyle X^{\{2\}}=[3,4],}X{3}=[2,4]∪[6,7],{\displaystyle X^{\{3\}}=[2,4]\cup [6,7],}X{4}=[2,7],{\displaystyle X^{\{4\}}=[2,7],}X{5}=[1,9],{\displaystyle X^{\{5\}}=[1,9],}X{6}=]−∞,∞[.{\displaystyle X^{\{6\}}=]-\infty ,\infty [.}
Characterizing the q-relaxed intersection is a thus a set inversion problem.[1]
Jaulin, L.; Kieffer, M.; Walter, E.; Meizel, D. (2002). "Guaranteed robust nonlinear estimation, with application to robot localization" (PDF). IEEE Transactions on systems, man and cybernetics; Part C Applications and Reviews. 32. Archived from the original (PDF) on 2011-04-28.
Note that when q=0, the relaxed union/intersection corresponds tothe classical union/intersection. More precisely, we have
9.6Fluctuations within an isolated system in its own internal thermodynamic equilibrium
Otherwise, a thermodynamic operation may directly affect a wall of the system.
Haase, R. (1971). Survey of Fundamental Laws, chapter 1 of Thermodynamics, pages 1–97 of volume 1, ed. W. Jost, of Physical Chemistry. An Advanced Treatise, ed. H. Eyring, D. Henderson, W. Jost, Academic Press, New York, lcn 73–117081.
Another author, cited by Callen as giving a "scholarly and rigorous treatment",[19] and cited by Adkins as having written a "classic text",[20] A.B. Pippard writes in that text: "Given long enough a supercooled vapour will eventually condense, ... . The time involved may be so enormous, however, perhaps 10100 years or more, ... . For most purposes, provided the rapid change is not artificially stimulated, the systems may be regarded as being in equilibrium."[21]
In systems that are at a state of non-equilibrium there are, by contrast, net flows of matter or energy. If such changes can be triggered to occur in a system in which they are not already occurring, the system is said to be in a meta-stable equilibrium.
Buchdahl, H.A. (1966). The Concepts of Classical Thermodynamics, Cambridge University Press, Cambridge UK.
de Groot, S.R., Mazur, P. (1962). Non-equilibrium Thermodynamics, North-Holland, Amsterdam. Reprinted (1984), Dover Publications Inc., New York, ISBN 0486647412.
The temperature within a system in thermodynamic equilibrium is uniform in space as well as in time. In a system in its own state of internal thermodynamic equilibrium, there are no net internal macroscopic flows. In particular, this means that all local parts of the system are in mutual radiative exchange equilibrium. This means that the temperature of the system is spatially uniform.[3] This is so in all cases, including those of non-uniform external force fields. For an externally imposed gravitational field, this may be proved in macroscopic thermodynamic terms, by the calculus of variations, using the method of Langrangian multipliers.[42][43][44][45][46][47] Considerations of kinetic theory or statistical mechanics also support this statement.[48][49][50][51][52][53][54]
Marsland, Robert; Brown, Harvey R.; Valente, Giovanni (2015). "Time and irreversibility in axiomatic thermodynamics". American Journal of Physics. 83 (7): 628–634. Bibcode:2015AmJPh..83..628M. doi:10.1119/1.4914528. hdl:11311/1043322. S2CID 117173742.
In a section headed "Thermodynamic equilibrium", H.B. Callen defines equilibrium states in a paragraph. He points out that they "are determined by intrinsic factors" within the system. They are "terminal states", towards which the systems evolve, over time, which may occur with "glacial slowness".[28] This statement does not explicitly say that for thermodynamic equilibrium, the system must be isolated; Callen does not spell out what he means by the words "intrinsic factors".
^ Silbey, R.J., Alberty, R.A., Bawendi, M.G. (1955/2005), p. 4.
Carathéodory, C. (1909). Untersuchungen über die Grundlagen der Thermodynamik, Mathematische Annalen, 67: 355–386. A translation may be found here.Also a mostly reliable translation is to be found at Kestin, J. (1976). The Second Law of Thermodynamics, Dowden, Hutchinson & Ross, Stroudsburg PA.
C. Michael Hogan, Leda C. Patmore and Harry Seidman (1973) Statistical Prediction of Dynamic Thermal Equilibrium Temperatures using Standard Meteorological Data Bases, Second Edition (EPA-660/2-73-003 2006) United States Environmental Protection Agency Office of Research and Development, Washington, D.C. [1]
Coombes, C.A.; Laue, H. (1985). "A paradox concerning the temperature distribution of a gas in a gravitational field". Am. J. Phys. 53 (3): 272–273. Bibcode:1985AmJPh..53..272C. doi:10.1119/1.14138.
Beattie, J.A., Oppenheim, I. (1979). Principles of Thermodynamics, Elsevier Scientific Publishing, Amsterdam, ISBN 0-444-41806-7.
A system's internal state of thermodynamic equilibrium should be distinguished from a "stationary state" in which thermodynamic parameters are unchanging in time but the system is not isolated, so that there are, into and out of the system, non-zero macroscopic fluxes which are constant in time.[64]
Lieb, E. H.; Yngvason, J. (1999). "The Physics and Mathematics of the Second Law of Thermodynamics". Phys. Rep. 310 (1): 1–96. arXiv:cond-mat/9708200. Bibcode:1999PhR...310....1L. doi:10.1016/S0370-1573(98)00082-9. S2CID 119620408.
J.R. Waldram writes of "a definite thermodynamic state". He defines the term "thermal equilibrium" for a system "when its observables have ceased to change over time". But shortly below that definition he writes of a piece of glass that has not yet reached its "full thermodynamic equilibrium state".[37]
Another potential, the Gibbs free energy (G), is minimized at thermodynamic equilibrium in a closed system at constant temperature and pressure, both controlled by the surroundings:
Bailyn, M. (1994). A Survey of Thermodynamics, American Institute of Physics Press, New York, ISBN 0-88318-797-3.
Though not a widely named "law," it is an axiom of thermodynamics that there exist states of thermodynamic equilibrium. The second law of thermodynamics states that when an isolated body of material starts from an equilibrium state, in which portions of it are held at different states by more or less permeable or impermeable partitions, and a thermodynamic operation removes or makes the partitions more permeable, then it spontaneously reaches its own new state of internal thermodynamic equilibrium and this is accompanied by an increase in the sum of the entropies of the portions.
Fluctuations within an isolated system in its own internal thermodynamic equilibrium
To consider the notion of fluctuations in an isolated thermodynamic system, a convenient example is a system specified by its extensive state variables, internal energy, volume, and mass composition. By definition they are time-invariant. By definition, they combine with time-invariant nominal values of their conjugate intensive functions of state, inverse temperature, pressure divided by temperature, and the chemical potentials divided by temperature, so as to exactly obey the laws of thermodynamics.[59] But the laws of thermodynamics, combined with the values of the specifying extensive variables of state, are not sufficient to provide knowledge of those nominal values. Further information is needed, namely, of the constitutive properties of the system.
Non-equilibrium thermodynamics is a branch of thermodynamics that deals with systems that are not in thermodynamic equilibrium. Most systems found in nature are not in thermodynamic equilibrium because they are changing or can be triggered to change over time, and are continuously and discontinuously subject to flux of matter and energy to and from other systems. The thermodynamic study of non-equilibrium systems requires more general concepts than are dealt with by equilibrium thermodynamics.[65] Many natural systems still today remain beyond the scope of currently known macroscopic thermodynamic methods.
"On the Dynamical Theory of Heat, with numerical results deduced from Mr Joule's equivalent of a Thermal Unit, and M. Regnault's Observations on Steam"
A student textbook by F.H. Crawford has a section headed "Thermodynamic Equilibrium". It distinguishes several drivers of flows, and then says: "These are examples of the apparently universal tendency of isolated systems toward a state of complete mechanical, thermal, chemical, and electrical—or, in a single word, thermodynamic—equilibrium."[31]
Hans R. Griem (2005) Principles of Plasma Spectroscopy (Cambridge Monographs on Plasma Physics), Cambridge University Press, New YorkISBN 0-521-61941-6
Another textbook writer, C.J. Adkins, explicitly allows thermodynamic equilibrium to occur in a system which is not isolated. His system is, however, closed with respect to transfer of matter. He writes: "In general, the approach to thermodynamic equilibrium will involve both thermal and work-like interactions with the surroundings." He distinguishes such thermodynamic equilibrium from thermal equilibrium, in which only thermal contact is mediating transfer of energy.[29]
Another textbook author, J.R. Partington, writes: "(i) An equilibrium state is one which is independent of time." But, referring to systems "which are only apparently in equilibrium", he adds : "Such systems are in states of ″false equilibrium.″" Partington's statement does not explicitly state that the equilibrium refers to an isolated system. Like Münster, Partington also refers to the mixture of oxygen and hydrogen. He adds a proviso that "In a true equilibrium state, the smallest change of any external condition which influences the state will produce a small change of state ..."[30] This proviso means that thermodynamic equilibrium must be stable against small perturbations; this requirement is essential for the strict meaning of thermodynamic equilibrium.
In his exposition of his scheme of closed system equilibrium thermodynamics, C. Carathéodory initially postulates that experiment reveals that a definite number of real variables define the states that are the points of the manifold of equilibria.[8] In the words of Prigogine and Defay (1945): "It is a matter of experience that when we have specified a certain number of macroscopic properties of a system, then all the other properties are fixed."[56][57] As noted above, according to A. Münster, the number of variables needed to define a thermodynamic equilibrium is the least for any state of a given isolated system. As noted above, J.G. Kirkwood and I. Oppenheim point out that a state of thermodynamic equilibrium may be defined by a special subclass of intensive variables, with a definite number of members in that subclass.
Thomson, W. (March 1851). "On the Dynamical Theory of Heat, with numerical results deduced from Mr Joule's equivalent of a Thermal Unit, and M. Regnault's Observations on Steam". Transactions of the Royal Society of Edinburgh. XX (part II): 261–268, 289–298. Also published in Thomson, W. (December 1852). "On the Dynamical Theory of Heat, with numerical results deduced from Mr Joule's equivalent of a Thermal Unit, and M. Regnault's Observations on Steam". Phil. Mag. 4. IV (22): 8–21. Retrieved 25 June 2012.
Akmaev, R.A. (2008). "On the energetics of maximum-entropy temperature profiles". Q. J. R. Meteorol. Soc. 134 (630): 187–197. Bibcode:2008QJRMS.134..187A. doi:10.1002/qj.209. S2CID 122759570.
^ Akmaev, R.A. (2008). "On the energetics of maximum-entropy temperature profiles". Q. J. R. Meteorol. Soc. 134 (630): 187–197. Bibcode:2008QJRMS.134..187A. doi:10.1002/qj.209. S2CID 122759570.
If the description of the system requires variations in the intensive parameters that are too large, the very assumptions upon which the definitions of these intensive parameters are based will break down, and the system will be in neither global nor local equilibrium. For example, it takes a certain number of collisions for a particle to equilibrate to its surroundings. If the average distance it has moved during these collisions removes it from the neighborhood it is equilibrating to, it will never equilibrate, and there will be no LTE. Temperature is, by definition, proportional to the average internal energy of an equilibrated neighborhood. Since there is no equilibrated neighborhood, the concept of temperature doesn't hold, and the temperature becomes undefined.
where T denotes the absolute thermodynamic temperature, P the pressure, S the entropy, V the volume, and U the internal energy of the system. In other words, ΔG=0{\displaystyle \Delta G=0} is a necessary condition for chemical equilibrium under these conditions (in the absence of an applied voltage).
F. Mandl (1988) Statistical Physics, Second Edition, John Wiley & Sons
Zemansky, M. (1937/1968). Heat and Thermodynamics. An Intermediate Textbook, fifth edition 1967, McGraw–Hill Book Company, New York.
^ Verkley, W.T.M.; Gerkema, T. (2004). "On maximum entropy profiles". J. Atmos. Sci. 61 (8): 931–936. Bibcode:2004JAtS...61..931V. doi:10.1175/1520-0469(2004)0612.0.co;2.
Uhlenbeck, G.E., Ford, G.W. (1963). Lectures in Statistical Mechanics, American Mathematical Society, Providence RI.
Callen, H.B. (1960/1985). Thermodynamics and an Introduction to Thermostatistics, (1st edition 1960) 2nd edition 1985, Wiley, New York, ISBN 0-471-86256-8.
Non-Local Thermodynamic Equilibrium in Cloudy Planetary Atmospheres Paper by R. E. Samueison quantifying the effects due to non-LTE in an atmosphere
^ Marsland, Robert; Brown, Harvey R.; Valente, Giovanni (2015). "Time and irreversibility in axiomatic thermodynamics". American Journal of Physics. 83 (7): 628–634. Bibcode:2015AmJPh..83..628M. doi:10.1119/1.4914528. hdl:11311/1043322. S2CID 117173742.
R. Haase's presentation of thermodynamics does not start with a restriction to thermodynamic equilibrium because he intends to allow for non-equilibrium thermodynamics. He considers an arbitrary system with time invariant properties. He tests it for thermodynamic equilibrium by cutting it off from all external influences, except external force fields. If after insulation, nothing changes, he says that the system was in equilibrium.[27]
Prigogine, I., Defay, R. (1950/1954). Chemical Thermodynamics, Longmans, Green & Co, London.
P.M. Morse writes that thermodynamics is concerned with "states of thermodynamic equilibrium". He also uses the phrase "thermal equilibrium" while discussing transfer of energy as heat between a body and a heat reservoir in its surroundings, though not explicitly defining a special term 'thermal equilibrium'.[36]
Cesare Barbieri (2007) Fundamentals of Astronomy. First Edition (QB43.3.B37 2006) CRC Press.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}ISBN 0-7503-0886-9, ISBN 978-0-7503-0886-1
Partington, J.R. (1949). An Advanced Treatise on Physical Chemistry, volume 1, Fundamental Principles. The Properties of Gases, Longmans, Green and Co., London.
^ Tschoegl, N.W. (2000). Fundamentals of Equilibrium and Steady-State Thermodynamics, Elsevier, Amsterdam, ISBN 0-444-50426-5, p. 21.
Breakdown of Local Thermodynamic Equilibrium George W. Collins, The Fundamentals of Stellar Astrophysics, Chapter 15
Pokrovskii, Vladimir (2020). Thermodynamics of Complex Systems: Principles and applications. IOP Publishing, Bristol, UK.
J.A. Beattie and I. Oppenheim write: "Insistence on a strict interpretation of the definition of equilibrium would rule out the application of thermodynamics to practically all states of real systems."[18]
Local thermodynamic equilibrium does not require either local or global stationarity. In other words, each small locality need not have a constant temperature. However, it does require that each small locality change slowly enough to practically sustain its local Maxwell–Boltzmann distribution of molecular velocities. A global non-equilibrium state can be stably stationary only if it is maintained by exchanges between the system and the outside. For example, a globally-stable stationary state could be maintained inside the glass of water by continuously adding finely powdered ice into it to compensate for the melting, and continuously draining off the meltwater. Natural transport phenomena may lead a system from local to global thermodynamic equilibrium. Going back to our example, the diffusion of heat will lead our glass of water toward global thermodynamic equilibrium, a state in which the temperature of the glass is completely homogeneous.[16]
It is useful to distinguish between global and local thermodynamic equilibrium. In thermodynamics, exchanges within a system and between the system and the outside are controlled by intensive parameters. As an example, temperature controls heat exchanges. Global thermodynamic equilibrium (GTE) means that those intensive parameters are homogeneous throughout the whole system, while local thermodynamic equilibrium (LTE) means that those intensive parameters are varying in space and time, but are varying so slowly that, for any point, one can assume thermodynamic equilibrium in some neighborhood about that point.
As an example, LTE will exist in a glass of water that contains a melting ice cube. The temperature inside the glass can be defined at any point, but it is colder near the ice cube than far away from it. If energies of the molecules located near a given point are observed, they will be distributed according to the Maxwell–Boltzmann distribution for a certain temperature. If the energies of the molecules located near another point are observed, they will be distributed according to the Maxwell–Boltzmann distribution for another temperature.
Tschoegl, N.W. (2000). Fundamentals of Equilibrium and Steady-State Thermodynamics, Elsevier, Amsterdam, ISBN 0-444-50426-5, p. 21.
Boltzmann, L. (1896/1964). Lectures on Gas Theory, translated by S.G. Brush, University of California Press, Berkeley.
Ziegler, H. (1983). An Introduction to Thermomechanics. North Holland, Amsterdam.
Kleidon, A.; et., al. (2005). Non-equilibrium Thermodynamics and the Production of Entropy (Heidelberg: Springer. ed.).
Levine, I.N. (1983), Physical Chemistry, second edition, McGraw-Hill, New York, ISBN 978-0072538625.
Mortimer, R. G. Physical Chemistry, 3rd ed., p. 157, Academic Press, 2008.
Román, F.L.; White, J.A.; Velasco, S. (1995). "Microcanonical single-particle distributions for an ideal gas in a gravitational field". Eur. J. Phys. 16 (2): 83–90. Bibcode:1995EJPh...16...83R. doi:10.1088/0143-0807/16/2/008. S2CID 250840083.
Silbey, R.J., Alberty, R.A., Bawendi, M.G. (1955/2005). Physical Chemistry, fourth edition, Wiley, Hoboken NJ.
A collection of matter may be entirely isolated from its surroundings. If it has been left undisturbed for an indefinitely long time, classical thermodynamics postulates that it is in a state in which no changes occur within it, and there are no flows within it. This is a thermodynamic state of internal equilibrium.[4][5] (This postulate is sometimes, but not often, called the "minus first" law of thermodynamics.[6] One textbook[7] calls it the "zeroth law", remarking that the authors think this more befitting that title than its more customary definition, which apparently was suggested by Fowler.)
Two systems are in mechanical equilibrium when their pressures are the same.
9Characteristics of a state of internal thermodynamic equilibrium											Toggle Characteristics of a state of internal thermodynamic equilibrium subsection																					9.1Homogeneity in the absence of external forces																											9.2Uniform temperature																											9.3Number of real variables needed for specification																											9.4Stability against small perturbations																											9.5Approach to thermodynamic equilibrium within an isolated system																											9.6Fluctuations within an isolated system in its own internal thermodynamic equilibrium																											9.7Thermal equilibrium
M. Zemansky also distinguishes mechanical, chemical, and thermal equilibrium. He then writes: "When the conditions for all three types of equilibrium are satisfied, the system is said to be in a state of thermodynamic equilibrium".[35]
Morse, P.M. (1969). Thermal Physics, second edition, W.A. Benjamin, Inc, New York.
In an isolated system, thermodynamic equilibrium by definition persists over an indefinitely long time. In classical physics it is often convenient to ignore the effects of measurement and this is assumed in the present account.
Pippard, A.B. (1957/1966).The Elements of Classical Thermodynamics, reprinted with corrections 1966, Cambridge University Press, London.
Thermodynamic equilibrium is the unique stable stationary state that is approached or eventually reached as the system interacts with its surroundings over a long time. The above-mentioned potentials are mathematically constructed to be the thermodynamic quantities that are minimized under the particular conditions in the specified surroundings.
Another author, A. Münster, writes in this context. He observes that thermonuclear processes often occur so slowly that they can be ignored in thermodynamics. He comments: "The concept 'absolute equilibrium' or 'equilibrium with respect to all imaginable processes', has therefore, no physical significance." He therefore states that: "... we can consider an equilibrium only with respect to specified processes and defined experimental conditions."[22]
Considering equilibrium states, M. Bailyn writes: "Each intensive variable has its own type of equilibrium." He then defines thermal equilibrium, mechanical equilibrium, and material equilibrium. Accordingly, he writes: "If all the intensive variables become uniform, thermodynamic equilibrium is said to exist." He is not here considering the presence of an external force field.[38]
Kirkwood, J.G., Oppenheim, I. (1961). Chemical Thermodynamics, McGraw-Hill Book Company, New York.
A monograph on classical thermodynamics by H.A. Buchdahl considers the "equilibrium of a thermodynamic system", without actually writing the phrase "thermodynamic equilibrium". Referring to systems closed to exchange of matter, Buchdahl writes: "If a system is in a terminal condition which is properly static, it will be said to be in equilibrium."[32] Buchdahl's monograph also discusses amorphous glass, for the purposes of thermodynamic description. It states: "More precisely, the glass may be regarded as being in equilibrium so long as experimental tests show that 'slow' transitions are in effect reversible."[33] It is not customary to make this proviso part of the definition of thermodynamic equilibrium, but the converse is usually assumed: that if a body in thermodynamic equilibrium is subject to a sufficiently slow process, that process may be considered to be sufficiently nearly reversible, and the body remains sufficiently nearly in thermodynamic equilibrium during the process.[34]
In order that a system may be in its own internal state of thermodynamic equilibrium, it is of course necessary, but not sufficient, that it be in its own internal state of thermal equilibrium; it is possible for a system to reach internal mechanical equilibrium before it reaches internal thermal equilibrium.[55]
^ Velasco, S.; Román, F.L.; White, J.A. (1996). "On a paradox concerning the temperature distribution of an ideal gas in a gravitational field". Eur. J. Phys. 17: 43–44. doi:10.1088/0143-0807/17/1/008. S2CID 250885860.
Münster, A. (1970). Classical Thermodynamics, translated by E.S. Halberstadt, Wiley–Interscience, London.
For example, one widely cited writer, H. B. Callen writes in this context: "In actuality, few systems are in absolute and true equilibrium." He refers to radioactive processes and remarks that they may take "cosmic times to complete, [and] generally can be ignored". He adds "In practice, the criterion for equilibrium is circular. Operationally, a system is in an equilibrium state if its properties are consistently described by thermodynamic theory!"[17]
Systems in mutual thermodynamic equilibrium are simultaneously in mutual thermal, mechanical, chemical, and radiative equilibria. Systems can be in one kind of mutual equilibrium, while not in others. In thermodynamic equilibrium, all kinds of equilibrium hold at once and indefinitely, until disturbed by a thermodynamic operation. In a macroscopic equilibrium, perfectly or almost perfectly balanced microscopic exchanges occur; this is the physical explanation of the notion of macroscopic equilibrium.
Guggenheim, E.A. (1949/1967). Thermodynamics. An Advanced Treatment for Chemists and Physicists, fifth revised edition, North-Holland, Amsterdam.
As noted above, J.R. Partington points out that a state of thermodynamic equilibrium is stable against small transient perturbations. Without this condition, in general, experiments intended to study systems in thermodynamic equilibrium are in severe difficulties.
Griem, H.R. (2005). Principles of Plasma Spectroscopy (Cambridge Monographs on Plasma Physics), Cambridge University Press, New YorkISBN 0-521-61941-6.
A thermodynamic operation may occur as an event restricted to the walls that are within the surroundings, directly affecting neither the walls of contact of the system of interest with its surroundings, nor its interior, and occurring within a definitely limited time. For example, an immovable adiabatic wall may be placed or removed within the surroundings. Consequent upon such an operation restricted to the surroundings, the system may be for a time driven away from its own initial internal state of thermodynamic equilibrium. Then, according to the second law of thermodynamics, the whole undergoes changes and eventually reaches a new and final equilibrium with the surroundings. Following Planck, this consequent train of events is called a natural thermodynamic process.[12] It is allowed in equilibrium thermodynamics just because the initial and final states are of thermodynamic equilibrium, even though during the process there is transient departure from thermodynamic equilibrium, when neither the system nor its surroundings are in well defined states of internal equilibrium. A natural process proceeds at a finite rate for the main part of its course. It is thereby radically different from a fictive quasi-static 'process' that proceeds infinitely slowly throughout its course, and is fictively 'reversible'. Classical thermodynamics allows that even though a process may take a very long time to settle to thermodynamic equilibrium, if the main part of its course is at a finite rate, then it is considered to be natural, and to be subject to the second law of thermodynamics, and thereby irreversible. Engineered machines and artificial devices and manipulations are permitted within the surroundings.[13][14] The allowance of such operations and devices in the surroundings but not in the system is the reason why Kelvin in one of his statements of the second law of thermodynamics spoke of "inanimate" agency; a system in thermodynamic equilibrium is inanimate.[15]
^ Belkin, Andrey; et., al. (2015). "Self-Assembled Wiggling Nano-Structures and the Principle of Maximum Entropy Production". Sci. Rep. 5: 8323. Bibcode:2015NatSR...5E8323B. doi:10.1038/srep08323. PMC 4321171. PMID 25662746.
Often the surroundings of a thermodynamic system may also be regarded as another thermodynamic system. In this view, one may consider the system and its surroundings as two systems in mutual contact, with long-range forces also linking them. The enclosure of the system is the surface of contiguity or boundary between the two systems. In the thermodynamic formalism, that surface is regarded as having specific properties of permeability. For example, the surface of contiguity may be supposed to be permeable only to heat, allowing energy to transfer only as heat. Then the two systems are said to be in thermal equilibrium when the long-range forces are unchanging in time and the transfer of energy as heat between them has slowed and eventually stopped permanently; this is an example of a contact equilibrium. Other kinds of contact equilibrium are defined by other kinds of specific permeability.[2] When two systems are in contact equilibrium with respect to a particular kind of permeability, they have common values of the intensive variable that belongs to that particular kind of permeability. Examples of such intensive variables are temperature, pressure, chemical potential.
The statement that 'the system is its own internal thermodynamic equilibrium' may be taken to mean that 'indefinitely many such measurements have been taken from time to time, with no trend in time in the various measured values'. Thus the statement, that 'a system is in its own internal thermodynamic equilibrium, with stated nominal values of its functions of state conjugate to its specifying state variables', is far far more informative than a statement that 'a set of single simultaneous measurements of those functions of state have those same values'. This is because the single measurements might have been made during a slight fluctuation, away from another set of nominal values of those conjugate intensive functions of state, that is due to unknown and different constitutive properties. A single measurement cannot tell whether that might be so, unless there is also knowledge of the nominal values that belong to the equilibrium state.
If the mesoscopic system is further repeatedly divided, eventually amicroscopic system is produced. Then the molecular character of matter and the quantal nature of momentum transfer become important in the processes of fluctuation. One has left the realm of classical or macroscopic thermodynamics, and one needs quantum statistical mechanics. The fluctuations can become relatively dominant, and questions of measurement become important.
^ Román, F.L.; White, J.A.; Velasco, S. (1995). "Microcanonical single-particle distributions for an ideal gas in a gravitational field". Eur. J. Phys. 16 (2): 83–90. Bibcode:1995EJPh...16...83R. doi:10.1088/0143-0807/16/2/008. S2CID 250840083.
If the system is repeatedly subdivided, eventually a system is produced that is small enough to exhibit obvious fluctuations. This is a mesoscopic level of investigation. The fluctuations are then directly dependent on the natures of the various walls of the system. The precise choice of independent state variables is then important. At this stage, statistical features of the laws of thermodynamics become apparent.
J.G. Kirkwood and I. Oppenheim define thermodynamic equilibrium as follows: "A system is in a state of thermodynamic equilibrium if, during the time period allotted for experimentation, (a) its intensive properties are independent of time and (b) no current of matter or energy exists in its interior or at its boundaries with the surroundings." It is evident that they are not restricting the definition to isolated or to closed systems. They do not discuss the possibility of changes that occur with "glacial slowness", and proceed beyond the time period allotted for experimentation. They note that for two systems in contact, there exists a small subclass of intensive properties such that if all those of that small subclass are respectively equal, then all respective intensive properties are equal. States of thermodynamic equilibrium may be defined by this subclass, provided some other conditions are satisfied.[39]
Thermodynamic equilibrium is a primitive notion of the theory of thermodynamics. According to P.M. Morse: "It should be emphasized that the fact that there are thermodynamic states, ..., and the fact that there are thermodynamic variables which are uniquely specified by the equilibrium state ... are not conclusions deduced logically from some philosophical first principles. They are conclusions ineluctably drawn from more than two centuries of experiments."[24] This means that thermodynamic equilibrium is not to be defined solely in terms of other theoretical concepts of thermodynamics. M. Bailyn proposes a fundamental law of thermodynamics that defines and postulates the existence of states of thermodynamic equilibrium.[25]
Fluctuations within an isolated system in its own internal thermodynamic equilibrium[edit]
This page was last edited on 16 March 2023, at 03:59 (UTC).
A radiative exchange can occur between two otherwise separate systems. Radiative exchange equilibrium prevails when the two systems have the same temperature.[3]
Waldram, J.R. (1985). The Theory of Thermodynamics, Cambridge University Press, Cambridge UK, ISBN 0-521-24575-3.
Belkin, Andrey; et., al. (2015). "Self-Assembled Wiggling Nano-Structures and the Principle of Maximum Entropy Production". Sci. Rep. 5: 8323. Bibcode:2015NatSR...5E8323B. doi:10.1038/srep08323. PMC 4321171. PMID 25662746.
It is often convenient to suppose that some of the surrounding subsystems are so much larger than the system that the process can affect the intensive variables only of the surrounding subsystems, and they are then called reservoirs for relevant intensive variables.
^ Pokrovskii, Vladimir (2020). Thermodynamics of Complex Systems: Principles and applications. IOP Publishing, Bristol, UK.
A. Münster carefully extends his definition of thermodynamic equilibrium for isolated systems by introducing a concept of contact equilibrium. This specifies particular processes that are allowed when considering thermodynamic equilibrium for non-isolated systems, with special concern for open systems, which may gain or lose matter from or to their surroundings. A contact equilibrium is between the system of interest and a system in the surroundings, brought into contact with the system of interest, the contact being through a special kind of wall; for the rest, the whole joint system is isolated. Walls of this special kind were also considered by C. Carathéodory, and are mentioned by other writers also. They are selectively permeable. They may be permeable only to mechanical work, or only to heat, or only to some particular chemical substance. Each contact equilibrium defines an intensive parameter; for example, a wall permeable only to heat defines an empirical temperature. A contact equilibrium can exist for each chemical constituent of the system of interest. In a contact equilibrium, despite the possible exchange through the selectively permeable wall, the system of interest is changeless, as if it were in isolated thermodynamic equilibrium. This scheme follows the general rule that "... we can consider an equilibrium only with respect to specified processes and defined experimental conditions."[22] Thermodynamic equilibrium for an open system means that, with respect to every relevant kind of selectively permeable wall, contact equilibrium exists when the respective intensive parameters of the system and surroundings are equal.[2] This definition does not consider the most general kind of thermodynamic equilibrium, which is through unselective contacts. This definition does not simply state that no current of matter or energy exists in the interior or at the boundaries; but it is compatible with the following definition, which does so state.
Classical thermodynamics deals with states of dynamic equilibrium. The state of a system at thermodynamic equilibrium is the one for which some thermodynamic potential is minimized (in the absence of an applied voltage),[1] or for which the entropy (S) is maximized, for specified conditions. One such potential is the Helmholtz free energy (A), for a closed system at constant volume and temperature (controlled by a heat bath):
Velasco, S.; Román, F.L.; White, J.A. (1996). "On a paradox concerning the temperature distribution of an ideal gas in a gravitational field". Eur. J. Phys. 17: 43–44. doi:10.1088/0143-0807/17/1/008. S2CID 250885860.
^ Ziegler, H. (1983). An Introduction to Thermomechanics. North Holland, Amsterdam.
For a completely isolated system, S is maximum at thermodynamic equilibrium.
Such states are a principal concern in what is known as classical or equilibrium thermodynamics, for they are the only states of the system that are regarded as well defined in that subject. A system in contact equilibrium with another system can by a thermodynamic operation be isolated, and upon the event of isolation, no change occurs in it. A system in a relation of contact equilibrium with another system may thus also be regarded as being in its own state of internal thermodynamic equilibrium.
Crawford, F.H. (1963). Heat, Thermodynamics, and Statistical Physics, Rupert Hart-Davis, London, Harcourt, Brace & World, Inc.
Landsberg, P.T. (1961). Thermodynamics with Quantum Statistical Illustrations, Interscience, New York.
^ Mortimer, R. G. Physical Chemistry, 3rd ed., p. 157, Academic Press, 2008.
^ Coombes, C.A.; Laue, H. (1985). "A paradox concerning the temperature distribution of a gas in a gravitational field". Am. J. Phys. 53 (3): 272–273. Bibcode:1985AmJPh..53..272C. doi:10.1119/1.14138.
The most general kind of thermodynamic equilibrium of a system is through contact with the surroundings that allows simultaneous passages of all chemical substances and all kinds of energy. A system in thermodynamic equilibrium may move with uniform acceleration through space but must not change its shape or size while doing so; thus it is defined by a rigid volume in space. It may lie within external fields of force, determined by external factors of far greater extent than the system itself, so that events within the system cannot in an appreciable amount affect the external fields of force. The system can be in thermodynamic equilibrium only if the external force fields are uniform, and are determining its uniform acceleration, or if it lies in a non-uniform force field but is held stationary there by local forces, such as mechanical pressures, on its surface.
A thermodynamic system consisting of a single phase in the absence of external forces, in its own internal thermodynamic equilibrium, is homogeneous.[40] This means that the material in any small volume element of the system can be interchanged with the material of any other geometrically congruent volume element of the system, and the effect is to leave the system thermodynamically unchanged. In general, a strong external force field makes a system of a single phase in its own internal thermodynamic equilibrium inhomogeneous with respect to some intensive variables. For example, a relatively dense component of a mixture can be concentrated by centrifugation.
An explicit distinction between 'thermal equilibrium' and 'thermodynamic equilibrium' is made by B. C. Eu. He considers two systems in thermal contact, one a thermometer, the other a system in which there are several occurring irreversible processes, entailing non-zero fluxes; the two systems are separated by a wall permeable only to heat. He considers the case in which, over the time scale of interest, it happens that both the thermometer reading and the irreversible processes are steady. Then there is thermal equilibrium without thermodynamic equilibrium. Eu proposes consequently that the zeroth law of thermodynamics can be considered to apply even when thermodynamic equilibrium is not present; also he proposes that if changes are occurring so fast that a steady temperature cannot be defined, then "it is no longer possible to describe the process by means of a thermodynamic formalism. In other words, thermodynamics has no meaning for such a process."[61] This illustrates the importance for thermodynamics of the concept of temperature.
Gibbs, J.W. (1876/1878). On the equilibrium of heterogeneous substances, Trans. Conn. Acad., 3: 108–248, 343–524, reprinted in The Collected Works of J. Willard Gibbs, PhD, LL. D., edited by W.R. Longley, R.G. Van Name, Longmans, Green & Co., New York, 1928, volume 1, pp. 55–353.
A thermodynamic system in a state of internal thermodynamic equilibrium has a spatially uniform temperature. Its intensive properties, other than temperature, may be driven to spatial inhomogeneity by an unchanging long-range force field imposed on it by its surroundings.
If several systems are free of adiabatic walls between each other, but are jointly isolated from the rest of the world, then they reach a state of multiple contact equilibrium, and they have a common temperature, a total internal energy, and a total entropy.[8][9][10][11] Amongst intensive variables, this is a unique property of temperature. It holds even in the presence of long-range forces. (That is, there is no "force" that can maintain temperature discrepancies.) For example, in a system in thermodynamic equilibrium in a vertical gravitational field, the pressure on the top wall is less than that on the bottom wall, but the temperature is the same everywhere.
The thermodynamic formalism allows that a system may have contact with several other systems at once, which may or may not also have mutual contact, the contacts having respectively different permeabilities. If these systems are all jointly isolated from the rest of the world those of them that are in contact then reach respective contact equilibria with one another.
According to L. Tisza: "... in the discussion of phenomena near absolute zero. The absolute predictions of the classical theory become particularly vague because the occurrence of frozen-in nonequilibrium states is very common."[23]
For example, A. Münster writes: "An isolated system is in thermodynamic equilibrium when, in the system, no changes of state are occurring at a measurable rate." There are two reservations stated here; the system is isolated; any changes of state are immeasurably slow. He discusses the second proviso by giving an account of a mixture oxygen and hydrogen at room temperature in the absence of a catalyst. Münster points out that a thermodynamic equilibrium state is described by fewer macroscopic variables than is any other state of a given system. This is partly, but not entirely, because all flows within and through the system are zero.[26]
Onsager, Lars (1931). "Reciprocal Relations in Irreversible Processes". Phys. Rev. 37 (4): 405–426. Bibcode:1931PhRv...37..405O. doi:10.1103/PhysRev.37.405.
For a closed system at controlled constant temperature and pressure without an applied voltage, G is minimum at thermodynamic equilibrium.
^ Kleidon, A.; et., al. (2005). Non-equilibrium Thermodynamics and the Production of Entropy (Heidelberg: Springer. ed.).
Eu, B.C. (2002). Generalized Thermodynamics. The Thermodynamics of Irreversible Processes and Generalized Hydrodynamics, Kluwer Academic Publishers, Dordrecht, ISBN 1-4020-0788-4.
Careful and well informed writers about thermodynamics, in their accounts of thermodynamic equilibrium, often enough make provisos or reservations to their statements. Some writers leave such reservations merely implied or more or less unstated.
Maxwell, J.C. (1867). "On the dynamical theory of gases". Phil. Trans. R. Soc. Lond. 157: 49–88.
Planck. M. (1914). The Theory of Heat Radiation, a translation by Masius, M. of the second German edition, P. Blakiston's Son & Co., Philadelphia.
Thermal equilibrium occurs when a system's macroscopic thermal observables have ceased to change with time.For example, an ideal gas whose distribution function has stabilised to a specific Maxwell–Boltzmann distribution would be in thermal equilibrium.This outcome allows a single temperature and pressure to be attributed to the whole system. For an isolated body, it is quite possible for mechanical equilibrium to be reached before thermal equilibrium is reached, but eventually, all aspects of equilibrium, including thermal equilibrium, are necessary for thermodynamic equilibrium.[63]
^ Onsager, Lars (1931). "Reciprocal Relations in Irreversible Processes". Phys. Rev. 37 (4): 405–426. Bibcode:1931PhRv...37..405O. doi:10.1103/PhysRev.37.405.
Fitts, D.D. (1962). Nonequilibrium thermodynamics. A Phenomenological Theory of Irreversible Processes in Fluid Systems, McGraw-Hill, New York.
It is important to note that this local equilibrium may apply only to a certain subset of particles in the system. For example, LTE is usually applied only to massive particles. In a radiating gas, the photons being emitted and absorbed by the gas doesn't need to be in a thermodynamic equilibrium with each other or with the massive particles of the gas for LTE to exist. In some cases, it is not considered necessary for free electrons to be in equilibrium with the much more massive atoms or molecules for LTE to exist.
Adkins, C.J. (1968/1983). Equilibrium Thermodynamics, third edition, McGraw-Hill, London, ISBN 0-521-25445-0.
All forces are balanced and there is no significant external driving force.
^ Chapman, S., Cowling, T.G. (1939/1970), Section 4.14, pp. 75–78.
Thermodynamic equilibrium is an axiomatic concept of thermodynamics. It is an internal state of a single thermodynamic system, or a relation between several thermodynamic systems connected by more or less permeable or impermeable walls. In thermodynamic equilibrium, there are no net macroscopic flows of matter nor of energy within a system or between systems. In a system that is in its own state of internal thermodynamic equilibrium, no macroscopic change occurs.
Prigogine, I. (1947). Étude Thermodynamique des Phénomènes irréversibles, Dunod, Paris, and Desoers, Liège.
Such equilibrium inhomogeneity, induced by external forces, does not occur for the intensive variable temperature. According to E.A. Guggenheim, "The most important conception of thermodynamics is temperature."[41] Planck introduces his treatise with a brief account of heat and temperature and thermal equilibrium, and then announces: "In the following we shall deal chiefly with homogeneous, isotropic bodies of any form, possessing throughout their substance the same temperature and density, and subject to a uniform pressure acting everywhere perpendicular to the surface."[40] As did Carathéodory, Planck was setting aside surface effects and external fields and anisotropic crystals. Though referring to temperature, Planck did not there explicitly refer to the concept of thermodynamic equilibrium. In contrast, Carathéodory's scheme of presentation of classical thermodynamics for closed systems postulates the concept of an "equilibrium state" following Gibbs (Gibbs speaks routinely of a "thermodynamic state"), though not explicitly using the phrase 'thermodynamic equilibrium', nor explicitly postulating the existence of a temperature to define it.
Textbook definitions of thermodynamic equilibrium are often stated carefully, with some reservation or other.
Two systems are in diffusive equilibrium when their chemical potentials are the same.
Denbigh, K.G. (1951). Thermodynamics of the Steady State, Methuen, London.
Two systems are in thermal equilibrium when their temperatures are the same.
It may be admitted that on repeated measurement of those conjugate intensive functions of state, they are found to have slightly different values from time to time. Such variability is regarded as due to internal fluctuations. The different measured values average to their nominal values.
If the thermodynamic equilibrium lies in an external force field, it is only the temperature that can in general be expected to be spatially uniform. Intensive variables other than temperature will in general be non-uniform if the external force field is non-zero. In such a case, in general, additional variables are needed to describe the spatial non-uniformity.
If the system is truly macroscopic as postulated by classical thermodynamics, then the fluctuations are too small to detect macroscopically. This is called the thermodynamic limit. In effect, the molecular nature of matter and the quantal nature of momentum transfer have vanished from sight, too small to see. According to Buchdahl: "... there is no place within the strictly phenomenological theory for the idea of fluctuations about equilibrium (see, however, Section 76)."[60]
For a closed system at controlled constant temperature and volume, A is minimum at thermodynamic equilibrium.
"Self-Assembled Wiggling Nano-Structures and the Principle of Maximum Entropy Production"
Laws governing systems which are far from equilibrium are also debatable. One of the guiding principles for these systems is the maximum entropy production principle.[66][67] It states that a non-equilibrium system evolves such as to maximize its entropy production.[68][69]
Chapman, S., Cowling, T.G. (1939/1970). The Mathematical Theory of Non-uniform gases. An Account of the Kinetic Theory of Viscosity, Thermal Conduction and Diffusion in Gases, third edition 1970, Cambridge University Press, London.
ter Haar, D., Wergeland, H. (1966). Elements of Thermodynamics, Addison-Wesley Publishing, Reading MA.
When a body of material starts from a non-equilibrium state of inhomogeneity or chemical non-equilibrium, and is then isolated, it spontaneously evolves towards its own internal state of thermodynamic equilibrium. It is not necessary that all aspects of internal thermodynamic equilibrium be reached simultaneously; some can be established before others. For example, in many cases of such evolution, internal mechanical equilibrium is established much more rapidly than the other aspects of the eventual thermodynamic equilibrium.[55] Another example is that, in many cases of such evolution, thermal equilibrium is reached much more rapidly than chemical equilibrium.[58]
Thermal equilibrium is achieved when two systems in thermal contact with each other cease to have a net exchange of energy. It follows that if two systems are in thermal equilibrium, then their temperatures are the same.[62]
Verkley, W.T.M.; Gerkema, T. (2004). "On maximum entropy profiles". J. Atmos. Sci. 61 (8): 931–936. Bibcode:2004JAtS...61..931V. doi:10.1175/1520-0469(2004)0612.0.co;2.
⟨Hkin⟩=⟨p22m⟩=⟨12mv2⟩=32kBT.{\displaystyle \langle H_{\mathrm {kin} }\rangle =\left\langle {\frac {p^{2}}{2m}}\right\rangle =\langle {\tfrac {1}{2}}mv^{2}\rangle ={\tfrac {3}{2}}k_{\text{B}}T.}
⟨Hkin⟩=12m⟨px2+py2+pz2⟩=12(⟨px∂Hkin∂px⟩+⟨py∂Hkin∂py⟩+⟨pz∂Hkin∂pz⟩)=32kBT{\displaystyle {\begin{aligned}\langle H^{\mathrm {kin} }\rangle &={\frac {1}{2m}}\langle p_{x}^{2}+p_{y}^{2}+p_{z}^{2}\rangle \\&={\frac {1}{2}}\left(\left\langle p_{x}{\frac {\partial H^{\mathrm {kin} }}{\partial p_{x}}}\right\rangle +\left\langle p_{y}{\frac {\partial H^{\mathrm {kin} }}{\partial p_{y}}}\right\rangle +\left\langle p_{z}{\frac {\partial H^{\mathrm {kin} }}{\partial p_{z}}}\right\rangle \right)={\frac {3}{2}}k_{\text{B}}T\end{aligned}}}
yields a minimum mass for stellar contraction, the Jeans mass MJ
⟨r⋅dvdt⟩+1τ⟨r⋅v⟩=0{\displaystyle \left\langle \mathbf {r} \cdot {\frac {d\mathbf {v} }{dt}}\right\rangle +{\frac {1}{\tau }}\langle \mathbf {r} \cdot \mathbf {v} \rangle =0}
Since ΔE is very small, the following integrations are equivalent
where v and p = mv denote the velocity and momentum of the oscillator. Combining these terms yields the total energy[8]
A commonly cited counter-example where energy is not shared among its various forms and where equipartition does not hold in the microcanonical ensemble is a system of coupled harmonic oscillators.[49] If the system is isolated from the rest of the world, the energy in each normal mode is constant; energy is not transferred from one mode to another. Hence, equipartition does not hold for such a system; the amount of energy in each normal mode is fixed at its initial value. If sufficiently strong nonlinear terms are present in the energy function, energy may be transferred between the normal modes, leading to ergodicity and rendering the law of equipartition valid. However, the Kolmogorov–Arnold–Moser theorem states that energy will not be exchanged unless the nonlinear perturbations are strong enough; if they are too small, the energy will remain trapped in at least some of the modes.
"On the physics of media that are composed of free and elastic molecules in a state of motion"
Reichl, LE (1998). A Modern Course in Statistical Physics (2nd ed.). Wiley Interscience. pp. 326–333. ISBN 978-0-471-59520-5.
However, on long time scales, with t ≫ τ, the exponential and constant terms are negligible, and the squared distance grows only linearly:
Goldstein, H (1980). Classical Mechanics (2nd. ed.). Addison-Wesley. ISBN 0-201-02918-9.
In the microcanonical ensemble, the system is isolated from the rest of the world, or at least very weakly coupled to it.[9] Hence, its total energy is effectively constant; to be definite, we say that the total energy H is confined between E and E+dE. For a given energy E and spread dE, there is a region of phase space Σ in which the system has that energy, and the probability of each state in that region of phase space is equal, by the definition of the microcanonical ensemble. Given these definitions, the equipartition average of phase-space variables xm (which could be either qk or pk) and xn is given by
N∫e−βH(p,q)xk∂H∂xkdΓ=⟨xk∂H∂xk⟩=1β=kBT.{\displaystyle {\mathcal {N}}\int e^{-\beta H(p,q)}x_{k}{\frac {\partial H}{\partial x_{k}}}\,d\Gamma =\left\langle x_{k}{\frac {\partial H}{\partial x_{k}}}\right\rangle ={\frac {1}{\beta }}=k_{\text{B}}T.}
Boltzmann, L (1895). "On certain Questions of the Theory of Gases". Nature. 51 (1322): 413–415. Bibcode:1895Natur..51..413B. doi:10.1038/051413b0. S2CID 4037658.
for the average kinetic energy per particle, the equipartition theorem can be used to derive the ideal gas law from classical mechanics.[5] If q = (qx, qy, qz) and p = (px, py, pz) denote the position vector and momentum of a particle in the gas, andF is the net force on that particle, then
^ a b Kittel, C (1996). Introduction to Solid State Physics. New York: John Wiley and Sons. pp. 151–156. ISBN 978-0-471-11181-8.
Khinchin, AI (1949). Mathematical Foundations of Statistical Mechanics (G. Gamow, translator). New York: Dover Publications. pp. 93–98. ISBN 0-486-63896-0.
Eucken, A (1912). "Die Molekularwärme des Wasserstoffs bei tiefen Temperaturen (The molecular specific heat of hydrogen at low temperatures)". Sitzungsberichte der Königlich Preussischen Akademie der Wissenschaften (in German). 1912: 141–151.
More generally, the equipartition theorem states that any degree of freedom x which appears in the total energy H only as a simple quadratic term Ax2, where A is a constant, has an average energy of 1⁄2kBT in thermal equilibrium. In this case the equipartition theorem may be derived from the partition function Z(β), where β = 1/(kBT) is the canonical inverse temperature.[47] Integration over the variable x yields a factor
where the ellipses represent the integrand. From this, it follows that Σ is proportional to ΔE
^ a b c d e f g h i
^ Carroll, Bradley W.; Ostlie, Dale A. (1996). An Introduction to Modern Stellar Astrophysics. Reading, MA: Addison–Wesley. ISBN 0-201-59880-9.
^ Noyes, RW (1982). The Sun, Our Star. Cambridge, MA: Harvard University Press. ISBN 0-674-85435-7.
McQuarrie, DA (2000). Statistical Mechanics (revised 2nd ed.). University Science Books. pp. 91–128. ISBN 978-1-891389-15-3.
where the angular brackets ⟨…⟩{\displaystyle \left\langle \ldots \right\rangle } denote the average of the enclosed quantity,[9]
On small time scales, with t ≪ τ, the particle acts as a freely moving particle: by the Taylor series of the exponential function, the squared distance grows approximately quadratically:
Hermann, Armin (1971). The Genesis of Quantum Theory (1899–1913) (original title: Frühgeschichte der Quantentheorie (1899–1913), translated by Claude W. Nash ed.). Cambridge, MA: The MIT Press. pp. 124–145. ISBN 0-262-08047-8. LCCN 73151106.
McQuarrie, DA (2000). Statistical Mechanics (revised 2nd ed.). University Science Books. pp. 121–128. ISBN 978-1-891389-15-3.
In this expression, ΔE is assumed to be very small, ΔE ≪ E. Similarly, Ω(E) is defined to be the total volume of phase space where the energy is less than E:
Mason, M; Weaver W (1924). "The Settling of Small Particles in a Fluid". Physical Review. 23 (3): 412–426. Bibcode:1924PhRv...23..412M. doi:10.1103/PhysRev.23.412.
As stated by the equipartition theorem. The same result can also be obtained by averaging the particle energy using the probability of finding the particle in certain quantum energy state.[35]
The same formulae may be applied to determining the conditions for star formation in giant molecular clouds.[44] A local fluctuation in the density of such a cloud can lead to a runaway condition in which the cloud collapses inwards under its own gravity. Such a collapse occurs when the equipartition theorem—or, equivalently, the virial theorem—is no longer valid, i.e., when the gravitational potential energy exceeds twice the kinetic energy
^ a b c Goldstein, H (1980). Classical Mechanics (2nd. ed.). Addison-Wesley. ISBN 0-201-02918-9.
Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Equipartition theorem" – news · newspapers · books · scholar · JSTOR
"A General Theory of Energy Partition with Applications to Quantum Theory"
The most general form of the equipartition theorem states that under suitable assumptions (discussed below), for a physical system with Hamiltonian energy function H and degrees of freedom xn, the following equipartition formula holds in thermal equilibrium for all indices m and n:[5][9][12]
⟨∑kqk∂H∂qk⟩=⟨∑kpk∂H∂pk⟩=⟨∑kpkdqkdt⟩=−⟨∑kqkdpkdt⟩,{\displaystyle \left\langle \sum _{k}q_{k}{\frac {\partial H}{\partial q_{k}}}\right\rangle =\left\langle \sum _{k}p_{k}{\frac {\partial H}{\partial p_{k}}}\right\rangle =\left\langle \sum _{k}p_{k}{\frac {dq_{k}}{dt}}\right\rangle =-\left\langle \sum _{k}q_{k}{\frac {dp_{k}}{dt}}\right\rangle ,}
where dV is an infinitesimal volume within the container and V is the total volume of the container.
The original formulation of the equipartition theorem states that, in any physical system in thermal equilibrium, every particle has exactly the same average translational kinetic energy, 3/2kBT.[46] However, this is true only for ideal gas, and the same result can be derived from the Maxwell–Boltzmann distribution. First, we choose to consider only the Maxwell–Boltzmann distribution of velocity of the z-component
^ a b c d e f g h i Huang, K (1987). Statistical Mechanics (2nd ed.). John Wiley and Sons. pp. 136–138. ISBN 0-471-81518-7.
Although the equipartition theorem makes accurate predictions in certain conditions, it is inaccurate when quantum effects are significant, such as at low temperatures.When the thermal energy kBT is smaller than the quantum energy spacing in a particular degree of freedom, the average energy and heat capacity of this degree of freedom are less than the values predicted by equipartition. Such a degree of freedom is said to be "frozen out" when the thermal energy is much smaller than this spacing. For example, the heat capacity of a solid decreases at low temperatures as various types of motion become frozen out, rather than remaining constant as predicted by equipartition. Such decreases in heat capacity were among the first signs to physicists of the 19th century that classical physics was incorrect and that a new, more subtle, scientific model was required. Along with other evidence, equipartition's failure to model black-body radiation—also known as the ultraviolet catastrophe—led Max Planck to suggest that energy in the oscillators in an object, which emit light, were quantized, a revolutionary hypothesis that spurred the development of quantum mechanics and quantum field theory.
A third discrepancy concerned the specific heat of metals.[26] According to the classical Drude model, metallic electrons act as a nearly ideal gas, and so they should contribute 3/2 NekB to the heat capacity by the equipartition theorem, where Ne is the number of electrons. Experimentally, however, electrons contribute little to the heat capacity: the molar heat capacities of many conductors and insulators are nearly the same.[26]
Several explanations of equipartition's failure to account for molar heat capacities were proposed. Boltzmann defended the derivation of his equipartition theorem as correct, but suggested that gases might not be in thermal equilibrium because of their interactions with the aether.[27] Lord Kelvin suggested that the derivation of the equipartition theorem must be incorrect, since it disagreed with experiment, but was unable to show how.[28] In 1900 Lord Rayleigh instead put forward a more radical view that the equipartition theorem and the experimental assumption of thermal equilibrium were both correct; to reconcile them, he noted the need for a new principle that would provide an "escape from the destructive simplicity" of the equipartition theorem.[29] Albert Einstein provided that escape, by showing in 1906 that these anomalies in the specific heat were due to quantum effects, specifically the quantization of energy in the elastic modes of the solid.[30] Einstein used the failure of equipartition to argue for the need of a new quantum theory of matter.[11] Nernst's 1910 measurements of specific heats at low temperatures[31] supported Einstein's theory, and led to the widespread acceptance of quantum theory among physicists.[32]
where ω1, ω2, and ω3 are the principal components of the angular velocity. By exactly the same reasoning as in the translational case, equipartition implies that in thermal equilibrium the average rotational energy of each particle is 3/2kBT. Similarly, the equipartition theorem allows the average (more precisely, the root mean square) angular speed of the molecules to be calculated.[5]
Dewar, J (1872). "The Specific Heat of Carbon at High Temperatures". Philosophical Magazine. 44: 461.Weber, HF (1872). "Die specifische Wärme des Kohlenstoffs (The specific heat of carbon)". Annalen der Physik (in German). 147 (10): 311–319. Bibcode:1872AnP...223..311W. doi:10.1002/andp.18722231007.Weber, HF (1875). "Die specifische Wärmen der Elemente Kohlenstoff, Bor und Silicium (The specific heats of elemental carbon, boron, and silicon)". Annalen der Physik (in German). 154 (3): 367–423, 553–582. Bibcode:1875AnP...230..367W. doi:10.1002/andp.18752300307.
kBT=⟨q∂Hpot∂q⟩=∑n=2∞⟨q⋅nCnqn−1⟩=∑n=2∞nCn⟨qn⟩.{\displaystyle k_{\text{B}}T=\left\langle q{\frac {\partial H_{\mathrm {pot} }}{\partial q}}\right\rangle =\sum _{n=2}^{\infty }\langle q\cdot nC_{n}q^{n-1}\rangle =\sum _{n=2}^{\infty }nC_{n}\langle q^{n}\rangle .}
where the first equality is Newton's second law, and the second line uses Hamilton's equations and the equipartition formula. Summing over a system of N particles yields
⟨Hx⟩=−∂log⁡Zx∂β=12β=12kBT{\displaystyle \langle H_{x}\rangle =-{\frac {\partial \log Z_{x}}{\partial \beta }}={\frac {1}{2\beta }}={\frac {1}{2}}k_{\text{B}}T}
∫H<Exm∂(H−E)∂xndΓ=∫H<E∂∂xn(xm(H−E))dΓ−∫H<Eδmn(H−E)dΓ=δmn∫H<E(E−H)dΓ,{\displaystyle {\begin{aligned}\int _{H<E}x_{m}{\frac {\partial (H-E)}{\partial x_{n}}}\,d\Gamma &=\int _{H<E}{\frac {\partial }{\partial x_{n}}}{\bigl (}x_{m}(H-E){\bigr )}\,d\Gamma -\int _{H<E}\delta _{mn}(H-E)d\Gamma \\&=\delta _{mn}\int _{H<E}(E-H)\,d\Gamma ,\end{aligned}}}
⟨xm∂H∂xn⟩=δmn1ρ∂∂E∫H<E(E−H)dΓ=δmn1ρ∫H<EdΓ=δmnΩρ.{\displaystyle \left\langle x_{m}{\frac {\partial H}{\partial x_{n}}}\right\rangle =\delta _{mn}{\frac {1}{\rho }}\,{\frac {\partial }{\partial E}}\int _{H<E}\left(E-H\right)\,d\Gamma =\delta _{mn}{\frac {1}{\rho }}\,\int _{H<E}\,d\Gamma =\delta _{mn}{\frac {\Omega }{\rho }}.}
The general equipartition theorem holds in both the microcanonical ensemble,[9] when the total energy of the system is constant, and also in the canonical ensemble,[5][33] when the system is coupled to a heat bath with which it can exchange energy. Derivations of the general formula are given later in the article.
At high temperatures, when the thermal energy kBT is much greater than the spacing hν between energy levels, the exponential argument βhν is much less than one and the average energy becomes kBT, in agreement with the equipartition theorem (Figure 10). However, at low temperatures, when hν ≫ kBT, the average energy goes to zero—the higher-frequency energy levels are "frozen out" (Figure 10). As another example, the internal excited electronic states of a hydrogen atom do not contribute to its specific heat as a gas at room temperature, since the thermal energy kBT (roughly 0.025 eV) is much smaller than the spacing between the lowest and next higher electronic energy levels (roughly 10 eV).
where vx, vy and vz are the Cartesian components of the velocity v. Here, H is short for Hamiltonian, and used henceforth as a symbol for energy because the Hamiltonian formalism plays a central role in the most general form of the equipartition theorem.
⟨xm∂H∂xn⟩=0for all m≠n.{\displaystyle \left\langle x_{m}{\frac {\partial H}{\partial x_{n}}}\right\rangle =0\quad {\text{for all }}m\neq n.}
Boltzmann, L (1876). "Über die Natur der Gasmoleküle (On the nature of gas molecules)". Wiener Berichte (in German). 74: 553–560.
"Recherches sur quelques points importants de la théorie de la chaleur (Studies on key points in the theory of heat)"
Mohling, F (1982). Statistical Mechanics: Methods and Applications. John Wiley and Sons. pp. 137–139, 270–273, 280, 285–292. ISBN 0-470-27340-2.
Potential energies are not always quadratic in the position. However, the equipartition theorem also shows that if a degree of freedom x contributes only a multiple of xs (for a fixed real number s) to the energy, then in thermal equilibrium the average energy of that part is kBT/s.
⟨H⟩=hνe−βhν1−e−βhν.{\displaystyle \langle H\rangle =h\nu {\frac {e^{-\beta h\nu }}{1-e^{-\beta h\nu }}}.}
where p1 and p2 are the momenta of the two atoms, and q is the deviation of the inter-atomic separation from its equilibrium value. Every degree of freedom in the energy is quadratic and, thus, should contribute 1⁄2kBT to the total average energy, and 1⁄2kB to the heat capacity. Therefore, the heat capacity of a gas of N diatomic molecules is predicted to be 7N·1⁄2kB: the momenta p1 and p2 contribute three degrees of freedom each, and the extension q contributes the seventh. It follows that the heat capacity of a mole of diatomic molecules with no other degrees of freedom should be 7/2NAkB = 7/2R and, thus, the predicted molar heat capacity should be roughly 7 cal/(mol·K). However, the experimental values for molar heat capacities of diatomic gases are typically about 5 cal/(mol·K)[23] and fall to 3 cal/(mol·K) at very low temperatures.[24] This disagreement between the equipartition prediction and the experimental value of the molar heat capacity cannot be explained by using a more complex model of the molecule, since adding more degrees of freedom can only increase the predicted specific heat, not decrease it.[25] This discrepancy was a key piece of evidence showing the need for a quantum theory of matter.
ddt(r⋅v)=v2+r⋅dvdt,{\displaystyle {\frac {d}{dt}}\left(\mathbf {r} \cdot \mathbf {v} \right)=v^{2}+\mathbf {r} \cdot {\frac {d\mathbf {v} }{dt}},}
Other, more subtle quantum effects can lead to corrections to equipartition, such as identical particles and continuous symmetries. The effects of identical particles can be dominant at very high densities and low temperatures. For example, the valence electrons in a metal can have a mean kinetic energy of a few electronvolts, which would normally correspond to a temperature of tens of thousands of kelvins. Such a state, in which the density is high enough that the Pauli exclusion principle invalidates the classical approach, is called a degenerate fermion gas. Such gases are important for the structure of white dwarf and neutron stars.[citation needed] At low temperatures, a fermionic analogue of the Bose–Einstein condensate (in which a large number of identical particles occupy the lowest-energy state) can form; such superfluid electrons are responsible[dubious– discuss] for superconductivity.
The first term is usually zero, either because xk is zero at the limits, or because the energy goes to infinity at those limits. In that case, the equipartition theorem for the canonical ensemble follows immediately
⟨qj∂H∂pk⟩=⟨pj∂H∂qk⟩=0 for all j,k{\displaystyle \left\langle q_{j}{\frac {\partial H}{\partial p_{k}}}\right\rangle =\left\langle p_{j}{\frac {\partial H}{\partial q_{k}}}\right\rangle =0\quad {\text{ for all }}\,j,k}
P∮surfaceq⋅dS=P∫volume(∇⋅q)dV=3PV,{\displaystyle P\oint _{\mathrm {surface} }\mathbf {q} \cdot \mathbf {dS} =P\int _{\mathrm {volume} }\left({\boldsymbol {\nabla }}\cdot \mathbf {q} \right)\,dV=3PV,}
^ Miedl M, Garcia M, Bamforth C (2005). "Haze formation in model beer systems". J. Agric. Food Chem. 53 (26): 10161–5. doi:10.1021/jf0506941. PMID 16366710.
Substitution of the mass and radius of the Sun yields an estimated solar temperature of T = 14 million kelvins, very close to its core temperature of 15 million kelvins. However, the Sun is much more complex than assumed by this model—both its temperature and density vary strongly with radius—and such excellent agreement (≈7% relative error) is partly fortuitous.[43]
where t denotes time.[8] Two key differences are that the virial theorem relates summed rather than individual averages to each other, and it does not connect them to the temperature T. Another difference is that traditional derivations of the virial theorem use averages over time, whereas those of the equipartition theorem use averages over phase space.
where n = N/NA is the number of moles of gas and R = NAkB is the gas constant. Although equipartition provides a simple derivation of the ideal-gas law and the internal energy, the same results can be obtained by an alternative method using the partition function.[35]
"Quelques recherches sur la chaleur spécifique (Some research on specific heat)"
N∫e−βH(p,q)dΓ=N∫d[xke−βH(p,q)]dΓk−N∫xk∂e−βH(p,q)∂xkdΓ,{\displaystyle {\mathcal {N}}\int e^{-\beta H(p,q)}d\Gamma ={\mathcal {N}}\int d[x_{k}e^{-\beta H(p,q)}]d\Gamma _{k}-{\mathcal {N}}\int x_{k}{\frac {\partial e^{-\beta H(p,q)}}{\partial x_{k}}}d\Gamma ,}
The equipartition of kinetic energy was proposed initially in 1843, and more correctly in 1845, by John James Waterston.[15] In 1859, James Clerk Maxwell argued that the kinetic heat energy of a gas is equally divided between linear and rotational energy.[16] In 1876, Ludwig Boltzmann expanded on this principle by showing that the average energy was divided equally among all the independent components of motion in a system.[17][18] Boltzmann applied the equipartition theorem to provide a theoretical explanation of the Dulong–Petit law for the specific heat capacities of solids.
The equipartition theorem in stellar physics, written by Nir J. Shaviv, an associate professor at the Racah Institute of Physics in the Hebrew University of Jerusalem.
does not allow the average potential energy to be written in terms of known constants.
^ Fact Sheet on Uranium Enrichment U.S. Nuclear Regulatory Commission. Accessed 30 April 2007
Cantor, CR; Schimmel PR (1980). Biophysical Chemistry. Part II. Techniques for the study of biological structure and function. W. H. Freeman. ISBN 978-0-7167-1189-6.
Petit, AT; Dulong PL (1819). "Recherches sur quelques points importants de la théorie de la chaleur (Studies on key points in the theory of heat)". Annales de Chimie et de Physique (in French). 10: 395–413.
Mandl, F (1971). Statistical Physics. John Wiley and Sons. pp. 213–219. ISBN 0-471-56658-6.
which immediately implies the ideal gas law for N particles:
Brush, SG (1976). The Kind of Motion We Call Heat, Volume 1. Amsterdam: North Holland. pp. 134–159. ISBN 978-0-444-87009-4.Brush, SG (1976). The Kind of Motion We Call Heat, Volume 2. Amsterdam: North Holland. pp. 336–339. ISBN 978-0-444-87009-4.Waterston, JJ (1846). "On the physics of media that are composed of free and elastic molecules in a state of motion". Proc. R. Soc. Lond. 5: 604. doi:10.1098/rspl.1843.0077 (abstract only). Published in full Waterston, J. J.; Rayleigh, L. (1893). "On the Physics of Media that are Composed of Free and Perfectly Elastic Molecules in a State of Motion". Philosophical Transactions of the Royal Society. A183: 1–79. Bibcode:1892RSPTA.183....1W. doi:10.1098/rsta.1892.0001. Reprinted J.S. Haldane, ed. (1928). The collected scientific papers of John James Waterston. Edinburgh: Oliver & Boyd.Waterston, JJ (1843). Thoughts on the Mental Functions. (reprinted in his Papers, 3, 167, 183.)Waterston, JJ (1851). British Association Reports. 21: 6. {{cite journal}}: Missing or empty |title= (help)Waterston's key paper was written and submitted in 1845 to the Royal Society. After refusing to publish his work, the Society also refused to return his manuscript and stored it among its files. The manuscript was discovered in 1891 by Lord Rayleigh, who criticized the original reviewer for failing to recognize the significance of Waterston's work. Waterston managed to publish his ideas in 1851, and therefore has priority over Maxwell for enunciating the first version of the equipartition theorem.
the basic equation for Brownian motion can be transformed into
The mean kinetic energy also allows the root mean square speed vrms of the gas particles to be calculated:
where β = 1/(kBT). Using Integration by parts for a phase-space variable xk the above can be written as
In contrast to the other examples cited here, the equipartition formula
Experimental observations of the specific heat capacities of gases also raised concerns about the validity of the equipartition theorem. The theorem predicts that the molar heat capacity of simple monatomic gases should be roughly 3 cal/(mol·K), whereas that of diatomic gases should be roughly 7 cal/(mol·K). Experiments confirmed the former prediction,[3] but found that molar heat capacities of diatomic gases were typically about 5 cal/(mol·K),[23] and fell to about 3 cal/(mol·K) at very low temperatures.[24] Maxwell noted in 1875 that the disagreement between experiment and the equipartition theorem was much worse than even these numbers suggest;[25] since atoms have internal parts, heat energy should go into the motion of these internal parts, making the predicted specific heats of monatomic and diatomic gases much higher than 3 cal/(mol·K) and 7 cal/(mol·K), respectively.
⟨xn∂H∂xn⟩=kBTfor all n{\displaystyle \left\langle x_{n}{\frac {\partial H}{\partial x_{n}}}\right\rangle =k_{\text{B}}T\quad {\text{for all }}n}
Ideal gases provide an important application of the equipartition theorem. As well as providing the formula
6Limitations											Toggle Limitations subsection																					6.1Requirement of ergodicity																											6.2Failure due to quantum effects
In the canonical ensemble, the system is in thermal equilibrium with an infinite heat bath at temperature T (in kelvins).[5][33] The probability of each state in phase space is given by its Boltzmann factor times a normalization factor N{\displaystyle {\mathcal {N}}}, which is chosen so that the probabilities sum to one
^ Jeans, JH (1902). "The Stability of a Spherical Nebula". Philosophical Transactions of the Royal Society A. 199 (312–320): 1–53. Bibcode:1902RSPTA.199....1J. doi:10.1098/rsta.1902.0012.
Fact Sheet on Uranium Enrichment U.S. Nuclear Regulatory Commission. Accessed 30 April 2007
1Basic concept and simple examples											Toggle Basic concept and simple examples subsection																					1.1Translational energy and ideal gases																											1.2Rotational energy and molecular tumbling in solution																											1.3Potential energy and harmonic oscillators																											1.4Specific heat capacity of solids																											1.5Sedimentation of particles
McQuarrie, DA (2000). Statistical Mechanics (revised 2nd ed.). University Science Books. pp. 254–264. ISBN 978-1-891389-15-3.
3NkBT=−⟨∑k=1Nqk⋅Fk⟩=3PV,{\displaystyle 3Nk_{\text{B}}T=-\left\langle \sum _{k=1}^{N}\mathbf {q} _{k}\cdot \mathbf {F} _{k}\right\rangle =3PV,}
Many other physical systems can be modeled as sets of coupled oscillators. The motions of such oscillators can be decomposed into normal modes, like the vibrational modes of a piano string or the resonances of an organ pipe. On the other hand, equipartition often breaks down for such systems, because there is no exchange of energy between the normal modes. In an extreme situation, the modes are independent and so their energies are independently conserved. This shows that some sort of mixing of energies, formally called ergodicity, is important for the law of equipartition to hold.
"Elementare Betrachtungen über die thermische Molekularbewegung in festen Körpern (Elementary observations on the thermal movements of molecules in solids)"
The average temperature of a star can be estimated from the equipartition theorem.[42] Since most stars are spherically symmetric, the total gravitational potential energy can be estimated by integration
where β = 1/kBT and the denominator Z is the partition function, here a geometric series
^ Chiu, H-Y (1968). Stellar Physics, volume I. Waltham, MA: Blaisdell Publishing. LCCN 67017990.
Tolman, RC (1927). Statistical Mechanics, with Applications to Physics and Chemistry. Chemical Catalog Company. pp. 76–77.
It follows that the heat capacity of the gas is 3/2 N kB and hence, in particular, the heat capacity of a mole of such gas particles is 3/2NAkB = 3/2R, where NA is the Avogadro constant and R is the gas constant. Since R ≈ 2 cal/(mol·K), equipartition predicts that the molar heat capacity of an ideal gas is roughly 3 cal/(mol·K). This prediction is confirmed by experiment when compared to monatomic gases.[3]
Here δmn is the Kronecker delta, which is equal to one if m = n and is zero otherwise. The averaging brackets ⟨…⟩{\displaystyle \left\langle \ldots \right\rangle } is assumed to be an ensemble average over phase space or, under an assumption of ergodicity, a time average of a single system.
^ Collins, GW (1978). The Virial Theorem in Stellar Astrophysics. Pachart Press.
d2dt2⟨r2⟩+1τddt⟨r2⟩=2⟨v2⟩=6mkBT,{\displaystyle {\frac {d^{2}}{dt^{2}}}\langle r^{2}\rangle +{\frac {1}{\tau }}{\frac {d}{dt}}\langle r^{2}\rangle =2\langle v^{2}\rangle ={\frac {6}{m}}k_{\text{B}}T,}
^ Rayleigh, JWS (1900). "The Law of Partition of Kinetic Energy". Philosophical Magazine. 49 (296): 98–118. doi:10.1080/14786440009463826.
^ Rayleigh, JWS (1900). "Remarks upon the Law of Complete Radiation". Philosophical Magazine. 49: 539–540. Bibcode:1900PMag...49..539R. doi:10.1080/14786440009463878.
A diatomic gas can be modelled as two masses, m1 and m2, joined by a spring of stiffness a, which is called the rigid rotor-harmonic oscillator approximation.[19] The classical energy of this system is
Jeans, JH (1902). "The Stability of a Spherical Nebula". Philosophical Transactions of the Royal Society A. 199 (312–320): 1–53. Bibcode:1902RSPTA.199....1J. doi:10.1098/rsta.1902.0012.
Since the kinetic energy is quadratic in the components of the velocity, by equipartition these three components each contribute 1⁄2kBT to the average kinetic energy in thermal equilibrium. Thus the average kinetic energy of the particle is 3/2kBT, as in the example of noble gases above.
Equipartition therefore implies that in thermal equilibrium, the oscillator has average energy
⟨hpot⟩=∫0∞4πr2ρU(r)g(r)dr.{\displaystyle \langle h_{\mathrm {pot} }\rangle =\int _{0}^{\infty }4\pi r^{2}\rho U(r)g(r)\,dr.}
.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}"equi-". Online Etymology Dictionary. Retrieved 2008-12-20.
1T=∂S∂E=kB∂log⁡Ω∂E=kB1Ω∂Ω∂E.{\displaystyle {\frac {1}{T}}={\frac {\partial S}{\partial E}}=k_{\text{B}}{\frac {\partial \log \Omega }{\partial E}}=k_{\text{B}}{\frac {1}{\Omega }}\,{\frac {\partial \Omega }{\partial E}}.}
A similar argument,[5] can be used to derive the pressure equation
H=⟨Hkin⟩+⟨Hpot⟩=32NkBT+2πNρ∫0∞r2U(r)g(r)dr.{\displaystyle H=\langle H_{\mathrm {kin} }\rangle +\langle H_{\mathrm {pot} }\rangle ={\frac {3}{2}}Nk_{\text{B}}T+2\pi N\rho \int _{0}^{\infty }r^{2}U(r)g(r)\,dr.}
^ Brush, SG (1976). The Kind of Motion We Call Heat, Volume 1. Amsterdam: North Holland. pp. 134–159. ISBN 978-0-444-87009-4.Brush, SG (1976). The Kind of Motion We Call Heat, Volume 2. Amsterdam: North Holland. pp. 336–339. ISBN 978-0-444-87009-4.Waterston, JJ (1846). "On the physics of media that are composed of free and elastic molecules in a state of motion". Proc. R. Soc. Lond. 5: 604. doi:10.1098/rspl.1843.0077 (abstract only). Published in full Waterston, J. J.; Rayleigh, L. (1893). "On the Physics of Media that are Composed of Free and Perfectly Elastic Molecules in a State of Motion". Philosophical Transactions of the Royal Society. A183: 1–79. Bibcode:1892RSPTA.183....1W. doi:10.1098/rsta.1892.0001. Reprinted J.S. Haldane, ed. (1928). The collected scientific papers of John James Waterston. Edinburgh: Oliver & Boyd.Waterston, JJ (1843). Thoughts on the Mental Functions. (reprinted in his Papers, 3, 167, 183.)Waterston, JJ (1851). British Association Reports. 21: 6. {{cite journal}}: Missing or empty |title= (help)Waterston's key paper was written and submitted in 1845 to the Royal Society. After refusing to publish his work, the Society also refused to return his manuscript and stored it among its files. The manuscript was discovered in 1891 by Lord Rayleigh, who criticized the original reviewer for failing to recognize the significance of Waterston's work. Waterston managed to publish his ideas in 1851, and therefore has priority over Maxwell for enunciating the first version of the equipartition theorem.
Thomson, W (1904). Baltimore Lectures. Baltimore: Johns Hopkins University Press. Sec. 27. ISBN 0-8391-1022-7. Re-issued in 1987 by MIT Press as Kelvin's Baltimore Lectures and Modern Theoretical Physics: Historical and Philosophical Perspectives (Robert Kargon and Peter Achinstein, editors). ISBN 978-0-262-11117-1
⟨xm∂H∂xn⟩=1Σ∫H∈[E,E+ΔE]xm∂H∂xndΓ=ΔEΣ∂∂E∫H<Exm∂H∂xndΓ=1ρ∂∂E∫H<Exm∂(H−E)∂xndΓ,{\displaystyle {\begin{aligned}\left\langle x_{m}{\frac {\partial H}{\partial x_{n}}}\right\rangle &={\frac {1}{\Sigma }}\,\int _{H\in \left[E,E+\Delta E\right]}x_{m}{\frac {\partial H}{\partial x_{n}}}\,d\Gamma \\&={\frac {\Delta E}{\Sigma }}\,{\frac {\partial }{\partial E}}\int _{H<E}x_{m}{\frac {\partial H}{\partial x_{n}}}\,d\Gamma \\&={\frac {1}{\rho }}\,{\frac {\partial }{\partial E}}\int _{H<E}x_{m}{\frac {\partial \left(H-E\right)}{\partial x_{n}}}\,d\Gamma ,\end{aligned}}}
More generally, a typical energy function of a one-dimensional system has a Taylor expansion in the extension q:
^ Clausius, R (1870). "Ueber einen auf die Wärme anwendbaren mechanischen Satz". Annalen der Physik (in German). 141 (9): 124–130. Bibcode:1870AnP...217..124C. doi:10.1002/andp.18702170911.Clausius, RJE (1870). "On a Mechanical Theorem Applicable to Heat". Philosophical Magazine. Series 4. 40: 122–127.
⟨H⟩=⟨Hkin⟩+⟨Hpot⟩=12kBT+12kBT=kBT,{\displaystyle \langle H\rangle =\langle H_{\text{kin}}\rangle +\langle H_{\text{pot}}\rangle ={\tfrac {1}{2}}k_{\text{B}}T+{\tfrac {1}{2}}k_{\text{B}}T=k_{\text{B}}T,}
"On the Physics of Media that are Composed of Free and Perfectly Elastic Molecules in a State of Motion"
Taking the derivative of H with respect to the px momentum component gives the formula
⟨qj∂H∂qk⟩=⟨pj∂H∂pk⟩=0 for all j≠k.{\displaystyle \left\langle q_{j}{\frac {\partial H}{\partial q_{k}}}\right\rangle =\left\langle p_{j}{\frac {\partial H}{\partial p_{k}}}\right\rangle =0\quad {\text{ for all }}\,j\neq k.}
^ Boltzmann, L (1876). "Über die Natur der Gasmoleküle (On the nature of gas molecules)". Wiener Berichte (in German). 74: 553–560.
∇⋅q=∂qx∂qx+∂qy∂qy+∂qz∂qz=3,{\displaystyle {\boldsymbol {\nabla }}\cdot \mathbf {q} ={\frac {\partial q_{x}}{\partial q_{x}}}+{\frac {\partial q_{y}}{\partial q_{y}}}+{\frac {\partial q_{z}}{\partial q_{z}}}=3,}
^ Boltzmann, L (1871). "Einige allgemeine Sätze über Wärmegleichgewicht (Some general statements on thermal equilibrium)". Wiener Berichte (in German). 63: 679–711. In this preliminary work, Boltzmann showed that the average total kinetic energy equals the average total potential energy when a system is acted upon by external harmonic forces.
where M = NAm is the mass of a mole of gas particles. This result is useful for many applications such as Graham's law of effusion, which provides a method for enriching uranium.[4]
Since ρ=∂Ω∂E{\displaystyle \rho ={\frac {\partial \Omega }{\partial E}}} the equipartition theorem follows:
Maxwell, JC (1890). "On the Dynamical Evidence of the Molecular Constitution of Bodies".In WD Niven (ed.). The Scientific Papers of James Clerk Maxwell. Cambridge: At the University Press. Vol.2, pp.418–438. ISBN 0-486-61534-0. ASIN B000GW7DXY. A lecture delivered by Prof. Maxwell at the Chemical Society on 18 February 1875.
"Berichtigung zu meiner Arbeit: 'Die Plancksche Theorie der Strahlung und die Theorie der spezifischen Wärme' (Correction to previous article)"
^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}"equi-". Online Etymology Dictionary. Retrieved 2008-12-20.
An important application of the equipartition theorem is to the specific heat capacity of a crystalline solid. Each atom in such a solid can oscillate in three independent directions, so the solid can be viewed as a system of 3N independent simple harmonic oscillators, where N denotes the number of atoms in the lattice. Since each harmonic oscillator has average energy kBT, the average total energy of the solid is 3N kBT, and its heat capacity is 3N kB.
Callen, HB (1985). Thermodynamics and an Introduction to Thermostatistics. New York: John Wiley and Sons. pp. 375–377. ISBN 0-471-86256-8.
3General formulation of the equipartition theorem											Toggle General formulation of the equipartition theorem subsection																					3.1Relation to the virial theorem
The law of equipartition breaks down when the thermal energy kBT is significantly smaller than the spacing between energy levels. Equipartition no longer holds because it is a poor approximation to assume that the energy levels form a smooth continuum, which is required in the derivations of the equipartition theorem above.[5][9] Historically, the failures of the classical equipartition theorem to explain specific heats and blackbody radiation were critical in showing the need for a new theory of matter and radiation, namely, quantum mechanics and quantum field theory.[11]
⟨pk∂H∂pk⟩=⟨qk∂H∂qk⟩=kBT.{\displaystyle \left\langle p_{k}{\frac {\partial H}{\partial p_{k}}}\right\rangle =\left\langle q_{k}{\frac {\partial H}{\partial q_{k}}}\right\rangle =k_{\text{B}}T.}
^ a b Tolman, RC (1918). "A General Theory of Energy Partition with Applications to Quantum Theory" (PDF). Physical Review. 11 (4): 261–275. Bibcode:1918PhRv...11..261T. doi:10.1103/PhysRev.11.261.
.mw-parser-output .sfrac{white-space:nowrap}.mw-parser-output .sfrac.tion,.mw-parser-output .sfrac .tion{display:inline-block;vertical-align:-0.5em;font-size:85%;text-align:center}.mw-parser-output .sfrac .num,.mw-parser-output .sfrac .den{display:block;line-height:1em;margin:0 0.1em}.mw-parser-output .sfrac .den{border-top:1px solid}.mw-parser-output .sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}3/2kBT
^ Nernst, W (1910). "Untersuchungen über die spezifische Wärme bei tiefen Temperaturen. II. (Investigations into the specific heat at low temperatures)". Sitzungsberichte der Königlich Preussischen Akademie der Wissenschaften (in German). 1910: 262–282.
Equipartition was used above to derive the classical ideal gas law from Newtonian mechanics. However, relativistic effects become dominant in some systems, such as white dwarfs and neutron stars,[9] and the ideal gas equations must be modified. The equipartition theorem provides a convenient way to derive the corresponding laws for an extreme relativistic ideal gas.[5] In such cases, the kinetic energy of a single particle is given by the formula
However, this law is inaccurate at lower temperatures, due to quantum effects; it is also inconsistent with the experimentally derived third law of thermodynamics, according to which the molar heat capacity of any substance must go to zero as the temperature goes to absolute zero.[10] A more accurate theory, incorporating quantum effects, was developed by Albert Einstein (1907) and Peter Debye (1911).[11]
^ Dewar, J (1872). "The Specific Heat of Carbon at High Temperatures". Philosophical Magazine. 44: 461.Weber, HF (1872). "Die specifische Wärme des Kohlenstoffs (The specific heat of carbon)". Annalen der Physik (in German). 147 (10): 311–319. Bibcode:1872AnP...223..311W. doi:10.1002/andp.18722231007.Weber, HF (1875). "Die specifische Wärmen der Elemente Kohlenstoff, Bor und Silicium (The specific heats of elemental carbon, boron, and silicon)". Annalen der Physik (in German). 154 (3): 367–423, 553–582. Bibcode:1875AnP...230..367W. doi:10.1002/andp.18752300307.
Miedl M, Garcia M, Bamforth C (2005). "Haze formation in model beer systems". J. Agric. Food Chem. 53 (26): 10161–5. doi:10.1021/jf0506941. PMID 16366710.
The equipartition theorem can be used to derive the Brownian motion of a particle from the Langevin equation.[5] According to that equation, the motion of a particle of mass m with velocity v is governed by Newton's second law
Pais, A (1982). Subtle is the Lord. Oxford University Press. ISBN 0-19-853907-X.
Wüller, A (1896). Lehrbuch der Experimentalphysik (Textbook of Experimental Physics) (in German). Leipzig: Teubner. Vol. 2, 507ff.
If a degree of freedom xn appears only as a quadratic term anxn2 in the Hamiltonian H, then the first of these formulae implies that
Using the equations of Hamiltonian mechanics,[8] these formulae may also be written
Einstein, A (1905). "Über einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt (A Heuristic Model of the Creation and Transformation of Light)". Annalen der Physik (in German). 17 (6): 132–148. Bibcode:1905AnP...322..132E. doi:10.1002/andp.19053220607.. An English translation is available from Wikisource.
where ρ(E) is the density of states. By the usual definitions of statistical mechanics, the entropy S equals kB log Ω(E), and the temperature T is defined by
^ Petit, AT; Dulong PL (1819). "Recherches sur quelques points importants de la théorie de la chaleur (Studies on key points in the theory of heat)". Annales de Chimie et de Physique (in French). 10: 395–413.
Equipartition applies to potential energies as well as kinetic energies: important examples include harmonic oscillators such as a spring, which has a quadratic potential energy
The name "equipartition" means "equal division," as derived from the Latin equi from the antecedent, æquus ("equal or even"), and partition from the noun, partitio ("division, portion").[1][2] The original concept of equipartition was that the total kinetic energy of a system is shared equally among all of its independent parts, on the average, once the system has reached thermal equilibrium. Equipartition also makes quantitative predictions for these energies. For example, it predicts that every atom of an inert noble gas, in thermal equilibrium at temperature T, has an average translational kinetic energy of 3/2kBT, where kB is the Boltzmann constant. As a consequence, since kinetic energy is equal to .mw-parser-output .frac{white-space:nowrap}.mw-parser-output .frac .num,.mw-parser-output .frac .den{font-size:80%;line-height:0;vertical-align:super}.mw-parser-output .frac .den{vertical-align:sub}.mw-parser-output .sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}1⁄2(mass)(velocity)2, the heavier atoms of xenon have a lower average speed than do the lighter atoms of helium at the same temperature. Figure 2 shows the Maxwell–Boltzmann distribution for the speeds of the atoms in four noble gases.
"Über einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt (A Heuristic Model of the Creation and Transformation of Light)"
where z is the height of the protein clump in the bottle and g is the acceleration due to gravity. Since s = 1, the average potential energy of a protein clump equals kBT. Hence, a protein clump with a buoyant mass of 10 MDa (roughly the size of a virus) would produce a haze with an average height of about 2 cm at equilibrium. The process of such sedimentation to equilibrium is described by the Mason–Weaver equation.[14]
Maxwell, JC (2003). "Illustrations of the Dynamical Theory of Gases".In WD Niven (ed.). The Scientific Papers of James Clerk Maxwell. New York: Dover. Vol.1, pp. 377–409. ISBN 978-0-486-49560-6. Read by Prof. Maxwell at a Meeting of the British Association at Aberdeen on 21 September 1859.
where the last equality follows because E is a constant that does not depend on xn. Integrating by parts yields the relation
The equipartition theorem and the related virial theorem have long been used as a tool in astrophysics.[39] As examples, the virial theorem may be used to estimate stellar temperatures or the Chandrasekhar limit on the mass of white dwarf stars.[40][41]
Collins, GW (1978). The Virial Theorem in Stellar Astrophysics. Pachart Press.
−⟨∑k=1Nqk⋅Fk⟩=P∮surfaceq⋅dS,{\displaystyle -\left\langle \sum _{k=1}^{N}\mathbf {q} _{k}\cdot \mathbf {F} _{k}\right\rangle =P\oint _{\text{surface}}\mathbf {q} \cdot d\mathbf {S} ,}
^ a b Reichl, LE (1998). A Modern Course in Statistical Physics (2nd ed.). Wiley Interscience. pp. 326–333. ISBN 978-0-471-59520-5.
To explain these derivations, the following notation is introduced. First, the phase space is described in terms of generalized position coordinates qj together with their conjugate momenta pj. The quantities qj completely describe the configuration of the system, while the quantities (qj,pj) together completely describe its state.
in the formula for Z. The mean energy associated with this factor is given by
which is twice the contribution that this degree of freedom makes to the average energy ⟨H⟩{\displaystyle \langle H\rangle }. Thus the equipartition theorem for systems with quadratic energies follows easily from the general formula. A similar argument, with 2 replaced by s, applies to energies of the form anxns.
This result is valid for any type of harmonic oscillator, such as a pendulum, a vibrating molecule or a passive electronic oscillator. Systems of such oscillators arise in many situations; by equipartition, each such oscillator receives an average total energy kBT and hence contributes kB to the system's heat capacity. This can be used to derive the formula for Johnson–Nyquist noise[10] and the Dulong–Petit law of solid heat capacities. The latter application was particularly significant in the history of equipartition.
Tolman, RC (1918). "A General Theory of Energy Partition with Applications to Quantum Theory" (PDF). Physical Review. 11 (4): 261–275. Bibcode:1918PhRv...11..261T. doi:10.1103/PhysRev.11.261.
Thus, the average potential energy equals kBT/s, not kBT/2 as for the quadratic harmonic oscillator (where s = 2).
"Über Temperaturabhängigkeit der spezifischen Wärme fester Elemente (On the temperature dependence of the specific heats of solids)"
Σ(E,ΔE)=ΔE ∂Ω∂E=ΔE ρ(E),{\displaystyle \Sigma (E,\Delta E)=\Delta E\ {\frac {\partial \Omega }{\partial E}}=\Delta E\ \rho (E),}
^ a b c d Pais, A (1982). Subtle is the Lord. Oxford University Press. ISBN 0-19-853907-X.
"Die specifische Wärme des Kohlenstoffs (The specific heat of carbon)"
This page was last edited on 7 March 2023, at 19:11 (UTC).
^ Chandrasekhar, S (1939). An Introduction to the Study of Stellar Structure. Chicago: University of Chicago Press. pp. 49–53. ISBN 0-486-60413-6.
3NkBT=−⟨∑k=1Nqk⋅Fk⟩.{\displaystyle 3Nk_{\text{B}}T=-\left\langle \sum _{k=1}^{N}\mathbf {q} _{k}\cdot \mathbf {F} _{k}\right\rangle .}
^ a b c Tolman, RC (1938). The Principles of Statistical Mechanics. New York: Dover Publications. pp. 93–98. ISBN 0-486-63896-0.
Einstein, A (1906). "Die Plancksche Theorie der Strahlung und die Theorie der spezifischen Wärme (The Planck theory of radiation and the theory of specific heat)". Annalen der Physik (in German). 22 (1): 180–190. Bibcode:1906AnP...327..180E. doi:10.1002/andp.19063270110.Einstein, A (1907). "Berichtigung zu meiner Arbeit: 'Die Plancksche Theorie der Strahlung und die Theorie der spezifischen Wärme' (Correction to previous article)". Annalen der Physik (in German). 22 (4): 800. Bibcode:1907AnP...327..800E. doi:10.1002/andp.19073270415. S2CID 122548821.Einstein, A (1911). "Eine Beziehung zwischen dem elastischen Verhalten and der spezifischen Wärme bei festen Körpern mit einatomigem Molekül (A connection between the elastic behavior and the specific heat of solids with single-atom molecules)". Annalen der Physik (in German). 34 (1): 170–174. Bibcode:1911AnP...339..170E. doi:10.1002/andp.19113390110. S2CID 122512507.Einstein, A (1911). "Bemerkung zu meiner Arbeit: 'Eine Beziehung zwischen dem elastischen Verhalten and der spezifischen Wärme bei festen Körpern mit einatomigem Molekül' (Comment on previous article)". Annalen der Physik (in German). 34 (3): 590. Bibcode:1911AnP...339..590E. doi:10.1002/andp.19113390312.Einstein, A (1911). "Elementare Betrachtungen über die thermische Molekularbewegung in festen Körpern (Elementary observations on the thermal movements of molecules in solids)". Annalen der Physik (in German). 35 (9): 679–694. Bibcode:1911AnP...340..679E. doi:10.1002/andp.19113400903.
⟨xm∂H∂xn⟩=δmn(1Ω∂Ω∂E)−1=δmn(∂log⁡Ω∂E)−1=δmnkBT.{\displaystyle \left\langle x_{m}{\frac {\partial H}{\partial x_{n}}}\right\rangle =\delta _{mn}\left({\frac {1}{\Omega }}{\frac {\partial \Omega }{\partial E}}\right)^{-1}=\delta _{mn}\left({\frac {\partial \log \Omega }{\partial E}}\right)^{-1}=\delta _{mn}k_{\text{B}}T.}
^ a b Eucken, A (1912). "Die Molekularwärme des Wasserstoffs bei tiefen Temperaturen (The molecular specific heat of hydrogen at low temperatures)". Sitzungsberichte der Königlich Preussischen Akademie der Wissenschaften (in German). 1912: 141–151.
Kittel, C (1996). Introduction to Solid State Physics. New York: John Wiley and Sons. pp. 151–156. ISBN 978-0-471-11181-8.
Cavanagh, J; Fairbrother WJ, Palmer AG III, Skelton NJ, Rance M (2006). Protein NMR Spectroscopy: Principles and Practice (2nd ed.). Academic Press. ISBN 978-0-12-164491-8.{{cite book}}:CS1 maint: uses authors parameter (link)
^ Boltzmann, L (1895). "On certain Questions of the Theory of Gases". Nature. 51 (1322): 413–415. Bibcode:1895Natur..51..413B. doi:10.1038/051413b0. S2CID 4037658.
with this equation, we can calculate the mean square velocity of the z-component
where dΓk = dΓ/dxk, i.e., the first integration is not carried out over xk. Performing the first integral between two limits a and b and simplifying the second integral yields the equation
^ Mason, M; Weaver W (1924). "The Settling of Small Particles in a Fluid". Physical Review. 23 (3): 412–426. Bibcode:1924PhRv...23..412M. doi:10.1103/PhysRev.23.412.
⟨Hgrav⟩=HgravN=−3GM25RN,{\displaystyle \langle H_{\mathrm {grav} }\rangle ={\frac {H_{\mathrm {grav} }}{N}}=-{\frac {3GM^{2}}{5RN}},}
and similarly for the py and pz components. Adding the three components together gives
Zx=∫−∞∞dx e−βAx2=πβA,{\displaystyle Z_{x}=\int _{-\infty }^{\infty }dx\ e^{-\beta Ax^{2}}={\sqrt {\frac {\pi }{\beta A}}},}
⟨H⟩=∑n=0∞EnP(En)=1Z∑n=0∞nhν e−nβhν=−1Z∂Z∂β=−∂log⁡Z∂β.{\displaystyle \langle H\rangle =\sum _{n=0}^{\infty }E_{n}P(E_{n})={\frac {1}{Z}}\sum _{n=0}^{\infty }nh\nu \ e^{-n\beta h\nu }=-{\frac {1}{Z}}{\frac {\partial Z}{\partial \beta }}=-{\frac {\partial \log Z}{\partial \beta }}.}
^ Cavanagh, J; Fairbrother WJ, Palmer AG III, Skelton NJ, Rance M (2006). Protein NMR Spectroscopy: Principles and Practice (2nd ed.). Academic Press. ISBN 978-0-12-164491-8.{{cite book}}:CS1 maint: uses authors parameter (link)
More generally, in a monatomic ideal gas the total energy consists purely of (translational) kinetic energy: by assumption, the particles have no internal degrees of freedom and move independently of one another. Equipartition therefore predicts that the total energy of an ideal gas of N particles is 3/2 N kB T.
To illustrate the breakdown of equipartition, consider the average energy in a single (quantum) harmonic oscillator, which was discussed above for the classical case. Neglecting the irrelevant zero-point energy term, its quantum energy levels are given by En = nhν, where h is the Planck constant, ν is the fundamental frequency of the oscillator, and n is an integer. The probability of a given energy level being populated in the canonical ensemble is given by its Boltzmann factor
^ a b McQuarrie, DA (2000). Statistical Mechanics (revised 2nd ed.). University Science Books. pp. 91–128. ISBN 978-1-891389-15-3.
Clausius, R (1870). "Ueber einen auf die Wärme anwendbaren mechanischen Satz". Annalen der Physik (in German). 141 (9): 124–130. Bibcode:1870AnP...217..124C. doi:10.1002/andp.18702170911.Clausius, RJE (1870). "On a Mechanical Theorem Applicable to Heat". Philosophical Magazine. Series 4. 40: 122–127.
Kourganoff, V (1980). Introduction to Advanced Astrophysics. Dordrecht, Holland: D. Reidel. pp. 59–60, 134–140, 181–184.
By taking N to be the Avogadro constant NA, and using the relation R = NAkB between the gas constant R and the Boltzmann constant kB, this provides an explanation for the Dulong–Petit law of specific heat capacities of solids, which stated that the specific heat capacity (per unit mass) of a solid element is inversely proportional to its atomic weight. A modern version is that the molar heat capacity of a solid is 3R ≈ 6 cal/(mol·K).
In classical statistical mechanics, the equipartition theorem relates the temperature of a system to its average energies. The equipartition theorem is also known as the law of equipartition, equipartition of energy, or simply equipartition. The original idea of equipartition was that, in thermal equilibrium, energy is shared equally among all of its various forms; for example, the average kinetic energy per degree of freedom in translational motion of a molecule should equal that in rotational motion.
Boltzmann, L (1871). "Einige allgemeine Sätze über Wärmegleichgewicht (Some general statements on thermal equilibrium)". Wiener Berichte (in German). 63: 679–711. In this preliminary work, Boltzmann showed that the average total kinetic energy equals the average total potential energy when a system is acted upon by external harmonic forces.
where the last equality follows from the equipartition theorem for translational kinetic energy:
Huang, K (1987). Statistical Mechanics (2nd ed.). John Wiley and Sons. pp. 136–138. ISBN 0-471-81518-7.
The equipartition theorem makes quantitative predictions. Like the virial theorem, it gives the total average kinetic and potential energies for a system at a given temperature, from which the system's heat capacity can be computed. However, equipartition also gives the average values of individual components of the energy, such as the kinetic energy of a particular particle or the potential energy of a single spring. For example, it predicts that every atom in a monatomic ideal gas has an average kinetic energy of .mw-parser-output .sfrac{white-space:nowrap}.mw-parser-output .sfrac.tion,.mw-parser-output .sfrac .tion{display:inline-block;vertical-align:-0.5em;font-size:85%;text-align:center}.mw-parser-output .sfrac .num,.mw-parser-output .sfrac .den{display:block;line-height:1em;margin:0 0.1em}.mw-parser-output .sfrac .den{border-top:1px solid}.mw-parser-output .sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}3/2kBT in thermal equilibrium, where kB is the Boltzmann constant and T is the (thermodynamic) temperature. More generally, equipartition can be applied to any classical system in thermal equilibrium, no matter how complicated. It can be used to derive the ideal gas law, and the Dulong–Petit law for the specific heat capacities of solids. The equipartition theorem can also be used to predict the properties of stars, even white dwarfs and neutron stars, since it holds even when relativistic effects are considered.
This describes the diffusion of the particle over time. An analogous equation for the rotational diffusion of a rigid molecule can be derived in a similar way.
An anharmonic oscillator (in contrast to a simple harmonic oscillator) is one in which the potential energy is not quadratic in the extension q (the generalized position which measures the deviation of the system from equilibrium). Such oscillators provide a complementary point of view on the equipartition theorem.[37][38] Simple examples are provided by potential energy functions of the form
Similar considerations apply whenever the energy level spacing is much larger than the thermal energy. This reasoning was used by Max Planck and Albert Einstein, among others, to resolve the ultraviolet catastrophe of blackbody radiation.[50] The paradox arises because there are an infinite number of independent modes of the electromagnetic field in a closed container, each of which may be treated as a harmonic oscillator. If each electromagnetic mode were to have an average energy kBT, there would be an infinite amount of energy in the container.[50][51] However, by the reasoning above, the average energy in the higher-frequency modes goes to zero as ν goes to infinity; moreover, Planck's law of black body radiation, which describes the experimental distribution of energy in the modes, follows from the same reasoning.[50]
Since different components of velocity are independent of each other, the average translational kinetic energy is given by
where M(r) is the mass within a radius r and ρ(r) is the stellar density at radius r; G represents the gravitational constant and R the total radius of the star. Assuming a constant density throughout the star, this integration yields the formula
Here, the averaging symbolized by ⟨…⟩{\displaystyle \langle \ldots \rangle } is the ensemble average taken over the canonical ensemble.
this article in the web archive on 2012 April 28
kBT=⟨q∂Hpot∂q⟩=⟨q⋅sCqs−1⟩=⟨sCqs⟩=s⟨Hpot⟩.{\displaystyle k_{\text{B}}T=\left\langle q{\frac {\partial H_{\mathrm {pot} }}{\partial q}}\right\rangle =\langle q\cdot sCq^{s-1}\rangle =\langle sCq^{s}\rangle =s\langle H_{\mathrm {pot} }\rangle .}
since the first term on the right hand side of the first line is zero (it can be rewritten as an integral of H − E on the hypersurface where H = E).
^ Kourganoff, V (1980). Introduction to Advanced Astrophysics. Dordrecht, Holland: D. Reidel. pp. 59–60, 134–140, 181–184.
where the constant a describes the stiffness of the spring and q is the deviation from equilibrium. If such a one-dimensional system has mass m, then its kinetic energy Hkin is
"Bemerkung zu meiner Arbeit: 'Eine Beziehung zwischen dem elastischen Verhalten and der spezifischen Wärme bei festen Körpern mit einatomigem Molekül' (Comment on previous article)"
Chiu, H-Y (1968). Stellar Physics, volume I. Waltham, MA: Blaisdell Publishing. LCCN 67017990.
^ Hermann, Armin (1971). The Genesis of Quantum Theory (1899–1913) (original title: Frühgeschichte der Quantentheorie (1899–1913), translated by Claude W. Nash ed.). Cambridge, MA: The MIT Press. pp. 124–145. ISBN 0-262-08047-8. LCCN 73151106.
Applet demonstrating equipartition in real time for a mixture of monatomic and diatomic gases
"Über die specifische Wärme des Quecksilbergases (On the specific heat of mercury gases)"
The (Newtonian) kinetic energy of a particle of mass m, velocity v is given by
Carroll, Bradley W.; Ostlie, Dale A. (1996). An Introduction to Modern Stellar Astrophysics. Reading, MA: Addison–Wesley. ISBN 0-201-59880-9.
A similar example is provided by a rotating molecule with principal moments of inertia I1, I2 and I3. According to classical mechanics, the rotational energy of such a molecule is given by
^ McQuarrie, DA (2000). Statistical Mechanics (revised 2nd ed.). University Science Books. pp. 121–128. ISBN 978-1-891389-15-3.
Rayleigh, JWS (1900). "The Law of Partition of Kinetic Energy". Philosophical Magazine. 49 (296): 98–118. doi:10.1080/14786440009463826.
Rayleigh, JWS (1900). "Remarks upon the Law of Complete Radiation". Philosophical Magazine. 49: 539–540. Bibcode:1900PMag...49..539R. doi:10.1080/14786440009463878.
^ Thomson, W (1904). Baltimore Lectures. Baltimore: Johns Hopkins University Press. Sec. 27. ISBN 0-8391-1022-7. Re-issued in 1987 by MIT Press as Kelvin's Baltimore Lectures and Modern Theoretical Physics: Historical and Philosophical Perspectives (Robert Kargon and Peter Achinstein, editors). ISBN 978-0-262-11117-1
The total mean potential energy of the gas is therefore ⟨Hpot⟩=12N⟨hpot⟩{\displaystyle \langle H_{\text{pot}}\rangle ={\tfrac {1}{2}}N\langle h_{\mathrm {pot} }\rangle }, where N is the number of particles in the gas, and the factor 1⁄2 is needed because summation over all the particles counts each interaction twice.Adding kinetic and potential energies, then applying equipartition, yields the energy equation
^ Arnold, VI; Avez A (1957). Théorie ergodique des systèms dynamiques (in French). Gauthier-Villars, Paris. (English edition: Benjamin-Cummings, Reading, Mass. 1968).
for non-negative integers n. There is no n = 1 term, because at the equilibrium point, there is no net force and so the first derivative of the energy is zero. The n = 0 term need not be included, since the energy at the equilibrium position may be set to zero by convention. In this case, the law of equipartition predicts that[37]
Find sources: "Equipartition theorem" – news · newspapers · books · scholar · JSTOR
for Brownian motion (since the random force Frnd is uncorrelated with the position r). Using the mathematical identities
^ a b Kundt, A; Warburg E (1876). "Über die specifische Wärme des Quecksilbergases (On the specific heat of mercury gases)". Annalen der Physik (in German). 157 (3): 353–369. Bibcode:1876AnP...233..353K. doi:10.1002/andp.18762330302.
N∫[e−βH(p,q)xk]xk=axk=bdΓk+N∫e−βH(p,q)xkβ∂H∂xkdΓ=1,{\displaystyle {\mathcal {N}}\int \left[e^{-\beta H(p,q)}x_{k}\right]_{x_{k}=a}^{x_{k}=b}d\Gamma _{k}+{\mathcal {N}}\int e^{-\beta H(p,q)}x_{k}\beta {\frac {\partial H}{\partial x_{k}}}d\Gamma =1,}
^ a b c d e f g h i j k l
Chandrasekhar, S (1939). An Introduction to the Study of Stellar Structure. Chicago: University of Chicago Press. pp. 49–53. ISBN 0-486-60413-6.
Pauli, W (1973). Pauli Lectures on Physics: Volume 4. Statistical Mechanics. MIT Press. pp. 27–40. ISBN 0-262-16049-8.
Pathria, RK (1972). Statistical Mechanics. Pergamon Press. pp. 43–48, 73–74. ISBN 0-08-016747-0.
ddt(r⋅r)=ddt(r2)=2(r⋅v){\displaystyle {\frac {d}{dt}}\left(\mathbf {r} \cdot \mathbf {r} \right)={\frac {d}{dt}}\left(r^{2}\right)=2\left(\mathbf {r} \cdot \mathbf {v} \right)}
where the last equality follows from the equipartition formula. Thus, the average total energy of an extreme relativistic gas is twice that of the non-relativistic case: for N particles, it is 3 NkBT.
5Derivations											Toggle Derivations subsection																					5.1Kinetic energies and the Maxwell–Boltzmann distribution																											5.2Quadratic energies and the partition function																											5.3General proofs																								5.3.1The canonical ensemble																											5.3.2The microcanonical ensemble
^ a b c d e f g h i j k l Pathria, RK (1972). Statistical Mechanics. Pergamon Press. pp. 43–48, 73–74. ISBN 0-08-016747-0.
"Die specifische Wärmen der Elemente Kohlenstoff, Bor und Silicium (The specific heats of elemental carbon, boron, and silicon)"
⟨r∂Hgrav∂r⟩=⟨−Hgrav⟩=kBT=3GM25RN.{\displaystyle \left\langle r{\frac {\partial H_{\mathrm {grav} }}{\partial r}}\right\rangle =\langle -H_{\mathrm {grav} }\rangle =k_{\text{B}}T={\frac {3GM^{2}}{5RN}}.}
The dot product of this equation with the position vector r, after averaging, yields the equation
The above differential equation for ⟨r2⟩{\displaystyle \langle r^{2}\rangle } (with suitable initial conditions) may be solved exactly:
The law of equipartition holds only for ergodic systems in thermal equilibrium, which implies that all states with the same energy must be equally likely to be populated.[9] Consequently, it must be possible to exchange energy among all its various forms within the system, or with an external heat bath in the canonical ensemble. The number of physical systems that have been rigorously proven to be ergodic is small; a famous example is the hard-sphere system of Yakov Sinai.[48] The requirements for isolated systems to ensure ergodicity—and, thus equipartition—have been studied, and provided motivation for the modern chaos theory of dynamical systems. A chaotic Hamiltonian system need not be ergodic, although that is usually a good assumption.[49]
Applet demonstrating equipartition in real time for a mixture of monatomic and diatomic gases Archived 2020-08-06 at the Wayback Machine
The history of the equipartition theorem is intertwined with that of specific heat capacity, both of which were studied in the 19th century. In 1819, the French physicists Pierre Louis Dulong and Alexis Thérèse Petit discovered that the specific heat capacities of solid elements at room temperature were inversely proportional to the atomic weight of the element.[20] Their law was used for many years as a technique for measuring atomic weights.[11] However, subsequent studies by James Dewar and Heinrich Friedrich Weber showed that this Dulong–Petit law holds only at high temperatures;[21] at lower temperatures, or for exceptionally hard solids such as diamond, the specific heat capacity was lower.[22]
4Applications											Toggle Applications subsection																					4.1Ideal gas law																											4.2Diatomic gases																											4.3Extreme relativistic ideal gases																											4.4Non-ideal gases																											4.5Anharmonic oscillators																											4.6Brownian motion																											4.7Stellar physics																											4.8Star formation
By Newton's third law and the ideal gas assumption, the net force on the system is the force applied by the walls of their container, and this force is given by the pressure P of the gas. Hence
^ a b Wüller, A (1896). Lehrbuch der Experimentalphysik (Textbook of Experimental Physics) (in German). Leipzig: Teubner. Vol. 2, 507ff.
Nernst, W (1910). "Untersuchungen über die spezifische Wärme bei tiefen Temperaturen. II. (Investigations into the specific heat at low temperatures)". Sitzungsberichte der Königlich Preussischen Akademie der Wissenschaften (in German). 1910: 262–282.
^ a b Mandl, F (1971). Statistical Physics. John Wiley and Sons. pp. 213–219. ISBN 0-471-56658-6.
^ Callen, HB (1985). Thermodynamics and an Introduction to Thermostatistics. New York: John Wiley and Sons. pp. 375–377. ISBN 0-471-86256-8.
Arnold, VI; Avez A (1957). Théorie ergodique des systèms dynamiques (in French). Gauthier-Villars, Paris. (English edition: Benjamin-Cummings, Reading, Mass. 1968).
"Eine Beziehung zwischen dem elastischen Verhalten and der spezifischen Wärme bei festen Körpern mit einatomigem Molekül (A connection between the elastic behavior and the specific heat of solids with single-atom molecules)"
^ a b Tolman, RC (1927). Statistical Mechanics, with Applications to Physics and Chemistry. Chemical Catalog Company. pp. 76–77.
Landau, LD; Lifshitz EM (1980). Statistical Physics, Part 1 (3rd ed.). Pergamon Press. pp. 129–132. ISBN 0-08-023039-3.
where M is the star's total mass. Hence, the average potential energy of a single particle is
^ a b c Einstein, A (1905). "Über einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt (A Heuristic Model of the Creation and Transformation of Light)". Annalen der Physik (in German). 17 (6): 132–148. Bibcode:1905AnP...322..132E. doi:10.1002/andp.19053220607.. An English translation is available from Wikisource.
Noyes, RW (1982). The Sun, Our Star. Cambridge, MA: Harvard University Press. ISBN 0-674-85435-7.
Notice, the Maxwell–Boltzmann distribution should not be confused with the Boltzmann distribution, which the former can be derived from the latter by assuming the energy of a particle is equal to its translational kinetic energy.
^ Cantor, CR; Schimmel PR (1980). Biophysical Chemistry. Part II. Techniques for the study of biological structure and function. W. H. Freeman. ISBN 978-0-7167-1189-6.
"Die Plancksche Theorie der Strahlung und die Theorie der spezifischen Wärme (The Planck theory of radiation and the theory of specific heat)"
Substituting the values typically observed in such clouds (T = 150 K, ρ = 2×10−16 g/cm3) gives an estimated minimum mass of 17 solar masses, which is consistent with observed star formation. This effect is also known as the Jeans instability, after the British physicist James Hopwood Jeans who published it in 1902.[45]
where dS is the infinitesimal area element along the walls of the container. Since the divergence of the position vector q is
Terletskii, YP (1971). Statistical Physics (translated: N. Fröman ed.). Amsterdam: North-Holland. pp. 83–84. ISBN 0-7204-0221-2. LCCN 70157006.
∫H∈[E,E+ΔE]…dΓ=ΔE∂∂E∫H<E…dΓ,{\displaystyle \int _{H\in \left[E,E+\Delta E\right]}\ldots d\Gamma =\Delta E{\frac {\partial }{\partial E}}\int _{H<E}\ldots d\Gamma ,}
where N is the number of particles in the star. Since most stars are composed mainly of ionized hydrogen, N equals roughly M/mp, where mp is the mass of one proton. Application of the equipartition theorem gives an estimate of the star's temperature
In an ideal gas the particles are assumed to interact only through collisions. The equipartition theorem may also be used to derive the energy and pressure of "non-ideal gases" in which the particles also interact with one another through conservative forces whose potential U(r) depends only on the distance r between the particles.[5] This situation can be described by first restricting attention to a single gas particle, and approximating the rest of the gas by a spherically symmetric distribution. It is then customary to introduce a radial distribution function g(r) such that the probability density of finding another particle at a distance r from the given particle is equal to 4πr2ρg(r), where ρ = N/V is the mean density of the gas.[36] It follows that the mean potential energy associated to the interaction of the given particle with the rest of the gas is
where Frnd is a random force representing the random collisions of the particle and the surrounding molecules, and where the time constant τ reflects the drag force that opposes the particle's motion through the solution. The drag force is often written Fdrag = −γv; therefore, the time constant τ equals m/γ.
Kundt, A; Warburg E (1876). "Über die specifische Wärme des Quecksilbergases (On the specific heat of mercury gases)". Annalen der Physik (in German). 157 (3): 353–369. Bibcode:1876AnP...233..353K. doi:10.1002/andp.18762330302.
⟨q⋅F⟩=⟨qxdpxdt⟩+⟨qydpydt⟩+⟨qzdpzdt⟩=−⟨qx∂H∂qx⟩−⟨qy∂H∂qy⟩−⟨qz∂H∂qz⟩=−3kBT,{\displaystyle {\begin{aligned}\langle \mathbf {q} \cdot \mathbf {F} \rangle &=\left\langle q_{x}{\frac {dp_{x}}{dt}}\right\rangle +\left\langle q_{y}{\frac {dp_{y}}{dt}}\right\rangle +\left\langle q_{z}{\frac {dp_{z}}{dt}}\right\rangle \\&=-\left\langle q_{x}{\frac {\partial H}{\partial q_{x}}}\right\rangle -\left\langle q_{y}{\frac {\partial H}{\partial q_{y}}}\right\rangle -\left\langle q_{z}{\frac {\partial H}{\partial q_{z}}}\right\rangle =-3k_{\text{B}}T,\end{aligned}}}
of the phase space is introduced and used to define the volume Σ(E, ΔE) of the portion of phase space where the energy H of the system lies between two limits, E and E + ΔE:
Another way ergodicity can be broken is by the existence of nonlinear soliton symmetries. In 1953, Fermi, Pasta, Ulam and Tsingou conducted computer simulations of a vibrating string that included a non-linear term (quadratic in one test, cubic in another, and a piecewise linear approximation to a cubic in a third). They found that the behavior of the system was quite different from what intuition based on equipartition would have led them to expect. Instead of the energies in the modes becoming equally shared, the system exhibited a very complicated quasi-periodic behavior. This puzzling result was eventually explained by Kruskal and Zabusky in 1965 in a paper which, by connecting the simulated system to the Korteweg–de Vries equation led to the development of soliton mathematics.
Tolman, RC (1938). The Principles of Statistical Mechanics. New York: Dover Publications. pp. 93–98. ISBN 0-486-63896-0.
^ Terletskii, YP (1971). Statistical Physics (translated: N. Fröman ed.). Amsterdam: North-Holland. pp. 83–84. ISBN 0-7204-0221-2. LCCN 70157006.
Tolman, RC (1927). Statistical Mechanics, with Applications to Physics and Chemistry. Chemical Catalog Company. pp. 72–81. ASIN B00085D6OO
General derivations of the equipartition theorem can be found in many statistical mechanics textbooks, both for the microcanonical ensemble[5][9] and for the canonical ensemble.[5][33]They involve taking averages over the phase space of the system, which is a symplectic manifold.
^ McQuarrie, DA (2000). Statistical Mechanics (revised 2nd ed.). University Science Books. pp. 254–264. ISBN 978-1-891389-15-3.
The general equipartition theorem is an extension of the virial theorem (proposed in 1870[34]), which states that
Thus, we have derived the general formulation of the equipartition theorem
where C and s are arbitrary real constants. In these cases, the law of equipartition predicts that
dvdt=1mF=−vτ+1mFrnd,{\displaystyle {\frac {d\mathbf {v} }{dt}}={\frac {1}{m}}\mathbf {F} =-{\frac {\mathbf {v} }{\tau }}+{\frac {1}{m}}\mathbf {F} _{\mathrm {rnd} },}
The degrees of freedom xn are coordinates on the phase space of the system and are therefore commonly subdivided into generalized position coordinates qk and generalized momentum coordinates pk, where pk is the conjugate momentum to qk. In this situation, formula 1 means that for all k,
⟨Hpot⟩=12kBT−∑n=3∞(n−22)Cn⟨qn⟩{\displaystyle \langle H_{\mathrm {pot} }\rangle ={\frac {1}{2}}k_{\text{B}}T-\sum _{n=3}^{\infty }\left({\frac {n-2}{2}}\right)C_{n}\langle q^{n}\rangle }
In this example, the key point is that the kinetic energy is quadratic in the velocity. The equipartition theorem shows that in thermal equilibrium, any degree of freedom (such as a component of the position or velocity of a particle) which appears only quadratically in the energy has an average energy of 1⁄2kBT and therefore contributes 1⁄2kB to the system's heat capacity. This has many applications.
The tumbling of rigid molecules—that is, the random rotations of molecules in solution—plays a key role in the relaxations observed by nuclear magnetic resonance, particularly protein NMR and residual dipolar couplings.[6] Rotational diffusion can also be observed by other biophysical probes such as fluorescence anisotropy, flow birefringence and dielectric spectroscopy.[7]
⟨Hkin⟩=⟨cpx2+py2+pz2px2+py2+pz2⟩=⟨px∂Hkin∂px⟩+⟨py∂Hkin∂py⟩+⟨pz∂Hkin∂pz⟩=3kBT{\displaystyle {\begin{aligned}\langle H_{\mathrm {kin} }\rangle &=\left\langle c{\frac {p_{x}^{2}+p_{y}^{2}+p_{z}^{2}}{\sqrt {p_{x}^{2}+p_{y}^{2}+p_{z}^{2}}}}\right\rangle \\&=\left\langle p_{x}{\frac {\partial H^{\mathrm {kin} }}{\partial p_{x}}}\right\rangle +\left\langle p_{y}{\frac {\partial H^{\mathrm {kin} }}{\partial p_{y}}}\right\rangle +\left\langle p_{z}{\frac {\partial H^{\mathrm {kin} }}{\partial p_{z}}}\right\rangle \\&=3k_{\text{B}}T\end{aligned}}}
^ Einstein, A (1906). "Die Plancksche Theorie der Strahlung und die Theorie der spezifischen Wärme (The Planck theory of radiation and the theory of specific heat)". Annalen der Physik (in German). 22 (1): 180–190. Bibcode:1906AnP...327..180E. doi:10.1002/andp.19063270110.Einstein, A (1907). "Berichtigung zu meiner Arbeit: 'Die Plancksche Theorie der Strahlung und die Theorie der spezifischen Wärme' (Correction to previous article)". Annalen der Physik (in German). 22 (4): 800. Bibcode:1907AnP...327..800E. doi:10.1002/andp.19073270415. S2CID 122548821.Einstein, A (1911). "Eine Beziehung zwischen dem elastischen Verhalten and der spezifischen Wärme bei festen Körpern mit einatomigem Molekül (A connection between the elastic behavior and the specific heat of solids with single-atom molecules)". Annalen der Physik (in German). 34 (1): 170–174. Bibcode:1911AnP...339..170E. doi:10.1002/andp.19113390110. S2CID 122512507.Einstein, A (1911). "Bemerkung zu meiner Arbeit: 'Eine Beziehung zwischen dem elastischen Verhalten and der spezifischen Wärme bei festen Körpern mit einatomigem Molekül' (Comment on previous article)". Annalen der Physik (in German). 34 (3): 590. Bibcode:1911AnP...339..590E. doi:10.1002/andp.19113390312.Einstein, A (1911). "Elementare Betrachtungen über die thermische Molekularbewegung in festen Körpern (Elementary observations on the thermal movements of molecules in solids)". Annalen der Physik (in German). 35 (9): 679–694. Bibcode:1911AnP...340..679E. doi:10.1002/andp.19113400903.
^ Maxwell, JC (2003). "Illustrations of the Dynamical Theory of Gases".In WD Niven (ed.). The Scientific Papers of James Clerk Maxwell. New York: Dover. Vol.1, pp. 377–409. ISBN 978-0-486-49560-6. Read by Prof. Maxwell at a Meeting of the British Association at Aberdeen on 21 September 1859.
^ a b Maxwell, JC (1890). "On the Dynamical Evidence of the Molecular Constitution of Bodies".In WD Niven (ed.). The Scientific Papers of James Clerk Maxwell. Cambridge: At the University Press. Vol.2, pp.418–438. ISBN 0-486-61534-0. ASIN B000GW7DXY. A lecture delivered by Prof. Maxwell at the Chemical Society on 18 February 1875.
"1954: Morris Tanenbaum fabricates the first silicon transistor at Bell Labs"
^ "Band strcutre and carrier concentration (Ge)". Retrieved May 3, 2021.
^ a b c d e f g Neamen, Donald. "Semiconductor Physics and Devices" (PDF). Elizabeth A. Jones.
B. G. Yacobi, Semiconductor Materials: An Introduction to Basic Principles, Springer 2003 ISBN 0-306-47361-5, pp. 1–3.
4Early history of semiconductors											Toggle Early history of semiconductors subsection																					4.1Early transistors
Agreement between theoretical predictions (based on developing quantum mechanics) and experimental results was sometimes poor. This was later explained by John Bardeen as due to the extreme "structure sensitive" behavior of semiconductors, whose properties change dramatically based on tiny amounts of impurities.[28] Commercially pure materials of the 1920s containing varying proportions of trace contaminants produced differing experimental results. This spurred the development of improved material refining techniques, culminating in modern semiconductor refineries producing materials with parts-per-trillion purity.
The probability of meeting is increased by carrier traps – impurities or dislocations which can trap an electron or hole and hold it until a pair is completed. Such carrier traps are sometimes purposely added to reduce the time needed to reach the steady-state.[14]
1Properties											Toggle Properties subsection																					1.1Variable electrical conductivity																											1.2Heterojunctions																											1.3Excited electrons																											1.4Light emission																											1.5High thermal conductivity																											1.6Thermal energy conversion
The first working transistor was a point-contact transistor invented by John Bardeen, Walter Houser Brattain, and William Shockley at Bell Labs in 1947. Shockley had earlier theorized a field-effect amplifier made from germanium and silicon, but he failed to build such a working device, before eventually using germanium to invent the point-contact transistor.[35] In France, during the war, Herbert Mataré had observed amplification between adjacent point contacts on a germanium base. After the war, Mataré's group announced their "Transistron" amplifier only shortly after Bell Labs announced the "transistor".
As in the Mott formula for conductivity, see Cutler, M.; Mott, N. (1969). "Observation of Anderson Localization in an Electron Gas". Physical Review. 181 (3): 1336. Bibcode:1969PhRv..181.1336C. doi:10.1103/PhysRev.181.1336.
Detector and power rectifiers could not amplify a signal. Many efforts were made to develop a solid-state amplifier and were successful in developing a device called the point contact transistor which could amplify 20dB or more.[34] In 1922, Oleg Losev developed two-terminal, negative resistance amplifiers for radio, but he perished in the Siege of Leningrad after successful completion. In 1926, Julius Edgar Lilienfeld patented a device resembling a field-effect transistor, but it was not practical. R. Hilsch and R. W. Pohl in 1938 demonstrated a solid-state amplifier using a structure resembling the control grid of a vacuum tube; although the device displayed power gain, it had a cut-off frequency of one cycle per second, too low for any practical applications, but an effective application of the available theory.[28] At Bell Labs, William Shockley and A. Holden started investigating solid-state amplifiers in 1938. The first p–n junction in silicon was observed by Russell Ohl about 1941 when a specimen was found to be light-sensitive, with a sharp boundary between p-type impurity at one end and n-type at the other. A slice cut from the specimen at the p–n boundary developed a voltage when exposed to light.
In the years preceding World War II, infrared detection and communications devices prompted research into lead-sulfide and lead-selenide materials. These devices were used for detecting ships and aircraft, for infrared rangefinders, and for voice communication systems. The point-contact crystal detector became vital for microwave radio systems since available vacuum tube devices could not serve as detectors above about 4000 MHz; advanced radar systems relied on the fast response of crystal detectors. Considerable research and development of silicon materials occurred during the war to develop detectors of consistent quality.[28]
A few of the properties of semiconductor materials were observed throughout the mid-19th and first decades of the 20th century. The first practical application of semiconductors in electronics was the 1904 development of the cat's-whisker detector, a primitive semiconductor diode used in early radio receivers. Developments in quantum physics led in turn to the invention of the transistor in 1947[3] and the integrated circuit in 1958.
Semiconductors have large thermoelectric power factors making them useful in thermoelectric generators, as well as high thermoelectric figures of merit making them useful in thermoelectric coolers.[6]
Peter Robin Morris (1990) A History of the World Semiconductor Industry, IET, ISBN 0-86341-227-0, pp. 11–25
Yu, Peter Y.; Cardona, Manuel (2004). Fundamentals of Semiconductors: Physics and Materials Properties. Springer. ISBN 978-3-540-41323-3.
This page was last edited on 16 March 2023, at 06:14 (UTC).
"Band strcutre and carrier concentration (Ge)". Retrieved May 3, 2021.
^ By Abdul Al-Azzawi. "Light and Optics: Principles and Practices." 2007. March 4, 2016.
Dong, Renhao; Han, Peng; Arora, Himani; Ballabio, Marco; Karakus, Melike; Zhang, Zhe; Shekhar, Chandra; Adler, Peter; Petkov, Petko St.; Erbe, Artur; Mannsfeld, Stefan C. B. (2018). "High-mobility band-like charge transport in a semiconducting two-dimensional metal–organic framework". Nature Materials. 17 (11): 1027–1032. Bibcode:2018NatMa..17.1027D. doi:10.1038/s41563-018-0189-z. ISSN 1476-4660. PMID 30323335. S2CID 53027396.
Lidia Łukasiak & Andrzej Jakubowski (January 2010). "History of Semiconductors" (PDF). Journal of Telecommunication and Information Technology: 3. Archived from the original (PDF) on 2013-06-22. Retrieved 2012-08-03.
^ Y., Roshni (5 February 2019). "Difference Between Intrinsic and Extrinsic Semiconductors". Retrieved May 3, 2021.
A 1 cm3 specimen of a metal or semiconductor has the order of 1022 atoms.[18] In a metal, every atom donates at least one free electron for conduction, thus 1 cm3 of metal contains on the order of 1022 free electrons,[19] whereas a 1 cm3 sample of pure germanium at 20 °C contains about 4.2×1022 atoms, but only 2.5×1013 free electrons and 2.5×1013 holes. The addition of 0.001% of arsenic (an impurity) donates an extra 1017 free electrons in the same volume and the electrical conductivity is increased by a factor of 10,000.[20][21]
^ a b Lidia Łukasiak & Andrzej Jakubowski (January 2010). "History of Semiconductors" (PDF). Journal of Telecommunication and Information Technology: 3. Archived from the original (PDF) on 2013-06-22. Retrieved 2012-08-03.
Busch, G (1989). "Early history of the physics and chemistry of semiconductors-from doubts to fact in a hundred years". European Journal of Physics. 10 (4): 254–64. Bibcode:1989EJPh...10..254B. doi:10.1088/0143-0807/10/4/002. S2CID 250888128.
^ a b c d .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Feynman, Richard. Feynman Lectures on Physics.
^ Busch, G (1989). "Early history of the physics and chemistry of semiconductors-from doubts to fact in a hundred years". European Journal of Physics. 10 (4): 254–64. Bibcode:1989EJPh...10..254B. doi:10.1088/0143-0807/10/4/002. S2CID 250888128.
^ B. G. Yacobi, Semiconductor Materials: An Introduction to Basic Principles, Springer 2003 ISBN 0-306-47361-5, pp. 1–3.
Yu, Peter (2010). Fundamentals of Semiconductors. Berlin: Springer-Verlag. ISBN 978-3-642-00709-5.
^ Arora, Himani (2020). Charge transport in two-dimensional materials and their electronic applications (PDF). Dresden: Qucosa.
A unified explanation of these phenomena required a theory of solid-state physics, which developed greatly in the first half of the 20th century. In 1878 Edwin Herbert Hall demonstrated the deflection of flowing charge carriers by an applied magnetic field, the Hall effect. The discovery of the electron by J.J. Thomson in 1897 prompted theories of electron-based conduction in solids. Karl Baedeker, by observing a Hall effect with the reverse sign to that in metals, theorized that copper iodide had positive charge carriers. Johan Koenigsberger classified solid materials like metals, insulators, and "variable conductors" in 1914 although his student Josef Weiss already introduced the term Halbleiter (a semiconductor in modern meaning) in his Ph.D. thesis in 1910.[30][31] Felix Bloch published a theory of the movement of electrons through atomic lattices in 1928. In 1930, B. Gudden stated that conductivity in semiconductors was due to minor concentrations of impurities. By 1931, the band theory of conduction had been established by Alan Herries Wilson and the concept of band gaps had been developed. Walter H. Schottky and Nevill Francis Mott developed models of the potential barrier and of the characteristics of a metal–semiconductor junction. By 1938, Boris Davydov had developed a theory of the copper-oxide rectifier, identifying the effect of the p–n junction and the importance of minority carriers and surface states.[28]
3Physics of semiconductors											Toggle Physics of semiconductors subsection																					3.1Energy bands and electrical conduction																											3.2Charge carriers (electrons and holes)																								3.2.1Carrier generation and recombination																														3.3Doping																											3.4Amorphous semiconductors
Louis Nashelsky, Robert L.Boylestad (2006). Electronic Devices and Circuit Theory (9th ed.). India: Prentice-Hall of India Private Limited. pp. 7–10. ISBN 978-81-203-2967-6.
^ a b c Charles Kittel (1995) Introduction to Solid State Physics, 7th ed. Wiley, ISBN 0-471-11181-3.
Nave, R. "Ohm's Law, Microscopic View". Archived from the original on May 3, 2021. Retrieved May 3, 2021.
The last process is called diffusion. This is the process that gives the semiconducting material its desired semiconducting properties. It is also known as doping. The process introduces an impure atom to the system, which creates the p–n junction. To get the impure atoms embedded in the silicon wafer, the wafer is first put in a 1,100 degree Celsius chamber. The atoms are injected in and eventually diffuse with the silicon. After the process is completed and the silicon has reached room temperature, the doping process is done and the semiconducting material is ready to be used in an integrated circuit.[1][4]
The first semiconductor devices used galena, including German physicist Ferdinand Braun's crystal detector in 1874 and Bengali physicist Jagadish Chandra Bose's radio crystal detector in 1901.[32][33]
High conductivity in material comes from it having many partially filled states and much state delocalization.Metals are good electrical conductors and have many partially filled states with energies near their Fermi level.Insulators, by contrast, have few partially filled states, their Fermi levels sit within band gaps with few energy states to occupy. Importantly, an insulator can be made to conduct by increasing its temperature: heating provides energy to promote some electrons across the bandgap, inducing partially filled states in both the band of states beneath the band gap (valence band) and the band of states above the bandgap (conduction band). An (intrinsic) semiconductor has a bandgap that is smaller than that of an insulator and at room temperature, significant numbers of electrons can be excited to cross the band gap.[12]
^ a b c d e f g Morris, Peter Robin (July 22, 1990). A History of the World Semiconductor Industry. IET. ISBN 9780863412271 – via Google Books.
Some materials, when rapidly cooled to a glassy amorphous state, have semiconducting properties. These include B, Si, Ge, Se, and Te, and there are multiple theories to explain them.[25][26]
^ "1954: Morris Tanenbaum fabricates the first silicon transistor at Bell Labs". The Silicon Engine. Computer History Museum. Retrieved 23 August 2019.
Turley, Jim (2002). The Essential Guide to Semiconductors. Prentice Hall PTR. ISBN 978-0-13-046404-0.
^ Moskowitz, Sanford L. (2016). Advanced Materials Innovation: Managing Global Technology in the 21st century. John Wiley & Sons. p. 168. ISBN 9780470508923.
^ Nave, R. "Silicon and Germanium". Retrieved May 3, 2021.
"1947: Invention of the Point-Contact Transistor". The Silicon Engine. Computer History Museum. Retrieved 23 August 2019.
Heterojunctions occur when two differently doped semiconducting materials are joined. For example, a configuration could consist of p-doped and n-doped germanium. This results in an exchange of electrons and holes between the differently doped semiconducting materials. The n-doped germanium would have an excess of electrons, and the p-doped germanium would have an excess of holes. The transfer occurs until an equilibrium is reached by a process called recombination, which causes the migrating electrons from the n-type to come in contact with the migrating holes from the p-type. The result of this process is a narrow strip of immobile ions, which causes an electric field across the junction.[1][4]
Certain pure elements are found in group 14 of the periodic table; the most commercially important of these elements are silicon and germanium. Silicon and germanium are used here effectively because they have 4 valence electrons in their outermost shell, which gives them the ability to gain or lose electrons equally at the same time.
Binary compounds, particularly between elements in groups 13 and 15, such as gallium arsenide, groups 12 and 16, groups 14 and 16, and between different group-14 elements, e.g. silicon carbide.
^ Shockley, William (1950). Electrons and holes in semiconductors: with applications to transistor electronics. R. E. Krieger Pub. Co. ISBN 978-0-88275-382-9.
Semiconductors with high thermal conductivity can be used for heat dissipation and improving thermal management of electronics.
^ Nave, R. "Ohm's Law, Microscopic View". Archived from the original on May 3, 2021. Retrieved May 3, 2021.
"Experimentelle Beiträge Zur Elektronentheorie Aus dem Gebiet der Thermoelektrizität, Inaugural-Dissertation ... von J. Weiss, ..."
During manufacture, dopants can be diffused into the semiconductor body by contact with gaseous compounds of the desired element, or ion implantation can be used to accurately position the doped regions.
Devices using semiconductors were at first constructed based on empirical knowledge before semiconductor theory provided a guide to the construction of more capable and reliable devices.
Alexander Graham Bell used the light-sensitive property of selenium to transmit sound over a beam of light in 1880. A working solar cell, of low efficiency, was constructed by Charles Fritts in 1883, using a metal plate coated with selenium and a thin layer of gold; the device became commercially useful in photographic light meters in the 1930s.[28] Point-contact microwave detector rectifiers made of lead sulfide were used by Jagadish Chandra Bose in 1904; the cat's-whisker detector using natural galena or other materials became a common device in the development of radio. However, it was somewhat unpredictable in operation and required manual adjustment for best performance. In 1906, H.J. Round observed light emission when electric current passed through silicon carbide crystals, the principle behind the light-emitting diode. Oleg Losev observed similar light emission in 1922, but at the time the effect had no practical use. Power rectifiers, using copper oxide and selenium, were developed in the 1920s and became commercially important as an alternative to vacuum tube rectifiers.[29][28]
^ Dong, Renhao; Han, Peng; Arora, Himani; Ballabio, Marco; Karakus, Melike; Zhang, Zhe; Shekhar, Chandra; Adler, Peter; Petkov, Petko St.; Erbe, Artur; Mannsfeld, Stefan C. B. (2018). "High-mobility band-like charge transport in a semiconducting two-dimensional metal–organic framework". Nature Materials. 17 (11): 1027–1032. Bibcode:2018NatMa..17.1027D. doi:10.1038/s41563-018-0189-z. ISSN 1476-4660. PMID 30323335. S2CID 53027396.
Morris, Peter Robin (July 22, 1990). A History of the World Semiconductor Industry. IET. ISBN 9780863412271 – via Google Books.
The etching is the next process that is required. The part of the silicon that was not covered by the photoresist layer from the previous step can now be etched. The main process typically used today is called plasma etching. Plasma etching usually involves an etch gas pumped in a low-pressure chamber to create plasma. A common etch gas is chlorofluorocarbon, or more commonly known Freon. A high radio-frequency voltage between the cathode and anode is what creates the plasma in the chamber. The silicon wafer is located on the cathode, which causes it to be hit by the positively charged ions that are released from the plasma. The result is silicon that is etched anisotropically.[1][4]
The conductivity of silicon is increased by adding a small amount (of the order of 1 in 108) of pentavalent (antimony, phosphorus, or arsenic) or trivalent (boron, gallium, indium) atoms. This process is known as doping, and the resulting semiconductors are known as doped or extrinsic semiconductors. Apart from doping, the conductivity of a semiconductor can be improved by increasing its temperature. This is contrary to the behavior of a metal, in which conductivity decreases with an increase in temperature.
J. W. Allen (1960). "Gallium Arsenide as a semi-insulator". Nature. 187 (4735): 403–05. Bibcode:1960Natur.187..403A. doi:10.1038/187403b0. S2CID 4183332.
"1901: Semiconductor Rectifiers Patented as "Cat's Whisker" Detectors". The Silicon Engine. Computer History Museum. Retrieved 23 August 2019.
Almost all of today's electronic technology involves the use of semiconductors, with the most important aspect being the integrated circuit (IC), which are found in desktops, laptops, scanners, cell-phones, and other electronic devices. Semiconductors for ICs are mass-produced. To create an ideal semiconducting material, chemical purity is paramount. Any small imperfection can have a drastic effect on how the semiconducting material behaves due to the scale at which the materials are used.[4]
Electron-hole pairs are also apt to recombine. Conservation of energy demands that these recombination events, in which an electron loses an amount of energy larger than the band gap, be accompanied by the emission of thermal energy (in the form of phonons) or radiation (in the form of photons).
Semiconductor devices can display a range of different useful properties, such as passing current more easily in one direction than the other, showing variable resistance, and having sensitivity to light or heat. Because the electrical properties of a semiconductor material can be modified by doping and by the application of electrical fields or light, devices made from semiconductors can be used for amplification, switching, and energy conversion.
A large number of elements and compounds have semiconducting properties, including:[7]
Semiconductors are defined by their unique electric conductive behavior, somewhere between that of a conductor and an insulator.[10] The differences between these materials can be understood in terms of the quantum states for electrons, each of which may contain zero or one electron (by the Pauli exclusion principle). These states are associated with the electronic band structure of the material. Electrical conductivity arises due to the presence of electrons in states that are delocalized (extending through the material), however in order to transport electrons a state must be partially filled, containing an electron only part of the time.[11] If the state is always occupied with an electron, then it is inert, blocking the passage of other electrons via that state. The energies of these quantum states are critical since a state is partially filled only if its energy is near the Fermi level (see Fermi–Dirac statistics).
Y., Roshni (5 February 2019). "Difference Between Intrinsic and Extrinsic Semiconductors". Retrieved May 3, 2021.
Moskowitz, Sanford L. (2016). Advanced Materials Innovation: Managing Global Technology in the 21st century. John Wiley & Sons. p. 168. ISBN 9780470508923.
Hulls, K.; McMillan, P. W. (May 22, 1972). "Amorphous semiconductors: a review of current theories". Journal of Physics D: Applied Physics. 5 (5): 865–82. doi:10.1088/0022-3727/5/5/205. S2CID 250874071.
Arora, Himani (2020). Charge transport in two-dimensional materials and their electronic applications (PDF). Dresden: Qucosa.
^ "1901: Semiconductor Rectifiers Patented as "Cat's Whisker" Detectors". The Silicon Engine. Computer History Museum. Retrieved 23 August 2019.
Semiconductors in their natural state are poor conductors because a current requires the flow of electrons, and semiconductors have their valence bands filled, preventing the entire flow of new electrons. Several developed techniques allow semiconducting materials to behave like conducting materials, such as doping or gating. These modifications have two outcomes: n-type and p-type. These refer to the excess or shortage of electrons, respectively. A balanced number of electrons would cause a current to flow throughout the material.[4]
^ Van Zeghbroeck, Bart (2000). "Carrier densities". Archived from the original on May 3, 2021. Retrieved May 3, 2021.
A. A. Balandin & K. L. Wang (2006). Handbook of Semiconductor Nanostructures and Nanodevices (5-Volume Set). American Scientific Publishers. ISBN 978-1-58883-073-9.
ABACUS: Introduction to Semiconductor Devices – by Gerhard Klimeck and Dragica Vasileska, online learning resource with simulation tools on nanoHUB
A pure semiconductor, however, is not very useful, as it is neither a very good insulator nor a very good conductor.However, one important feature of semiconductors (and some insulators, known as semi-insulators) is that their conductivity can be increased and controlled by doping with impurities and gating with electric fields. Doping and gating move either the conduction or valence band much closer to the Fermi level and greatly increase the number of partially filled states.
Charles Kittel (1995) Introduction to Solid State Physics, 7th ed. Wiley, ISBN 0-471-11181-3.
Some wider-bandgap semiconductor materials are sometimes referred to as semi-insulators. When undoped, these have electrical conductivity nearer to that of electrical insulators, however they can be doped (making them as useful as semiconductors). Semi-insulators find niche applications in micro-electronics, such as substrates for HEMT. An example of a common semi-insulator is gallium arsenide.[13] Some materials, such as titanium dioxide, can even be used as insulating materials for some applications, while being treated as wide-gap semiconductors for other applications.
^ "How do thermoelectric coolers (TECs) work?". ii-vi.com. Retrieved 2021-11-08.
.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Feynman, Richard. Feynman Lectures on Physics.
As the probability that electrons and holes meet together is proportional to the product of their numbers, the product is in the steady-state nearly constant at a given temperature, providing that there is no significant electric field (which might "flush" carriers of both types, or move them from neighbor regions containing more of them to meet together) or externally driven pair generation. The product is a function of the temperature, as the probability of getting enough thermal energy to produce a pair increases with temperature, being approximately exp(−EG/kT), where k is Boltzmann's constant, T is the absolute temperature and EG is bandgap.
In 1954, physical chemist Morris Tanenbaum fabricated the first silicon junction transistor at Bell Labs.[36] However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.[37]
^ "Lesson 6: Extrinsic semiconductors" (PDF). Archived from the original (PDF) on January 28, 2023. Retrieved January 28, 2023.
^ Hulls, K.; McMillan, P. W. (May 22, 1972). "Amorphous semiconductors: a review of current theories". Journal of Physics D: Applied Physics. 5 (5): 865–82. doi:10.1088/0022-3727/5/5/205. S2CID 250874071.
Honsberg, Christiana; Bowden, Stuart. "Semiconductor Materials". Retrieved May 3, 2021.
G. B. Abdullayev, T. D. Dzhafarov, S. Torstveit (Translator), Atomic Diffusion in Semiconductor Structures, Gordon & Breach Science Pub., 1987 ISBN 978-2-88124-152-9
^ Yu, Peter (2010). Fundamentals of Semiconductors. Berlin: Springer-Verlag. ISBN 978-3-642-00709-5.
"1954: Morris Tanenbaum fabricates the first silicon transistor at Bell Labs". The Silicon Engine. Computer History Museum. Retrieved 23 August 2019.
For partial filling at the top of the valence band, it is helpful to introduce the concept of an electron hole. Although the electrons in the valence band are always moving around, a completely full valence band is inert, not conducting any current. If an electron is taken out of the valence band, then the trajectory that the electron would normally have taken is now missing its charge. For the purposes of electric current, this combination of the full valence band, minus the electron, can be converted into a picture of a completely empty band containing a positively charged particle that moves in the same way as the electron. Combined with the negative effective mass of the electrons at the top of the valence band, we arrive at a picture of a positively charged particle that responds to electric and magnetic fields just as a normal positively charged particle would do in a vacuum, again with some positive effective mass.[12] This particle is called a hole, and the collection of holes in the valence band can again be understood in simple classical terms (as with the electrons in the conduction band).
US Navy Electrical Engineering Training Series Archived 2004-06-06 at the Wayback Machine
"Lesson 6: Extrinsic semiconductors" (PDF). Archived from the original (PDF) on January 28, 2023. Retrieved January 28, 2023.
^ Überlingen.), Josef Weiss (de (July 22, 1910). "Experimentelle Beiträge Zur Elektronentheorie Aus dem Gebiet der Thermoelektrizität, Inaugural-Dissertation ... von J. Weiss, ..." Druck- und Verlags-Gesellschaft – via Google Books.
The most common semiconducting materials are crystalline solids, but amorphous and liquid semiconductors are also known. These include hydrogenated amorphous silicon and mixtures of arsenic, selenium, and tellurium in a variety of proportions. These compounds share with better-known semiconductors the properties of intermediate conductivity and a rapid variation of conductivity with temperature, as well as occasional negative resistance. Such disordered materials lack the rigid crystalline structure of conventional semiconductors such as silicon. They are generally used in thin film structures, which do not require material of higher electronic quality, being relatively insensitive to impurities and radiation damage.
Sze, Simon M. (1981). Physics of Semiconductor Devices (2nd ed.). John Wiley and Sons (WIE). ISBN 978-0-471-05661-4.
A high degree of crystalline perfection is also required, since faults in the crystal structure (such as dislocations, twins, and stacking faults) interfere with the semiconducting properties of the material. Crystalline faults are a major cause of defective semiconductor devices. The larger the crystal, the more difficult it is to achieve the necessary perfection. Current mass production processes use crystal ingots between 100 and 300 mm (3.9 and 11.8 in) in diameter, grown as cylinders and sliced into wafers.
^ "1947: Invention of the Point-Contact Transistor". The Silicon Engine. Computer History Museum. Retrieved 23 August 2019.
Advanced Materials Innovation: Managing Global Technology in the 21st century
^ Peter Robin Morris (1990) A History of the World Semiconductor Industry, IET, ISBN 0-86341-227-0, pp. 11–25
By Abdul Al-Azzawi. "Light and Optics: Principles and Practices." 2007. March 4, 2016.
Neamen, Donald. "Semiconductor Physics and Devices" (PDF). Elizabeth A. Jones.
Thomas Johann Seebeck was the first to notice an effect due to semiconductors, in 1821.[27] In 1833, Michael Faraday reported that the resistance of specimens of silver sulfide decreases when they are heated. This is contrary to the behavior of metallic substances such as copper. In 1839, Alexandre Edmond Becquerel reported observation of a voltage between a solid and a liquid electrolyte, when struck by light, the photovoltaic effect. In 1873, Willoughby Smith observed that selenium resistors exhibit decreasing resistance when light falls on them. In 1874, Karl Ferdinand Braun observed conduction and rectification in metallic sulfides, although this effect had been discovered much earlier by Peter Munck af Rosenschold (sv) writing for the Annalen der Physik und Chemie in 1835,[28] and Arthur Schuster found that a copper oxide layer on wires has rectification properties that ceases, when the wires are cleaned. William Grylls Adams and Richard Evans Day observed the photovoltaic effect in selenium in 1876.[29]
Shockley, William (1950). Electrons and holes in semiconductors: with applications to transistor electronics. R. E. Krieger Pub. Co. ISBN 978-0-88275-382-9.
Van Zeghbroeck, Bart (2000). "Carrier densities". Archived from the original on May 3, 2021. Retrieved May 3, 2021.
The conductivity of semiconductors may easily be modified by introducing impurities into their crystal lattice. The process of adding controlled impurities to a semiconductor is known as doping. The amount of impurity, or dopant, added to an intrinsic (pure) semiconductor varies its level of conductivity.[15] Doped semiconductors are referred to as extrinsic.[16] By adding impurity to the pure semiconductors, the electrical conductivity may be varied by factors of thousands or millions.[17]
For example, the pure semiconductor silicon has four valence electrons that bond each silicon atom to its neighbors.[23] In silicon, the most common dopants are group III and group V elements. Group III elements all contain three valence electrons, causing them to function as acceptors when used to dope silicon. When an acceptor atom replaces a silicon atom in the crystal, a vacant state (an electron "hole") is created, which can move around the lattice and function as a charge carrier. Group V elements have five valence electrons, which allows them to act as a donor; substitution of these atoms for silicon creates an extra free electron. Therefore, a silicon crystal doped with boron creates a p-type semiconductor whereas one doped with phosphorus results in an n-type material.[24]
The partial filling of the states at the bottom of the conduction band can be understood as adding electrons to that band. The electrons do not stay indefinitely (due to the natural thermal recombination) but they can move around for some time. The actual concentration of electrons is typically very dilute, and so (unlike in metals) it is possible to think of the electrons in the conduction band of a semiconductor as a sort of classical ideal gas, where the electrons fly around freely without being subject to the Pauli exclusion principle. In most semiconductors, the conduction bands have a parabolic dispersion relation, and so these electrons respond to forces (electric field, magnetic field, etc.) much as they would in a vacuum, though with a different effective mass.[12] Because the electrons behave like an ideal gas, one may also think about conduction in very simplistic terms such as the Drude model, and introduce concepts such as electron mobility.
When ionizing radiation strikes a semiconductor, it may excite an electron out of its energy level and consequently leave a hole. This process is known as electron-hole pair generation. Electron-hole pairs are constantly generated from thermal energy as well, in the absence of any external energy source.
^ "2.4.7.9 The "hot-probe" experiment". ecee.colorado.edu. Archived from the original on 6 March 2021. Retrieved 27 November 2020.
"High-mobility band-like charge transport in a semiconducting two-dimensional metal–organic framework"
^ J. W. Allen (1960). "Gallium Arsenide as a semi-insulator". Nature. 187 (4735): 403–05. Bibcode:1960Natur.187..403A. doi:10.1038/187403b0. S2CID 4183332.
Sadao Adachi (2012). The Handbook on Optical Constants of Semiconductors: In Tables and Figures. World Scientific Publishing. ISBN 978-981-4405-97-3.
"2.4.7.9 The "hot-probe" experiment". ecee.colorado.edu. Archived from the original on 6 March 2021. Retrieved 27 November 2020.
There is a combination of processes that are used to prepare semiconducting materials for ICs. One process is called thermal oxidation, which forms silicon dioxide on the surface of the silicon. This is used as a gate insulator and field oxide. Other processes are called photomasks and photolithography. This process is what creates the patterns on the circuit in the integrated circuit. Ultraviolet light is used along with a photoresist layer to create a chemical change that generates the patterns for the circuit.[4]
"Timeline". The Silicon Engine. Computer History Museum. Retrieved 22 August 2019.
^ As in the Mott formula for conductivity, see Cutler, M.; Mott, N. (1969). "Observation of Anderson Localization in an Electron Gas". Physical Review. 181 (3): 1336. Bibcode:1969PhRv..181.1336C. doi:10.1103/PhysRev.181.1336.
The modern understanding of the properties of a semiconductor relies on quantum physics to explain the movement of charge carriers in a crystal lattice.[1] Doping greatly increases the number of charge carriers within the crystal. When a doped semiconductor contains free holes, it is called "p-type", and when it contains free electrons, it is known as "n-type". The semiconductor materials used in electronic devices are doped under precise conditions to control the concentration and regions of p- and n-type dopants. A single semiconductor device crystal can have many p- and n-type regions; the p–n junctions between these regions are responsible for the useful electronic behavior. Using a hot-point probe, one can determine quickly whether a semiconductor sample is p- or n-type.[2]
^ Louis Nashelsky, Robert L.Boylestad (2006). Electronic Devices and Circuit Theory (9th ed.). India: Prentice-Hall of India Private Limited. pp. 7–10. ISBN 978-81-203-2967-6.
The history of the understanding of semiconductors begins with experiments on the electrical properties of materials. The properties of the time-temperature coefficient of resistance, rectification, and light-sensitivity were observed starting in the early 19th century.
A difference in electric potential on a semiconducting material would cause it to leave thermal equilibrium and create a non-equilibrium situation. This introduces electrons and holes to the system, which interact via a process called ambipolar diffusion. Whenever thermal equilibrium is disturbed in a semiconducting material, the number of holes and electrons changes. Such disruptions can occur as a result of a temperature difference or photons, which can enter the system and create electrons and holes. The process that creates and annihilates electrons and holes are called generation and recombination, respectively.[4]
Überlingen.), Josef Weiss (de (July 22, 1910). "Experimentelle Beiträge Zur Elektronentheorie Aus dem Gebiet der Thermoelektrizität, Inaugural-Dissertation ... von J. Weiss, ..." Druck- und Verlags-Gesellschaft – via Google Books.
In some states, the generation and recombination of electron-hole pairs are in equipoise. The number of electron-hole pairs in the steady state at a given temperature is determined by quantum statistical mechanics. The precise quantum mechanical mechanisms of generation and recombination are governed by the conservation of energy and conservation of momentum.
In certain semiconductors, excited electrons can relax by emitting light instead of producing heat.[5] These semiconductors are used in the construction of light-emitting diodes and fluorescent quantum dots.
^ Honsberg, Christiana; Bowden, Stuart. "Semiconductor Materials". Retrieved May 3, 2021.
^ "Timeline". The Silicon Engine. Computer History Museum. Retrieved 22 August 2019.
Solving this equation for V yields the formula for exponential decay:
More accurate integration and differentiation can be achieved by placing resistors and capacitors as appropriate on the input and feedback loop of operational amplifiers (see operational amplifier integrator and operational amplifier differentiator).
In addition, the transfer function for the voltage across the resistor has a zero located at the origin.
By viewing the circuit as a voltage divider, the voltage across the capacitor is:
The most straightforward way to derive the time domain behaviour is to use the Laplace transforms of the expressions for VC and VR given above. This effectively transforms jω → s. Assuming a step input (i.e.Vin = 0 before t = 0 and then Vin = V afterwards):
The parallel RC circuit is generally of less interest than the series circuit. This is largely because the output voltage Vout is equal to the input voltage Vin — as a result, this circuit does not act as a filter on the input signal unless fed by a current source.
where u(t) is the Heaviside step function and τ = RC is the time constant.
GC=|HC(jω)|=|VC(jω)Vin(jω)|=11+(ωRC)2{\displaystyle G_{C}={\big |}H_{C}(j\omega ){\big |}=\left|{\frac {V_{C}(j\omega )}{V_{\mathrm {in} }(j\omega )}}\right|={\frac {1}{\sqrt {1+\left(\omega RC\right)^{2}}}}}
Consider the output across the capacitor at high frequency, i.e.
The current in the circuit is the same everywhere since the circuit is in series:
These are frequency domain expressions. Analysis of them will show which frequencies the circuits (or filters) pass and reject. This analysis rests on a consideration of what happens to these gains as the frequency becomes very large and very small.
So at DC (0 Hz), the capacitor voltage is in phase with the signal voltage while the resistor voltage leads it by 90°. As frequency increases, the capacitor voltage comes to have a 90° lag relative to the signal and the resistor voltage comes to be in-phase with the signal.
This page was last edited on 28 December 2022, at 11:29 (UTC).
The complex frequency s is, in general, a complex number,
The impulse response for each voltage is the inverse Laplace transform of the corresponding transfer function.It represents the response of the circuit to an input voltage consisting of an impulse or Dirac delta function.
The synthesis can be achieved with a modification of the Foster synthesis or Cauer synthesis used to synthesise LC circuits.In the case of Cauer synthesis, a ladder network of resistors and capacitors will result.[2]
Find sources: "RC circuit" – news · newspapers · books · scholar · JSTOR
ϕC→0andϕR→90∘=π2 radians.{\displaystyle \phi _{C}\to 0\quad {\mbox{and}}\quad \phi _{R}\to 90^{\circ }={\frac {\pi }{2}}{\mbox{ radians}}\,.}
Bakshi, U.A.; Bakshi, A.V., Circuit Analysis - II, Technical Publications, 2009 .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}ISBN 9788184315974.
The transfer function from the input voltage to the voltage across the capacitor is
Sinusoidal steady state is a special case in which the input voltage consists of a pure sinusoid (with no exponential decay).As a result, σ=0{\displaystyle \sigma =0} and the impedance becomes
In this formula, τ is measured in seconds, R in ohms and C in farads.
ω is the sinusoidal angular frequency (in radians per second).
RC circuits can be used to filter a signal by blocking certain frequencies and passing others. The two most common RC filters arethe high-pass filters and low-pass filters; band-pass filters and band-stop filters usually require RLC filters, though crude ones can be made with RC filters.
This shows that, if the output is taken across the capacitor, high frequencies are attenuated (shorted to ground) and low frequencies are passed. Thus, the circuit behaves as a low-pass filter. If, though, the output is taken across the resistor, high frequencies are passed and low frequencies are attenuated (since the capacitor blocks the signal as its frequency approaches 0). In this configuration, the circuit behaves as a high-pass filter.
which is the frequency that the filter will attenuate to half its original power.
The time required for the voltage to fall to .mw-parser-output .sfrac{white-space:nowrap}.mw-parser-output .sfrac.tion,.mw-parser-output .sfrac .tion{display:inline-block;vertical-align:-0.5em;font-size:85%;text-align:center}.mw-parser-output .sfrac .num,.mw-parser-output .sfrac .den{display:block;line-height:1em;margin:0 0.1em}.mw-parser-output .sfrac .den{border-top:1px solid}.mw-parser-output .sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}V0/e is called the RC time constant and is given by,[1]
These equations are for calculating the voltage across the capacitor and resistor respectively while the capacitor is charging; for discharging, the equations are vice versa.These equations can be rewritten in terms of charge and current using the relationships C = Q/V and V = IR (see Ohm's law).
Thus, the voltage across the capacitor tends towards V as time passes, while the voltage across the resistor tends towards 0, as shown in the figures. This is in keeping with the intuitive point that the capacitor will be charging from the supply voltage as time passes, and will eventually be fully charged.
These expressions together may be substituted into the usual expression for the phasor representing the output:
VC(s)=1CsR+1CsVin(s)=11+RCsVin(s){\displaystyle V_{C}(s)={\frac {\frac {1}{Cs}}{R+{\frac {1}{Cs}}}}V_{\mathrm {in} }(s)={\frac {1}{1+RCs}}V_{\mathrm {in} }(s)}
I≈Vin1jωCVin≈IjωC=VC.{\displaystyle {\begin{aligned}I&\approx {\frac {V_{\mathrm {in} }}{\frac {1}{j\omega C}}}\\V_{\mathrm {in} }&\approx {\frac {I}{j\omega C}}=V_{C}\,.\end{aligned}}}
The magnitude of the gains across the two components are
Horowitz, Paul; Hill, Winfield, The Art of Electronics (3rd edition), Cambridge University Press, 2015 ISBN 0521809266.
There are three basic, linear passive lumped analog circuit components: the resistor (R), the capacitor (C), and the inductor (L). These may be combined in the RC circuit, the RL circuit, the LC circuit, and the RLC circuit, with the acronyms indicating which components are used. These circuits, among them, exhibit a large number of important types of behaviour that are fundamental to much of analog electronics. In particular, they are able to act as passive filters. This article considers the RC circuit, in both series and parallel forms, as shown in the diagrams below.
ϕC→−90∘=−π2 radiansandϕR→0.{\displaystyle \phi _{C}\to -90^{\circ }=-{\frac {\pi }{2}}{\mbox{ radians}}\quad {\mbox{and}}\quad \phi _{R}\to 0\,.}
Vin(s)=V⋅1sVC(s)=V⋅11+sRC⋅1sVR(s)=V⋅sRC1+sRC⋅1s.{\displaystyle {\begin{aligned}V_{\mathrm {in} }(s)&=V\cdot {\frac {1}{s}}\\V_{C}(s)&=V\cdot {\frac {1}{1+sRC}}\cdot {\frac {1}{s}}\\V_{R}(s)&=V\cdot {\frac {sRC}{1+sRC}}\cdot {\frac {1}{s}}\,.\end{aligned}}}
These equations show that a series RC circuit has a time constant, usually denoted τ = RC being the time it takes the voltage across the component to either rise (across the capacitor) or fall (across the resistor) to within 1/e of its final value. That is, τ is the time it takes VC to reach V(1 − 1/e) and VR to reach V(1/e).
These results may also be derived by solving the differential equations describing the circuit:
It is sometimes required to synthesise an RC circuit from a given rational function in s.For synthesis to be possible in passive elements, the function must be a positive-real function.To synthesise as an RC circuit, all the critical frequencies (poles and zeroes) must be on the negative real axis and alternate between poles and zeroes with an equal number of each.Further, the critical frequency nearest the origin must be a pole, assuming the rational function represents an impedance rather than an admittance.
ωc=1RCorfc=12πRC{\displaystyle \omega _{\mathrm {c} }={\frac {1}{RC}}\quad {\mbox{or}}\quad f_{\mathrm {c} }={\frac {1}{2\pi RC}}}
GR=|HR(jω)|=|VR(jω)Vin(jω)|=ωRC1+(ωRC)2,{\displaystyle G_{R}={\big |}H_{R}(j\omega ){\big |}=\left|{\frac {V_{R}(j\omega )}{V_{\mathrm {in} }(j\omega )}}\right|={\frac {\omega RC}{\sqrt {1+\left(\omega RC\right)^{2}}}}\,,}
Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "RC circuit" – news · newspapers · books · scholar · JSTOR
This shows that the capacitor current is 90° out of phase with the resistor (and source) current. Alternatively, the governing differential equations may be used:
A resistor–capacitor circuit (RC circuit), or RC filter or RC network, is an electric circuit composed of resistors and capacitors.It may be driven by a voltage or current source and these will produce different responses. A first order RC circuit is composed of one resistor and one capacitor and is the simplest type of RC circuit.
hR(t)=δ(t)−1RCe−tRCu(t)=δ(t)−1τe−tτu(t),{\displaystyle h_{R}(t)=\delta (t)-{\frac {1}{RC}}e^{-{\frac {t}{RC}}}u(t)=\delta (t)-{\frac {1}{\tau }}e^{-{\frac {t}{\tau }}}u(t)\,,}
The range of frequencies that the filter passes is called its bandwidth. The point at which the filter attenuates the signal to half its unfiltered power is termed its cutoff frequency. This requires that the gain of the circuit be reduced to
The rate of change is a fractional 1 − 1/e per τ. Thus, in going from t = Nτ to t = (N + 1)τ, the voltage will have moved about 63.2% of the way from its level at t = Nτ toward its final value. So the capacitor will be charged to about 63.2% after τ, and essentially fully charged (99.3%) after about 5τ. When the voltage source is replaced with a short circuit, with the capacitor fully charged, the voltage across the capacitor drops exponentially with t from V towards 0. The capacitor will be discharged to about 36.8% after τ, and essentially fully discharged (0.7%) after about 5τ. Note that the current, I, in the circuit behaves as the voltage across the resistor does, via Ohm's Law.
This means that the capacitor has time to charge up until its voltage is almost equal to the source's voltage. Considering the expression for I again, when
Consider the output across the resistor at low frequency i.e.,
The first equation is solved by using an integrating factor and the second follows easily; the solutions are exactly the same as those obtained via Laplace transforms.
This means that the capacitor has insufficient time to charge up and so its voltage is very small. Thus the input voltage approximately equals the voltage across the resistor. To see this, consider the expression for I{\displaystyle I} given above:
4Series circuit											Toggle Series circuit subsection																					4.1Transfer functions																								4.1.1Poles and zeros																														4.2Gain and phase																											4.3Current																											4.4Impulse response																											4.5Frequency-domain considerations																											4.6Time-domain considerations																								4.6.1Integrator																											4.6.2Differentiator
.mw-parser-output .sfrac{white-space:nowrap}.mw-parser-output .sfrac.tion,.mw-parser-output .sfrac .tion{display:inline-block;vertical-align:-0.5em;font-size:85%;text-align:center}.mw-parser-output .sfrac .num,.mw-parser-output .sfrac .den{display:block;line-height:1em;margin:0 0.1em}.mw-parser-output .sfrac .den{border-top:1px solid}.mw-parser-output .sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}V0/e
Clearly, the phases also depend on frequency, although this effect is less interesting generally than the gain variations.
The complex impedance, ZC (in ohms) of a capacitor with capacitance C (in farads) is
Similarly, the transfer function from the input to the voltage across the resistor is
σ is the exponential decay constant (in nepers per second), and
When fed by a current source, the transfer function of a parallel RC circuit is:
where V0 is the capacitor voltage at time t = 0.
Cady, W. G.; Arnold, H. D. (1907). "On the electric arc between metallic electrodes". American Journal of Science. 24 (143): 406. Retrieved April 12, 2017.
Vig, John R. and Ballato, Arthur "Frequency Control Devices" in Thurston, R. N.; Pierce, Allan D.; Papadakis, Emmanuel P. (1998). Reference for Modern Instrumentation, Techniques, and Technology: Ultrasonic Instruments and Devices II. Elsevier. p. 227. ISBN 0080538916.
Nahin, Paul J. (2001). The Science of Radio: With Matlab and Electronics Workbench Demonstration, 2nd Ed. Springer. p. 280. ISBN 978-0387951508.
1Harmonic oscillators											Toggle Harmonic oscillators subsection																					1.1Feedback oscillator																											1.2Negative-resistance oscillator
Ulrich Rohde, Ajay Poddar, and Georg Bock, The Design of Modern Microwave Oscillators for Wireless Applications: Theory and Optimization, (543 pages) John Wiley & Sons, 2005, ISBN 0-471-72342-8.
A feedback oscillator circuit consists of two parts connected in a feedback loop; an amplifier A{\displaystyle A} and an electronic filter β(jω){\displaystyle \beta (j\omega )}.The filter's purpose is to limit the frequencies that can pass through the loop so the circuit only oscillates at the desired frequency.[10]Since the filter and wires in the circuit have resistance they consume energy and the amplitude of the signal drops as it passes through the filter.The amplifier is needed to increase the amplitude of the signal to compensate for the energy lost in the other parts of the circuit, so the loop will oscillate, as well as supply energy to the load attached to the output.
This page was last edited on 9 March 2023, at 03:35 (UTC).
^ a b c d e f g h Garg, Rakesh Kumar; Ashish Dixit; Pavan Yadav (2008). Basic Electronics. Firewall Media. p. 280. ISBN 978-8131803028.
van der Tang, J.; Kasperkovitz, Dieter; van Roermund, Arthur (2006). High-Frequency Oscillator Design for Integrated Transceivers. Springer Science and Business Media. p. 51. ISBN 0306487160.
^ a b c d Hong, Sungook (2001). Wireless: From Marconi's Black-Box to the Audion. MIT Press. ISBN 978-0262082983., pp. 161–165
Since Aβ(jω){\displaystyle A\beta (j\omega )} is a complex number with two parts, a magnitude and an angle, the above equation actually consists of two conditions:[16][15][12]
The ratio of output to input of the loop, vovi=Aβ(jω){\displaystyle {v_{o} \over v_{i}}=A\beta (j\omega )}, is called the loop gain. So the condition for oscillation is that the loop gain must be one[13][12][14][15]
.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Snelgrove, Martin (2011). "Oscillator". McGraw-Hill Encyclopedia of Science and Technology, 10th Ed., Science Access online service. McGraw-Hill. Archived from the original on July 19, 2013. Retrieved March 1, 2012.
An RF oscillator produces signals in the radio frequency (RF) range of about 100 kHz to 100 GHz.[2]
In general, the phase shift of the feedback network increases with increasing frequency so there are only a few discrete frequencies (often only one) which satisfy the second equation.[15][10] If the amplifier gain A{\displaystyle A}is high enough that the loop gain is unity (or greater, see Startup section) at one of these frequencies, the circuit will oscillate at that frequency. Many amplifiers such as common-emitter transistor circuits are "inverting", meaning that their output voltage decreases when their input increases.[16][12]In these the amplifier provides 180° phase shift, so the circuit will oscillate at the frequency at which the feedback network provides the other 180° phase shift.[13][12]
Gonzalez, Guillermo (2006). Foundations of Oscillator Circuit Design (PDF). Artech House. pp. 3–5. ISBN 9781596931633.
Hijiya, James A. (1992). Lee De Forest and the Fatherhood of Radio. Lehigh University Press. pp. 89–90. ISBN 978-0934223232.
The first and most widely used relaxation oscillator circuit, the astable multivibrator, was invented in 1917 by French engineers Henri Abraham and Eugene Bloch.[64][65][66]They called their cross-coupled, dual-vacuum-tube circuit a multivibrateur, because the square-wave signal it produced was rich in harmonics,[65][66] compared to the sinusoidal signal of other vacuum-tube oscillators.
Glazebrook, Richard (1922). A Dictionary of Applied Physics, Vol. 2: Electricity. London: Macmillan and Co. Ltd. pp. 633–634.
^ Hempstead, Colin; William E. Worthington (2005). Encyclopedia of 20th-Century Technology. Vol. 2. Taylor & Francis. p. 648. ISBN 978-1579584641.
At frequencies well below the poles of the amplifying device, the amplifier will act as a pure gain A{\displaystyle A}, but if the oscillation frequency ω0{\displaystyle \omega _{0}} is near the amplifier's cutoff frequency ωC{\displaystyle \omega _{C}}, within 0.1ωC{\displaystyle 0.1\omega _{C}}, the active device can no longer be considered a 'pure gain', and it will contribute some phase shift to the loop.[13][17]
^ G. Fitzgerald, On the Driving of Electromagnetic Vibrations by Electromagnetic and Electrostatic Engines, read at the January 22, 1892, meeting of the Physical Society of London, in Larmor, Joseph, ed. (1902). The Scientific Writings of the late George Francis Fitzgerald. London: Longmans, Green and Co. pp. 277–281.
As the amplitude of the signal current through them increases during oscillator startup, the increasing resistance of these devices reduces the loop gain.The essential characteristic of all these circuits is that the nonlinear gain-control circuit must have a long time constant, much longer than a singleperiod of the oscillation.Therefore over a single cycle they act as virtually linear elements, and so introduce very little distortion.The operation of these circuits is somewhat analogous to an automatic gain control (AGC) circuit in a radio receiver.The Wein bridge oscillator is a widely used circuit in which this type of gain stabilization is used.
Fleming, John Ambrose (1919). The Thermionic Valve and its Developments in Radiotelegraphy and Telephony. London: The Wireless Press. pp. 148–155.
An oscillator can be designed so that the oscillation frequency can be varied over some range by an input voltage or current. These voltage controlled oscillators are widely used in phase-locked loops, in which the oscillator's frequency can be locked to the frequency of another oscillator. These are ubiquitous in modern communications circuits, used in filters, modulators, demodulators, and forming the basis of frequency synthesizer circuits which are used to tune radios and televisions.
^ a b Ellinger, Frank (2008). Radio Frequency Integrated Circuits and Technologies, 2nd Ed. USA: Springer. pp. 391–394. ISBN 978-3540693246.
US 500630, Thomson, Elihu, "Method of and Means for Producing Alternating Currents", published 18 July 1892, issued 4 July 1893
^ Toumazou, Chris; Moschytz, George S.; Gilbert, Barrie (2004). Trade-Offs in Analog Circuit Design: The Designer's Companion, Part 1. Springer Science and Business Media. pp. 565–566. ISBN 9781402080463.
Razavi, Behzad (2001)Design of Analog CMOS Integrated Circuits, p. 487-489
Rhea, Randall W. (2014). Discrete Oscillator Design: Linear, Nonlinear, Transient, and Noise Domains. Artech House. pp. 11–12. ISBN 978-1608070480.
Razavi, Behzad (2001). Design of Analog CMOS Integrated Circuits. The McGraw-Hill Companies. pp. 482–484. ISBN 7302108862.
The sine wave cannot grow indefinitely; in all real oscillators some nonlinear process in the circuit limits its amplitude,[15][33] reducing the gain as the amplitude increases, resulting in stable operation at some constant amplitude.[15] In most oscillators this nonlinearity is simply the saturation(limiting) of the amplifying device, the transistor, vacuum tube or op-amp.[31][34][35][13]The maximum voltage swing of the amplifier's output is limited by the DC voltage provided by its power supply.Another possibility is that the output may be limited by the amplifier slew rate.
^ a b c d Carter, Bruce; Mancini, Ron (2009). Op Amps for Everyone, 3rd Ed. Elsevier. pp. 345–347. ISBN 9781856175050.
The harmonic, or linear, oscillator produces a sinusoidal output.[2][4]There are two types:
"A history of the regeneration circuit: From invention to patent litigation"
An exception to the above are high Q oscillator circuits such as crystal oscillators; the narrow bandwidth of the crystal removes the harmonics from the output, producing a 'pure' sinusoidal wave with almost no distortion even with large loop gains.
^ .mw-parser-output .citation{word-wrap:break-word}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}US 500630, Thomson, Elihu, "Method of and Means for Producing Alternating Currents", published 18 July 1892, issued 4 July 1893
^ a b Glazebrook, Richard (1922). A Dictionary of Applied Physics, Vol. 2: Electricity. London: Macmillan and Co. Ltd. pp. 633–634.
^ Huijsing, Johan; van de Plassche, Rudy J.; Sansen, Willy (2013). Analog Circuit Design. Springer Scientific and Business Media. p. 77. ISBN 978-1475724622.
The Thermionic Valve and its Developments in Radiotelegraphy and Telephony
The most common form of linear oscillator is an electronic amplifier such as a transistor or operational amplifier connected in a feedback loop with its output fed back into its input through a frequency selective electronic filter to provide positive feedback.When the power supply to the amplifier is switched on initially, electronic noise in the circuit provides a non-zero signal to get oscillations started. The noise travels around the loop and is amplified and filtered until very quickly it converges on a sine wave at a single frequency.
^ Armstrong, Edwin H. (September 1915). "Some recent developments in the Audion receiver" (PDF). Proc. IRE. 3 (9): 215–247. doi:10.1109/jrproc.1915.216677. S2CID 2116636. Retrieved August 29, 2012.
At high frequencies it becomes difficult to physically implement feedback oscillators because of shortcomings of the components.Since at high frequencies the tank circuit has very small capacitance and inductance,parasitic capacitance and parasitic inductance of component leads and PCB traces become significant.These may create unwanted feedback paths between the output and input of the active device, creating instability and oscillations at unwanted frequencies (parasitic oscillation). Parasitic feedback paths inside the active device itself, such as the interelectrode capacitance between output and input, make the device unstable. The input impedance of the active device falls with frequency, so it may load the feedback network.As a result, stable feedback oscillators are difficult to build for frequencies above 500 MHz, and negative resistance oscillators are usually used for frequencies above this.
^ a b c d Stephan, Karl (2015). Analog and Mixed-Signal Electronics. John Wiley and Sons. pp. 192–193. ISBN 978-1119051800.
Hong, Sungook (2003). "A history of the regeneration circuit: From invention to patent litigation" (PDF). IEEE. Retrieved August 29, 2012., pp. 9–10
^ a b Maas, Stephen A. (2003). Nonlinear Microwave and RF Circuits, 2nd Ed. Artech House. pp. 542–544. ISBN 978-1580534840.
As the amplitude of the output nears the power supply voltage rails, the amplifier begins to saturate on the peaks (top and bottom) of the sine wave, flattening or "clipping" the peaks.[17]Since the output of the amplifier can no longer increase with increasing input, further increases in amplitude cause the equivalent gain of the amplifier and thus the loop gain to decrease.[30]The amplitude of the sine wave, and the resulting clipping, continues to grow until the loop gain is reduced to unity, |Aβ(jω0)|=1{\displaystyle |A\beta (j\omega _{0})|\;=\;1\,}, satisfying the Barkhausen criterion, at which point the amplitude levels off and steady state operation is achieved,[15] with the output a slightly distorted sine wave with peak amplitude determined by the supply voltage.This is a stable equilibrium; if the amplitude of the sine wave increases for some reason, increased clipping of the output causes the loop gain |Aβ(jω0)|{\displaystyle |A\beta (j\omega _{0})|} to drop below one temporarily, reducing the sine wave's amplitude back to its unity-gain value.Similarly if the amplitude of the wave decreases, the decreased clipping will cause the loop gain to increase above one, increasing the amplitude.
"Wireless telephony, in theory and practice". N.Y. Van Nostrand. 1908.
^ "Notes". The Electrical Review. 62 (1578): 812. February 21, 1908. Retrieved April 12, 2017.
Trade-Offs in Analog Circuit Design: The Designer's Companion, Part 1
If the small signal loop gain is made close to one, just slightly greater, the output waveform will have minimum distortion, and the frequency will be most stable and independent of supply voltage and load impedance.However, the oscillator may be slow starting up, and a small decrease in gain due to a variation in component values may prevent it from oscillating.
^ a b c d e f Carr, Joe (2002). RF Components and Circuits. Newnes. pp. 125–126. ISBN 0080498078.
Wireless Communication Electronics: Introduction to RF Circuits and Design Techniques
^ a b c d Rhea, Randall W. (2014). Discrete Oscillator Design: Linear, Nonlinear, Transient, and Noise Domains. Artech House. pp. 11–12. ISBN 978-1608070480.
|A||β(jω0)|=1(1){\displaystyle |A||\beta (j\omega _{0})|=1\,\qquad \qquad \qquad \qquad \qquad \qquad {\text{(1)}}}
^ a b Gottlieb, Irving M. (1997). Practical Oscillator Handbook. Elsevier. pp. 39–41. ISBN 0080539386.
E. Rubiola, Phase Noise and Frequency Stability in Oscillators Cambridge University Press, 2008. ISBN 978-0-521-88677-2.
To determine the frequency(s) ω0=2πf0{\displaystyle \omega _{0}\;=\;2\pi f_{0}} at which a feedback oscillator circuit will oscillate, the feedback loop is thought of as broken at some point (see diagrams) to give an input and output port. A sine wave is applied to the input vi(t)=Viejωt{\displaystyle v_{i}(t)=V_{i}e^{j\omega t}} and the amplitude and phase of the sine wave after going through the loop vo=Voej(ωt+ϕ){\displaystyle v_{o}=V_{o}e^{j(\omega t+\phi )}} is calculated[11][12]
^ a b Kazimierczuk, Marian K. (2014). RF Power Amplifiers, 2nd Ed. John Wiley and Sons. pp. 586–587. ISBN 978-1118844335.
4Theory of feedback oscillators											Toggle Theory of feedback oscillators subsection																					4.1Frequency of oscillation - the Barkhausen criterion																											4.2Frequency stability																											4.3Tunability																											4.4Startup and amplitude of oscillation																											4.5Design procedure																											4.6Amplitude-stabilized oscillators																											4.7Frequency limitations
^ a b c d "Sinusoidal Oscillators" (DOC). Course notes: ECE3434 Advanced Electronic Circuits. Electrical and Computer Engineering Dept., Mississippi State University. Summer 2015. Retrieved September 28, 2015., p. 4-7
^ a b c Fleming, John Ambrose (1919). The Thermionic Valve and its Developments in Radiotelegraphy and Telephony. London: The Wireless Press. pp. 148–155.
The magnitude of the gain (amplification) around the loop at ω0 must be unity
During startup, while the amplitude of the oscillation is small, the circuit is approximately linear, so the analysis used in the Barkhausen criterion is applicable.When the amplitude becomes large enough that the amplifier becomes nonlinear, technically the frequency domain analysis used in normal amplifier circuits is no longer applicable, so the "gain" of the circuit is undefined.However the filter attenuates the harmonic components produced by the nonlinearity of the amplifier, so the fundamental frequency component sin⁡ω0t{\displaystyle \sin \omega _{0}t} mainly determines the loop gain[32] (this is the "harmonic balance" analysis technique for nonlinear circuits).
Lesurf, Jim (2006). "Feedback Oscillators". The Scots Guide to Electronics. School of Physics and Astronomy, Univ. of St. Andrewes, Scotland. Retrieved 28 September 2015.
^ "Wireless telephony, in theory and practice". N.Y. Van Nostrand. 1908.
^ a b Horowitz, Paul; Hill, Winfield (2015). The Art of Electronics. USA. p. 425. ISBN 978-0-521-80926-9.
^ US 789449, Poulsen, Valdemar, "Method of Producing Alternating Currents with a High Number of Vibrations", issued 9 May 1905
The amount of harmonic distortion in the output is dependent on how much excess loop gain the circuit has:[30][31][17][10]
Stephan, Karl (2015). Analog and Mixed-Signal Electronics. John Wiley and Sons. pp. 192–193. ISBN 978-1119051800.
Schubert, Thomas F. Jr.; Kim, Ernest M. (2016). Fundamentals of Electronics. Book 4: Oscillators and Advanced Electronics Topics. Morgan and Claypool. pp. 926–928. ISBN 978-1627055697.
Fundamentals of Electronics. Book 4: Oscillators and Advanced Electronics Topics
An electronic oscillator is an electronic circuit that produces a periodic, oscillating electronic signal, often a sine wave or a square wave or a triangle wave.[1][2][3]Oscillators convert direct current (DC) from a power supply to an alternating current (AC) signal.They are widely used in many electronic devices ranging from simplest clock generators to digital instruments (like calculators) and complex computers and peripherals etc.[3]Common examples of signals generated by oscillators include signals broadcast by radio and television transmitters, clock signals that regulate computers and quartz clocks, and the sounds produced by electronic beepers and video games.[1]
In order for oscillations to start up in the circuit from zero, the circuit must have "excess gain"; the loop gain for small signals must be greater than one at its oscillation frequency[15][10][16][13][30]
^ a b c d e f g h i j Lesurf, Jim (2006). "Feedback Oscillators". The Scots Guide to Electronics. School of Physics and Astronomy, Univ. of St. Andrewes, Scotland. Retrieved 28 September 2015.
Square-wave relaxation oscillators are used to provide the clock signal for sequential logic circuits such as timers and counters, although crystal oscillators are often preferred for their greater stability. Triangle-wave or sawtooth oscillators are used in the timebase circuits that generate the horizontal deflection signals for cathode ray tubes in analogue oscilloscopes and television sets. They are also used in voltage-controlled oscillators (VCOs), inverters and switching power supplies, dual-slope analog to digital converters (ADCs), and in function generators to generate square and triangle waves for testing equipment. In general, relaxation oscillators are used at lower frequencies and have poorer frequency stability than linear oscillators.
^ a b c Nahin, Paul J. (2001). The Science of Radio: With Matlab and Electronics Workbench Demonstration, 2nd Ed. Springer. p. 280. ISBN 978-0387951508.
Armstrong, Edwin H. (September 1915). "Some recent developments in the Audion receiver" (PDF). Proc. IRE. 3 (9): 215–247. doi:10.1109/jrproc.1915.216677. S2CID 2116636. Retrieved August 29, 2012.
^ Anders, André (2009). Cathodic Arcs: From Fractal Spots to Energetic Condensation. Springer Science and Business Media. pp. 31–32. ISBN 978-0387791081.
Reference for Modern Instrumentation, Techniques, and Technology: Ultrasonic Instruments and Devices II
^ Maas, Stephen A. (2003). Nonlinear Microwave and RF Circuits. Artech House. pp. 537–540. ISBN 1580536115.
GB 190315599, Poulsen, Valdemar, "Improvements relating to the Production of Alternating Electric Currents", issued 14 July 1904
Hempstead, Colin; William E. Worthington (2005). Encyclopedia of 20th-Century Technology. Vol. 2. Taylor & Francis. p. 648. ISBN 978-1579584641.
The frequency of RC and LC oscillators can be tuned over a wide range by using variable components in the filter.A microwave cavity can be tuned mechanically by moving one of the walls. In contrast, a quartz crystal is a mechanical resonator whose resonant frequency is mainly determined by its dimensions, so a crystal oscillator's frequency is only adjustable over a very narrow range, a tiny fraction of one percent.[22][23][24][25][26][27][28] It's frequency can be changed slightly by using a trimmer capacitor in series or parallel with the crystal.[22]
^ van der Tang, J.; Kasperkovitz, Dieter; van Roermund, Arthur (2006). High-Frequency Oscillator Design for Integrated Transceivers. Springer Science and Business Media. p. 51. ISBN 0306487160.
.mw-parser-output .citation{word-wrap:break-word}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}US 500630, Thomson, Elihu, "Method of and Means for Producing Alternating Currents", published 18 July 1892, issued 4 July 1893
For stable operation, the feedback loop must include a nonlinear component which reduces the gain back to unity as the amplitude increases to its operating value.[15][10]
Räisänen, Antti V.; Arto Lehto (2003). Radio Engineering for Wireless Communication and Sensor Applications. USA: Artech House. pp. 180–182. ISBN 978-1580535427.
G. Fitzgerald, On the Driving of Electromagnetic Vibrations by Electromagnetic and Electrostatic Engines, read at the January 22, 1892, meeting of the Physical Society of London, in Larmor, Joseph, ed. (1902). The Scientific Writings of the late George Francis Fitzgerald. London: Longmans, Green and Co. pp. 277–281.
In negative-resistance oscillators, a resonant circuit, such as an LC circuit, crystal, or cavity resonator, is connected across a device with negative differential resistance, and a DC bias voltage is applied to supply energy.A resonant circuit by itself is "almost" an oscillator; it can store energy in the form of electronic oscillations if excited, but because it has electrical resistance and other losses the oscillations are damped and decay to zero.The negative resistance of the active device cancels the (positive) internal loss resistance in the resonator, in effect creating a resonator with no damping, which generates spontaneous continuous oscillations at its resonant frequency.
Carter, Bruce; Mancini, Ron (2009). Op Amps for Everyone, 3rd Ed. Elsevier. pp. 345–347. ISBN 9781856175050.
Kurokawa, K. (July 1969). "Some Basic Characteristics of Broadband Negative Resistance Oscillator Circuits" (PDF). Bell System Tech. J. 48 (6): 1937–1955. doi:10.1002/j.1538-7305.1969.tb01158.x. Retrieved December 8, 2012.Eq. 10 is a necessary condition for oscillation; eq. 12 is a sufficient condition,
Since oscillators depend on nonlinearity for their operation, the usual linear frequency domain circuit analysis techniques used for amplifiers based on the Laplace transform, such as root locus and gain and phase plots (Bode plots), cannot capture their full behavior.[29]To determinestartup and transient behavior and calculate the detailed shape of the output waveform, electronic circuit simulation computer programs like SPICE are used.[29]A typical design procedure for oscillator circuits is to use linear techniques such as the Barkhausen stability criterion or Nyquist stability criterion to design the circuit, then simulate the circuit on computer to make sure it starts up reliably and to determine the nonlinear aspects of operation such as harmonic distortion.[10][29][31]Component values are tweaked until the simulation results are satisfactory.The distorted oscillations of real-world (nonlinear) oscillators are called limit cycles and are studied in nonlinear control theory.
^ Roberge, James K. (1975). Operational Amplifiers: Theory and Practice (PDF). John Wiley and Sons. pp. 487–488. ISBN 0471725854.
^ Sobot, Robert (2012). Wireless Communication Electronics: Introduction to RF Circuits and Design Techniques. Springer Science and Business Media. pp. 221–222. ISBN 978-1461411161.
Horowitz, Paul; Hill, Winfield (2015). The Art of Electronics. USA. p. 425. ISBN 978-0-521-80926-9.
Stephan, Karl (2015). Analog and Mixed-Signal Electronics. John Wiley and Sons. pp. 187–188. ISBN 978-1119051800.
Vacuum-tube feedback oscillators became the basis of radio transmission by 1920.However, the triode vacuum tube oscillator performed poorly above 300 MHz because of interelectrode capacitance.[citation needed]To reach higher frequencies, new "transit time" (velocity modulation) vacuum tubes were developed, in which electrons traveled in "bunches" through the tube.The first of these was the Barkhausen–Kurz oscillator (1920), the first tube to produce power in the UHF range.The most important and widely used were the klystron (R. and S. Varian, 1937) and the cavity magnetron (J. Randall and H. Boot, 1940).
^ a b c d e f g h Gonzalez, Guillermo (2006). Foundations of Oscillator Circuit Design (PDF). Artech House. pp. 3–5. ISBN 9781596931633.
^ "Oscillator Application Notes" (PDF). Support. Frequency Management International, CA. Retrieved October 1, 2015.
Vidkjaer, Jens. "Ch. 6: Oscillators" (PDF). Class Notes: 31415 RF Communications Circuits. Technical Univ. of Denmark. Retrieved October 8, 2015. p. 8-9
"Oscillator Application Notes" (PDF). Support. Frequency Management International, CA. Retrieved October 1, 2015.
If the small signal loop gain is made significantly greater than one, the oscillator starts up faster, but more severe clipping of the sine wave occurs, and thus the resulting distortion of the output waveform increases.The oscillation frequency becomes more dependent on the supply voltage and current drawn by the load.[17]
A nonlinear or relaxation oscillator produces a non-sinusoidal output, such as a square, sawtooth or triangle wave.[4]It consists of an energy-storing element (a capacitor or, more rarely, an inductor) and a nonlinear switching device (a latch, Schmitt trigger, or negative-resistance element) connected in a feedback loop. The switching device periodically charges and discharges the energy stored in the storage element thus causing abrupt changes in the output waveform.
^ GB 190315599, Poulsen, Valdemar, "Improvements relating to the Production of Alternating Electric Currents", issued 14 July 1904
^ a b c d e f g h i j k l m n Chattopadhyay, D. (2006). Electronics (fundamentals And Applications). New Age International. pp. 224–225. ISBN 978-81-224-1780-7.
Froehlich, Fritz E.; Kent, Allen (1991). The Froehlich/Kent Encyclopedia of Telecommunications, Volume 3. CRC Press. p. 448. ISBN 0824729021.
The vacuum-tube feedback oscillator was invented around 1912, when it was discovered that feedback ("regeneration") in the recently invented audion vacuum tube could produce oscillations.At least six researchers independently made this discovery, although not all of them can be said to have a role in the invention of the oscillator.[51][52]In the summer of 1912, Edwin Armstrong observed oscillations in audion radio receiver circuits[53] and went on to use positive feedback in his invention of the regenerative receiver.[54][55]Austrian Alexander Meissner independently discovered positive feedback and invented oscillators in March 1913.[53][56] Irving Langmuir at General Electric observed feedback in 1913.[56]Fritz Lowenstein may have preceded the others with a crude oscillator in late 1911.[57]In Britain, H. J. Round patented amplifying and oscillating circuits in 1913.[53]In August 1912, Lee De Forest, the inventor of the audion, had also observed oscillations in his amplifiers, but he didn't understand the significance and tried to eliminate it[58][59] until he read Armstrong's patents in 1914,[60] which he promptly challenged.[61]Armstrong and De Forest fought a protracted legal battle over the rights to the "regenerative" oscillator circuit[61][62] which has been called "the most complicated patent litigation in the history of radio".[63] De Forest ultimately won before the Supreme Court in 1934 on technical grounds, but most sources regard Armstrong's claim as the stronger one.[59][61]
Toumazou, Chris; Moschytz, George S.; Gilbert, Barrie (2004). Trade-Offs in Analog Circuit Design: The Designer's Companion, Part 1. Springer Science and Business Media. pp. 565–566. ISBN 9781402080463.
An audio oscillator produces frequencies in the audio range, about 16 Hz to 20 kHz.[2]
Radio frequency VCOs are usually made by adding a varactor diode to the tuned circuit or resonator in an oscillator circuit. Changing the DC voltage across the varactor changes its capacitance, which changes the resonant frequency of the tuned circuit. Voltage controlled relaxation oscillators can be constructed by charging and discharging the energy storage capacitor with a voltage controlled current source. Increasing the input voltage increases the rate of charging the capacitor, decreasing the time between switching events.
^ Terman, Frederick E. (1943). Radio Engineer's Handbook (PDF). McGraw-Hill. p. 497.
Ellinger, Frank (2008). Radio Frequency Integrated Circuits and Technologies, 2nd Ed. USA: Springer. pp. 391–394. ISBN 978-3540693246.
^ a b c d e f g h Schubert, Thomas F. Jr.; Kim, Ernest M. (2016). Fundamentals of Electronics. Book 4: Oscillators and Advanced Electronics Topics. Morgan and Claypool. pp. 926–928. ISBN 978-1627055697.
In a crystal oscillator circuit the filter is a piezoelectric crystal (commonly a quartz crystal).[2][4]The crystal mechanically vibrates as a resonator, and its frequency of vibration determines the oscillation frequency. Crystals have a very high Q-factor and also better temperature stability than tuned circuits, so crystal oscillators have much better frequency stability than LC or RC oscillators. Crystal oscillators are the most common type of linear oscillator, used to stabilize the frequency of most radio transmitters, and to generate the clock signal in computers and quartz clocks. Crystal oscillators often use the same circuits as LC oscillators, with the crystal replacing the tuned circuit;[2] the Pierce oscillator circuit is also commonly used. Quartz crystals are generally limited to frequencies of 30 MHz or below.[2]Other types of resonators, dielectric resonators and surface acoustic wave (SAW) devices, are used to control higher frequency oscillators, up into the microwave range.For example, SAW oscillators are used to generate the radio signal in cell phones.[5]
Ring oscillators are built of a ring of active delay stages.Generally the ring has an odd number of inverting stages, so that there is no single stable state for the internal ring voltages. Instead, a single transition propagates endlessly around the ring.
In an RC oscillator circuit, the filter is a network of resistors and capacitors.[2][4] RC oscillators are mostly used to generate lower frequencies, for example in the audio range.Common types of RC oscillator circuits are the phase shift oscillator and the Wien bridge oscillator. LR oscillators, using inductor and resistor filters also exist, however they are much less common due to the required size of an inductor to achieve a value appropriate for use at lower frequencies.
Some of the more common relaxation oscillator circuits are listed below:
GB 190021629, Duddell, William du Bois, "Improvements in and connected with Means for the Conversion of Electrical Energy, Derived from a Source of Direct Current, into Varying or Alternating Currents", published 29 Nov 1900, issued 23 Nov 1901
^ Abraham, H.; E. Bloch (1919). "Measurement of period of high frequency oscillations". Comptes Rendus. 168: 1105.
Morse, A. H. (1925), Radio: Beam and Broadcast: Its story and patents, London: Ernest Benn. History of radio in 1925. Oscillator claims 1912; De Forest and Armstrong court case cf p. 45. Telephone hummer/oscillator by A. S. Hibbard in 1890 (carbon microphone has power gain); Larsen "used the same principle in the production of alternating current from a direct current source"; accidental development of vacuum tube oscillator; all at p. 86. Von Arco and Meissner first to recognize application to transmitter; Round for first transmitter; nobody patented triode transmitter at p. 87.
Gottlieb, Irving M. (1997). Practical Oscillator Handbook. Elsevier. pp. 39–41. ISBN 0080539386.
^ a b c d Stephan, Karl (2015). Analog and Mixed-Signal Electronics. John Wiley and Sons. pp. 187–188. ISBN 978-1119051800.
Scroggie, M. G.; Amos, S. W. (2013). Foundations of Wireless and Electronics. Elsevier. pp. 241–242. ISBN 978-1483105574.
Roberge, James K. (1975). Operational Amplifiers: Theory and Practice (PDF). John Wiley and Sons. pp. 487–488. ISBN 0471725854.
Sobot, Robert (2012). Wireless Communication Electronics: Introduction to RF Circuits and Design Techniques. Springer Science and Business Media. pp. 221–222. ISBN 978-1461411161.
Oscillators are often characterized by the frequency of their output signal:
An alternate mathematical stability test sometimes used instead of the Barkhausen criterion is the Nyquist stability criterion.This has a wider applicability than the Barkhausen, so it can identify some of the circuits which pass the Barkhausen criterion but do not oscillate.
^ a b c d Räisänen, Antti V.; Arto Lehto (2003). Radio Engineering for Wireless Communication and Sensor Applications. USA: Artech House. pp. 180–182. ISBN 978-1580535427.
Some of the many harmonic oscillator circuits are listed below:
^ a b Hijiya, James A. (1992). Lee De Forest and the Fatherhood of Radio. Lehigh University Press. pp. 89–90. ISBN 978-0934223232.
^ a b .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Snelgrove, Martin (2011). "Oscillator". McGraw-Hill Encyclopedia of Science and Technology, 10th Ed., Science Access online service. McGraw-Hill. Archived from the original on July 19, 2013. Retrieved March 1, 2012.
Since in the complete circuit vo{\displaystyle v_{o}} is connected to vi{\displaystyle v_{i}}, for oscillations to exist
US 789449, Poulsen, Valdemar, "Method of Producing Alternating Currents with a High Number of Vibrations", issued 9 May 1905
Garg, Rakesh Kumar; Ashish Dixit; Pavan Yadav (2008). Basic Electronics. Firewall Media. p. 280. ISBN 978-8131803028.
In an LC oscillator circuit, the filter is a tuned circuit (often called a tank circuit) consisting of an inductor (L) and capacitor (C) connected together, which acts as a resonator.[2][4]Charge flows back and forth between the capacitor's plates through the inductor, so the tuned circuit can store electrical energy oscillating at its resonant frequency. The amplifier adds power to compensate for resistive energy losses in the circuit and supplies the power for the output signal. LC oscillators are often used at radio frequencies,[2] when a tunable frequency source is necessary, such as in signal generators, tunable radio transmitters and the local oscillators in radio receivers.Typical LC oscillator circuits are the Hartley, Colpitts[2] and Clapp circuits.
A low-frequency oscillator (LFO) is an electronic oscillator that generates a frequency below approximately 20 Hz. This term is typically used in the field of audio synthesizers, to distinguish it from an audio frequency oscillator.
First Principles of Physics: Or Natural Philosophy, Designed for the Use of Schools and Colleges
Huijsing, Johan; van de Plassche, Rudy J.; Sansen, Willy (2013). Analog Circuit Design. Springer Scientific and Business Media. p. 77. ISBN 978-1475724622.
Kazimierczuk, Marian K. (2014). RF Power Amplifiers, 2nd Ed. John Wiley and Sons. pp. 586–587. ISBN 978-1118844335.
^ Vig, John R. and Ballato, Arthur "Frequency Control Devices" in Thurston, R. N.; Pierce, Allan D.; Papadakis, Emmanuel P. (1998). Reference for Modern Instrumentation, Techniques, and Technology: Ultrasonic Instruments and Devices II. Elsevier. p. 227. ISBN 0080538916.
The first practical oscillators were based on electric arcs, which were used for lighting in the 19th century. The current through an arc light is unstable due to its negative resistance, and often breaks into spontaneous oscillations, causing the arc to make hissing, humming or howling sounds[36] which had been noticed by Humphry Davy in 1821, Benjamin Silliman in 1822,[37] Auguste Arthur de la Rive in 1846,[38] and David Edward Hughes in 1878.[39] Ernst Lecher in 1888 showed that the current through an electric arc could be oscillatory.[40][41][42]
^ Scroggie, M. G.; Amos, S. W. (2013). Foundations of Wireless and Electronics. Elsevier. pp. 241–242. ISBN 978-1483105574.
Anders, André (2009). Cathodic Arcs: From Fractal Spots to Energetic Condensation. Springer Science and Business Media. pp. 31–32. ISBN 978-0387791081.
The sine wave at the end of the loop must be in phase with the wave at the beginning of the loop.[12]Since the sine wave is periodic and repeats every 2π radians, this means that the phase shift around the loop at the oscillation frequency ω0must be zero or a multiple of 2π radians (360°)
Abraham, H.; E. Bloch (1919). "Measurement of period of high frequency oscillations". Comptes Rendus. 168: 1105.
^ Van der Pol, Balthazar (1927). "On relaxation-oscillations". The London, Edinburgh and Dublin Philosophical Magazine. 2 (7): 978–992. doi:10.1080/14786442608564127.
A typical rule of thumb is to make the small signal loop gain at the oscillation frequency 2 or 3.[31][16]When the power is turned on, oscillation is started by the power turn-on transient or random electronic noise present in the circuit.[13]Noise guarantees that the circuit will not remain "balanced" precisely at its unstable DC equilibrium point (Q point) indefinitely. Due to the narrow passband of the filter, the response of the circuit to a noise pulse will be sinusoidal, it will excite a small sine wave of voltage in the loop. Since for small signals the loop gain is greater than one, the amplitude of the sine wave increases exponentially.[15][10]
^ Casperson, L. W (1991). "The humming telephone as an acoustic maser". Optical and Quantum Electronics. 23 (8): 995–1010. doi:10.1007/BF00611436. S2CID 119956732.
Silliman, Benjamin (1859). First Principles of Physics: Or Natural Philosophy, Designed for the Use of Schools and Colleges. H.C. Peck & T. Bliss. p. 629. Davy Silliman Hissing.
^ Froehlich, Fritz E.; Kent, Allen (1991). The Froehlich/Kent Encyclopedia of Telecommunications, Volume 3. CRC Press. p. 448. ISBN 0824729021.
Temperature changes, aging, and manufacturing tolerances will cause component values to "drift" away from their designed values.[18][19] Changes in frequency determining components such as the tank circuit in LC oscillators will cause the oscillation frequency to change, so for a constant frequency these components must have stable values. How stable the oscillator's frequency is to other changes in the circuit, such as changes in values of other components, gain of the amplifier, the load impedance, or the supply voltage, is mainly dependent on the Q factor ("quality factor") of the feedback filter.[18] Since the amplitude of the output is constant due to the nonlinearity of the amplifier (see Startup section below), changes in component values cause changes in the phase shift ϕ=∠Aβ(jω){\displaystyle \phi \;=\;\angle A\beta (j\omega )} of the feedback loop. Since oscillation can only occur at frequencies where the phase shift is a multiple of 360°, ϕ=360n∘{\displaystyle \phi \;=\;360n^{\circ }}, shifts in component values cause the oscillation frequency ω0{\displaystyle \omega _{0}} to change to bring the loop phase back to 360n°. The amount of frequency change Δω{\displaystyle \Delta \omega } caused by a given phase change Δϕ{\displaystyle \Delta \phi } depends on the slope of the loop phase curve at ω0{\displaystyle \omega _{0}}, which is determined by the Q{\displaystyle Q}[18][19][20][21]
^ a b c d Razavi, Behzad (2001). Design of Analog CMOS Integrated Circuits. The McGraw-Hill Companies. pp. 482–484. ISBN 7302108862.
Terman, Frederick E. (1943). Radio Engineer's Handbook (PDF). McGraw-Hill. p. 497.
^ Misra, Devendra (2004). Radio-Frequency and Microwave Communication Circuits: Analysis and Design. John Wiley. p. 494. ISBN 0471478733.
RC oscillators have the equivalent of a very low Q{\displaystyle Q}, so the phase changes very slowly with frequency, therefore a given phase change will cause a large change in the frequency. In contrast, LC oscillators have tank circuits with high Q{\displaystyle Q} (~102).This means the phase shift of the feedback network increases rapidly with frequency near the resonant frequency of the tank circuit.[18] So a large change in phase causes only a small change in frequency.Therefore the circuit's oscillation frequency is very close to the natural resonant frequency of the tuned circuit, and doesn't depend much on other components in the circuit.The quartz crystal resonators used in crystal oscillators have even higher Q{\displaystyle Q} (104 to 106)[21] and their frequency is very stable and independent of other circuit components.
Mathematical conditions for feedback oscillations, now called the Barkhausen criterion, were derived by Heinrich Georg Barkhausen in 1921.The first analysis of a nonlinear electronic oscillator model, the Van der Pol oscillator, was done by Balthasar van der Pol in 1927.[67] He showed that the stability of the oscillations (limit cycles) in actual oscillators was due to the nonlinearity of the amplifying device.He originated the term "relaxation oscillation" and was first to distinguish between linear and relaxation oscillators.Further advances in mathematical analysis of oscillation were made by Hendrik Wade Bode and Harry Nyquist[68] in the 1930s.In 1969 K. Kurokawa derived necessary and sufficient conditions for oscillation in negative-resistance circuits,[69] which form the basis of modern microwave oscillator design.[9]
"Sinusoidal Oscillators" (DOC). Course notes: ECE3434 Advanced Electronic Circuits. Electrical and Computer Engineering Dept., Mississippi State University. Summer 2015. Retrieved September 28, 2015., p. 4-7
^ a b c d e f g h i j
Maas, Stephen A. (2003). Nonlinear Microwave and RF Circuits, 2nd Ed. Artech House. pp. 542–544. ISBN 978-1580534840.
^ Kurokawa, K. (July 1969). "Some Basic Characteristics of Broadband Negative Resistance Oscillator Circuits" (PDF). Bell System Tech. J. 48 (6): 1937–1955. doi:10.1002/j.1538-7305.1969.tb01158.x. Retrieved December 8, 2012.Eq. 10 is a necessary condition for oscillation; eq. 12 is a sufficient condition,
Misra, Devendra (2004). Radio-Frequency and Microwave Communication Circuits: Analysis and Design. John Wiley. p. 494. ISBN 0471478733.
In addition to the feedback oscillators described above, which use two-port amplifying active elements such as transistors and operational amplifiers, linear oscillators can also be built using one-port (two terminal) devices with negative resistance,[2][4] such as magnetron tubes, tunnel diodes, IMPATT diodes and Gunn diodes.Negative-resistance oscillators are usually used at high frequencies in the microwave range and above, since at these frequencies feedback oscillators perform poorly due to excessive phase shift in the feedback path.
An oscillator was built by Elihu Thomson in 1892[43][44] by placing an LC tuned circuit in parallel with an electric arc and included a magnetic blowout. Independently, in the same year, George Francis FitzGerald realized that if the damping resistance in a resonant circuit could be made zero or negative, the circuit would produce oscillations, and, unsuccessfully, tried to build a negative resistance oscillator with a dynamo, what would now be called a parametric oscillator.[45][36] The arc oscillator was rediscovered and popularized by William Duddell in 1900.[46][47] Duddell, a student at London Technical College, was investigating the hissing arc effect.He attached an LC circuit (tuned circuit) to the electrodes of an arc lamp, and the negative resistance of the arc excited oscillation in the tuned circuit.[36] Some of the energy was radiated as sound waves by the arc, producing a musical tone. Duddell demonstrated his oscillator before the London Institute of Electrical Engineers by sequentially connecting different tuned circuits across the arc to play the national anthem "God Save the Queen".[36] Duddell's "singing arc" did not generate frequencies above the audio range. In 1902 Danish physicists Valdemar Poulsen and P. O. Pederson were able to increase the frequency produced into the radio range by operating the arc in a hydrogen atmosphere with a magnetic field, inventing the Poulsen arc radio transmitter, the first continuous wave radio transmitter, which was used through the 1920s.[48][49][50]
Maas, Stephen A. (2003). Nonlinear Microwave and RF Circuits. Artech House. pp. 537–540. ISBN 1580536115.
The Barkhausen criterion above, eqs. (1) and (2), merely gives the frequencies at which steady-state oscillation is possible, but says nothing about the amplitude of the oscillation, whether the amplitude is stable, or whether the circuit will start oscillating when the power is turned on.[29][13][30]For a practical oscillator two additional requirements are necessary:
Carr, Joe (2002). RF Components and Circuits. Newnes. pp. 125–126. ISBN 0080498078.
^ a b c d e f g h i j k l m n
Casperson, L. W (1991). "The humming telephone as an acoustic maser". Optical and Quantum Electronics. 23 (8): 995–1010. doi:10.1007/BF00611436. S2CID 119956732.
Feedback oscillator circuits can be classified according to the type of frequency selective filter they use in the feedback loop:[2][4]
∠A+∠β=2πnn∈0,1,2...(2){\displaystyle \angle A+\angle \beta =2\pi n\qquad n\in 0,1,2...\,\qquad \qquad {\text{(2)}}}
^ Hong, Sungook (2003). "A history of the regeneration circuit: From invention to patent litigation" (PDF). IEEE. Retrieved August 29, 2012., pp. 9–10
Hong, Sungook (2001). Wireless: From Marconi's Black-Box to the Audion. MIT Press. ISBN 978-0262082983., pp. 161–165
Equations (1) and (2) are called the Barkhausen stability criterion.[15][13]It is a necessary but not a sufficient criterion for oscillation, so there are somecircuits which satisfy these equations that will not oscillate.An equivalent condition often used instead of the Barkhausen condition is that the circuit's closed loop transfer function (the circuit's complex impedance at its output) have a pair of poles on the imaginary axis.
There are two main types of electronic oscillator – the linear or harmonic oscillator and the nonlinear or relaxation oscillator.[2][4]The most common linear oscillator today is the crystal oscillator, in which the frequency is controlled by a resonator consisting of a vibrating quartz crystal.It is ubiquitous in modern electronics, used to generate the clock signal in computers and digital watches and radio frequency signals in radio transmitters and receivers.
Van der Pol, Balthazar (1927). "On relaxation-oscillations". The London, Edinburgh and Dublin Philosophical Magazine. 2 (7): 978–992. doi:10.1080/14786442608564127.
"Notes". The Electrical Review. 62 (1578): 812. February 21, 1908. Retrieved April 12, 2017.
The negative-resistance oscillator model is not limited to one-port devices like diodes; feedback oscillator circuits with two-port amplifying devices such as transistors and tubes also have negative resistance.[6][7][8]At high frequencies, three terminal devices such as transistors and FETs are also used in negative resistance oscillators. At high frequencies these devices do not need a feedback loop, but with certain loads applied to one port can become unstable at the other port and show negative resistance due to internal feedback.The negative resistance port is connected to a tuned circuit or resonant cavity, causing them to oscillate.[6][7][9] High-frequency oscillators in general are designed using negative-resistance techniques.[6][7][8]
In applications where a 'pure' very low distortion sine wave is needed, such as precision signal generators,a nonlinear component is often used in the feedback loop that provides a 'slow' gain reduction with amplitude.This stabilizes the loop gain at an amplitude below the saturation level of the amplifier, so it does not saturate and "clip" the sine wave.Resistor-diode networks and FETs are often used for the nonlinear element.An older design uses a thermistor or an ordinary incandescent light bulb; both provide a resistance that increases with temperature as the current through them increases.
Chattopadhyay, D. (2006). Electronics (fundamentals And Applications). New Age International. pp. 224–225. ISBN 978-81-224-1780-7.
The Science of Radio: With Matlab and Electronics Workbench Demonstration, 2nd Ed
^ Silliman, Benjamin (1859). First Principles of Physics: Or Natural Philosophy, Designed for the Use of Schools and Colleges. H.C. Peck & T. Bliss. p. 629. Davy Silliman Hissing.
^ Razavi, Behzad (2001)Design of Analog CMOS Integrated Circuits, p. 487-489
^ Cady, W. G.; Arnold, H. D. (1907). "On the electric arc between metallic electrodes". American Journal of Science. 24 (143): 406. Retrieved April 12, 2017.
^ GB 190021629, Duddell, William du Bois, "Improvements in and connected with Means for the Conversion of Electrical Energy, Derived from a Source of Direct Current, into Varying or Alternating Currents", published 29 Nov 1900, issued 23 Nov 1901
^ a b Vidkjaer, Jens. "Ch. 6: Oscillators" (PDF). Class Notes: 31415 RF Communications Circuits. Technical Univ. of Denmark. Retrieved October 8, 2015. p. 8-9
The balance of forces (Newton's second law) for damped harmonic oscillators is then[1][2][3]
Compare this result with the theory section on resonance, as well as the "magnitude part" of the RLC circuit. This amplitude function is particularly important in the analysis and understanding of the frequency response of second-order systems.
A simple harmonic oscillator is an oscillator that is neither driven nor damped. It consists of a mass m, which experiences a single force F, which pulls the mass in the direction of the point x = 0 and depends only on the position x of the mass and a constant k. Balance of forces (Newton's second law) for the system is
This equation can be solved exactly for any driving force, using the solutions z(t) that satisfy the unforced equation
Underdamped (ζ < 1): The system oscillates (with a slightly different frequency than the undamped case) with the amplitude gradually decreasing to zero. The angular frequency of the underdamped harmonic oscillator is given by ω1=ω01−ζ2,{\textstyle \omega _{1}=\omega _{0}{\sqrt {1-\zeta ^{2}}},} the exponential decay of the underdamped harmonic oscillator is given by λ=ω0ζ.{\displaystyle \lambda =\omega _{0}\zeta .}
The value of the damping ratio ζ critically determines the behavior of the system. A damped harmonic oscillator can be:
Hayek, Sabih I. (15 Apr 2003). "Mechanical Vibration and Damping". Encyclopedia of Applied Physics. WILEY-VCH Verlag GmbH & Co KGaA. doi:10.1002/3527600434.eap231. ISBN 9783527600434.
Thus, given an arbitrary potential-energy function V(x){\displaystyle V(x)} with a non-vanishing second derivative, one can use the solution to the simple harmonic oscillator to provide an approximate solution for small perturbations around the equilibrium point.
If the initial displacement is A, and there is no initial velocity, the solution of this equation is given by
Driven harmonic oscillators are damped oscillators further affected by an externally applied force F(t).
Because V(x0){\displaystyle V(x_{0})} is a minimum, the first derivative evaluated at x0{\displaystyle x_{0}} must be zero, so the linear term drops out:
Analytical mechanics Lagrangian mechanicsHamiltonian mechanicsRouthian mechanicsHamilton–Jacobi equationAppell's equation of motionKoopman–von Neumann mechanics
This page was last edited on 31 December 2022, at 21:44 (UTC).
ζ=c2mk{\textstyle \zeta ={\frac {c}{2{\sqrt {mk}}}}} is called the "damping ratio".
Q is related to the damping ratio by Q=12ζ.{\textstyle Q={\frac {1}{2\zeta }}.}
Critically damped (ζ = 1):The system returns to steady state as quickly as possible without oscillating (although overshoot can occur if the initial velocity is nonzero).This is often desired for the damping of systems such as doors.
The problem of the simple harmonic oscillator occurs frequently in physics, because a mass at equilibrium under the influence of any conservative force, in the limit of small motions, behaves as a simple harmonic oscillator.
The steady-state solution is proportional to the driving force with an induced phase change φ{\displaystyle \varphi }:
Tipler, Paul (1998). Physics for Scientists and Engineers: Vol. 1 (4th ed.). W. H. Freeman. ISBN 1-57259-492-6.
ω0=km{\textstyle \omega _{0}={\sqrt {\frac {k}{m}}}} is called the "undamped angular frequency of the oscillator",
Apply the "complex variables method" by solving the auxiliary equation below and then finding the real part of its solution:
Wylie, C. R. (1975). Advanced Engineering Mathematics (4th ed.). McGraw-Hill. ISBN 0-07-072180-7.
.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Case, William. "Two ways of driving a child's swing". Archived from the original on 9 December 2011. Retrieved 27 November 2011.
The potential energy stored in a simple harmonic oscillator at position x is
Mechanical examples include pendulums (with small angles of displacement), masses connected to springs, and acoustical systems. Other analogous systems include electrical harmonic oscillators such as RLC circuits.The harmonic oscillator model is very important in physics, because any mass subject to a force in stable equilibrium acts as a harmonic oscillator for small vibrations.Harmonic oscillators occur widely in nature and are exploited in many manmade devices, such as clocks and radio circuits.They are the source of virtually all sinusoidal vibrations and waves.
Parametric oscillators have been developed as low-noise amplifiers, especially in the radio and microwave frequency range.Thermal noise is minimal, since a reactance (not a resistance) is varied.Another common use is frequency conversion, e.g., conversion from audio to radio frequencies.For example, the Optical parametric oscillator converts an input laser wave into two output waves of lower frequency (ωs,ωi{\displaystyle \omega _{s},\omega _{i}}).
Iθ¨+Γθ˙+μθ=τ{\displaystyle I{\ddot {\theta }}+\Gamma {\dot {\theta }}+\mu \theta =\tau }
Roura, P.; Gonzalez, J.A. (2010). "Towards a more realistic description of swing pumping due to the exchange of angular momentum". European Journal of Physics. 31 (5): 1195–1207. Bibcode:2010EJPh...31.1195R. doi:10.1088/0143-0807/31/5/020. S2CID 122086250.
^ Roura, P.; Gonzalez, J.A. (2010). "Towards a more realistic description of swing pumping due to the exchange of angular momentum". European Journal of Physics. 31 (5): 1195–1207. Bibcode:2010EJPh...31.1195R. doi:10.1088/0143-0807/31/5/020. S2CID 122086250.
Overdamped (ζ > 1): The system returns (exponentially decays) to steady state without oscillating.Larger values of the damping ratio ζ return to equilibrium more slowly.
In the case ζ < 1 and a unit step input with x(0) = 0:
The general solution is a sum of a transient solution that depends on initial conditions, and a steady state that is independent of initial conditions and depends only on the driving amplitude F0{\displaystyle F_{0}}, driving frequency ω{\displaystyle \omega }, undamped angular frequency ω0{\displaystyle \omega _{0}}, and the damping ratio ζ{\displaystyle \zeta }.
In terms of energy, all systems have two types of energy: potential energy and kinetic energy. When a spring is stretched or compressed, it stores elastic potential energy, which is then transferred into kinetic energy. The potential energy within a spring is determined by the equation U=12kx2.{\textstyle U={\frac {1}{2}}kx^{2}.}
^ Case, W. B. (1996). "The pumping of a swing from the standing position". American Journal of Physics. 64 (3): 215–220. Bibcode:1996AmJPh..64..215C. doi:10.1119/1.18209.
Dividing by the exponential term on the left results in
Solving this differential equation, we find that the motion is described by the function
is the phase of the oscillation relative to the driving force. The phase value is usually taken to be between −180° and 0 (that is, it represents a phase lag, for both positive and negative values of the arctan argument).
^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Case, William. "Two ways of driving a child's swing". Archived from the original on 9 December 2011. Retrieved 27 November 2011.
Combining the amplitude and phase portions results in the steady-state solution
For a particular driving frequency called the resonance, or resonant frequency ωr=ω01−2ζ2{\textstyle \omega _{r}=\omega _{0}{\sqrt {1-2\zeta ^{2}}}}, the amplitude (for a given F0{\displaystyle F_{0}}) is maximal. This resonance effect only occurs when ζ<1/2{\displaystyle \zeta <1/{\sqrt {2}}}, i.e. for significantly underdamped systems. For strongly underdamped systems the value of the amplitude can become quite large near the resonant frequency.
In classical mechanics, a harmonic oscillator is a system that, when displaced from its equilibrium position, experiences a restoring force F proportional to the displacement x:
The boundary solution between an underdamped oscillator and an overdamped oscillator occurs at a particular value of the friction coefficient and is called critically damped.
Harmonic oscillators occurring in a number of areas of engineering are equivalent in the sense that their mathematical models are identical (see universal oscillator equation above).Below is a table showing analogous quantities in four harmonic oscillator systems in mechanics and electronics.If analogous parameters on the same line in the table are given numerically equal values, the behavior of the oscillators – their output waveform, resonant frequency, damping factor, etc. – are the same.
The solution of original universal oscillator equation is a superposition (sum) of the transient and steady-state solutions:
The Q factor of a damped oscillator is defined as
By using either force balance or an energy method, it can be readily shown that the motion of this system is given by the following differential equation:
In electrical engineering, a multiple of τ is called the settling time, i.e. the time necessary to ensure the signal is within a fixed departure from final value, typically within 10%. The term overshoot refers to the extent the response maximum exceeds final value, and undershoot refers to the extent the response falls below final value for times following the response maximum.
In real oscillators, friction, or damping, slows the motion of the system. Due to frictional force, the velocity decreases in proportion to the acting frictional force. While in a simple undriven harmonic oscillator the only force acting on the mass is the restoring force, in a damped harmonic oscillator there is in addition a frictional force which is always in a direction to oppose the motion. In many vibrating systems the frictional force Ff can be modeled as being proportional to the velocity v of the object: Ff = −cv, where c is called the viscous damping coefficient.
Given an ideal massless spring, m{\displaystyle m} is the mass on the end of the spring. If the spring itself has mass, its effective mass must be included in m{\displaystyle m}.
Parametric resonance occurs in a mechanical system when a system is parametrically excited and oscillates at one of its resonant frequencies. Parametric excitation differs from forcing, since the action appears as a time varying modification on a system parameter. This effect is different from regular resonance because it exhibits the instability phenomenon.
5Universal oscillator equation											Toggle Universal oscillator equation subsection																					5.1Transient solution																											5.2Steady-state solution																								5.2.1Amplitude part																											5.2.2Phase part																														5.3Full solution
A conservative force is one that is associated with a potential energy.The potential-energy function of a harmonic oscillator is
Given an arbitrary potential-energy function V(x){\displaystyle V(x)}, one can do a Taylor expansion in terms of x{\displaystyle x} around an energy minimum (x=x0{\displaystyle x=x_{0}}) to model the behavior of small perturbations from equilibrium.
The constant term V(x0) is arbitrary and thus may be dropped, and a coordinate transformation allows the form of the simple harmonic oscillator to be retrieved:
Case, W. B. (1996). "The pumping of a swing from the standing position". American Journal of Physics. 64 (3): 215–220. Bibcode:1996AmJPh..64..215C. doi:10.1119/1.18209.
This phase function is particularly important in the analysis and understanding of the frequency response of second-order systems.
Serway, Raymond A.; Jewett, John W. (2003). Physics for Scientists and Engineers. Brooks/Cole. ISBN 0-534-40842-7.
Kreyszig, Erwin (1972), Advanced Engineering Mathematics (3rd ed.), New York: Wiley, ISBN 0-471-50728-8
A parametric oscillator is a driven harmonic oscillator in which the drive energy is provided by varying the parameters of the oscillator, such as the damping or restoring force.A familiar example of parametric oscillation is "pumping" on a playground swing.[4][5][6]A person on a moving swing can increase the amplitude of the swing's oscillations without any external drive force (pushes) being applied, by changing the moment of inertia of the swing by rocking back and forth ("pumping") or alternately standing and squatting, in rhythm with the swing's oscillations.The varying of the parameters drives the system.Examples of parameters that may be varied are its resonance frequency ω{\displaystyle \omega } and damping β{\displaystyle \beta }.
3Driven harmonic oscillators											Toggle Driven harmonic oscillators subsection																					3.1Step input																											3.2Sinusoidal driving force
The motion is periodic, repeating itself in a sinusoidal fashion with constant amplitude A. In addition to its amplitude, the motion of a simple harmonic oscillator is characterized by its period T=2π/ω{\displaystyle T=2\pi /\omega }, the time for a single oscillation or its frequency f=1/T{\displaystyle f=1/T}, the number of cycles per unit time. The position at a given time t also depends on the phase φ, which determines the starting point on the sine wave. The period and frequency are determined by the size of the mass m and the force constant k, while the amplitude and phase are determined by the starting position and velocity.
The time an oscillator needs to adapt to changed external conditions is of the order τ = 1/(ζω0). In physics, the adaptation is called relaxation, and τ is called the relaxation time.
If F is the only force acting on the system, the system is called a simple harmonic oscillator, and it undergoes simple harmonic motion: sinusoidal oscillations about the equilibrium point, with a constant amplitude and a constant frequency (which does not depend on the amplitude).
The solution to this differential equation contains two parts: the "transient" and the "steady-state".
If the maximal displacement of the pendulum is small, we can use the approximation sin⁡θ≈θ{\displaystyle \sin \theta \approx \theta } and instead consider the equation
The transient solutions are the same as the unforced (F0=0{\displaystyle F_{0}=0}) damped harmonic oscillator and represent the systems response to other events that occurred previously.The transient solutions typically die out rapidly enough that they can be ignored.
Oscillate with a frequency lower than in the undamped case, and an amplitude decreasing with time (underdamped oscillator).
8Examples											Toggle Examples subsection																					8.1Simple pendulum																											8.2Spring/mass system																								8.2.1Energy variation in the spring–damping system
If an external time-dependent force is present, the harmonic oscillator is described as a driven oscillator.
Parametric oscillators are used in many applications.The classical varactor parametric oscillator oscillates when the diode's capacitance is varied periodically.The circuit that varies the diode's capacitance is called the "pump" or "driver". In microwave electronics, waveguide/YAG based parametric oscillators operate in the same fashion. The designer varies a parameter periodically to induce oscillations.
Equating the real and imaginary parts results in two independent equations
If the forcing function is f(t) = cos(ωt) = cos(ωtcτ) = cos(ωτ), where ω = ωtc, the equation becomes
When a spring is stretched or compressed by a mass, the spring develops a restoring force. Hooke's law gives the relationship of the force exerted by the spring when the spring is compressed or stretched a certain length:
If a frictional force (damping) proportional to the velocity is also present, the harmonic oscillator is described as a damped oscillator. Depending on the friction coefficient, the system can:
Fowles, Grant R.; Cassiday, George L. (1986), Analytic Mechanics (5th ed.), Fort Worth: Saunders College Publishing, ISBN 0-03-089725-4, LCCN 93085193
Assuming no damping, the differential equation governing a simple pendulum of length l{\displaystyle l}, where g{\displaystyle g} is the local acceleration of gravity, is
When the spring is stretched or compressed, kinetic energy of the mass gets converted into potential energy of the spring. By conservation of energy, assuming the datum is defined at the equilibrium position, when the spring reaches its maximal potential energy, the kinetic energy of the mass is zero. When the spring is released, it tries to return to equilibrium, and all its potential energy converts to kinetic energy of the mass.
The solution based on solving the ordinary differential equation is for arbitrary constants c1 and c2
Chaudhuri, Ovijit; Cooper-White, Justin; Janmey, Paul A.; Mooney, David J.; Shenoy, Vivek B. (27 August 2020). "Effects of extracellular matrix viscoelasticity on cellular behaviour". Nature. 584 (7822): 535–546. Bibcode:2020Natur.584..535C. doi:10.1038/s41586-020-2612-2. PMC 7676152. PMID 32848221.
Since relaxation relieves the state of stress, it has the effect of also relieving the equipment reactions. Thus, relaxation has thesame effect as cold springing, except it occurs over a longer period of time.The amount of relaxation which takes place is a function of time, temperature and stress level, thus the actual effect it has on the system is not precisely known, but can be bounded.
Vegener et al. use a power series to describe stress relaxation in polyamides:[3]
^ a b c d T.M. Junisbekov. "Stress Relaxation in Viscoelastic Materials" (2003) ISBN 1-57808-258-7
To model stress relaxation in glass materials Dowvalter uses the following:[3]
^ Meyers and Chawla. "Mechanical Behavior of Materials" (1999) .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}ISBN 0-13-262817-1
T.M. Junisbekov. "Stress Relaxation in Viscoelastic Materials" (2003) ISBN 1-57808-258-7
The extracellular matrix and most tissues are stress relaxing, and the kinetics of stress relaxation have been recognized as an important mechanical cue that affects the migration, proliferation, and differentiation of embedded cells.[2]
Viscoelastic materials have the properties of both viscous and elastic materials and can be modeled by combining elements that represent these characteristics. One viscoelastic model, called the Maxwell model predicts behavior akin to a spring (elastic element) being in series with a dashpot (viscous element), while the Voigt model places these elements in parallel. Although the Maxwell model is good at predicting stress relaxation, it is fairly poor at predicting creep. On the other hand, the Voigt model is good at predicting creep but rather poor at predicting stress relaxation (see viscoelasticity).
In materials science, stress relaxation is the observed decrease in stress in response to strain generated in the structure. This is primarily due to keeping the structure in a strained condition for some finite interval of time hence causing some amount of plastic strain. This should not be confused with creep, which is a constant state of stress with an increasing amount of strain.
Stress relaxation describes how polymers relieve stress under constant strain. Because they are viscoelastic, polymers behave in a nonlinear, non-Hookean fashion.[1] This nonlinearity is described by both stress relaxation and a phenomenon known ascreep, which describes how polymers strain under constant stress. Experimentally, stress relaxation is determined by step strain experiments, i.e. by applying a sudden one-time strain and measuring the build-up and subsequent relaxation of stress in the material (see figure), in either extensional or shear rheology.
where σ0{\displaystyle \sigma _{0}} is the maximum stress at the time the loading was removed (t*), and n is a material parameter.
Meyers and Chawla. "Mechanical Behavior of Materials" (1999) .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}ISBN 0-13-262817-1
σ(t)=1b⋅log⁡10α(t−tn)+110α(t−tn)−1{\displaystyle \sigma (t)={\frac {1}{b}}\cdot \log {\frac {10^{\alpha }(t-t_{n})+1}{10^{\alpha }(t-t_{n})-1}}}where α{\displaystyle \alpha } is a material constant and b and tn{\displaystyle t_{n}} depend on processing conditions.
This page was last edited on 14 December 2022, at 17:29 (UTC).
The following non-material parameters all affect stress relaxation in polymers:[3]
^ Chaudhuri, Ovijit; Cooper-White, Justin; Janmey, Paul A.; Mooney, David J.; Shenoy, Vivek B. (27 August 2020). "Effects of extracellular matrix viscoelasticity on cellular behaviour". Nature. 584 (7822): 535–546. Bibcode:2020Natur.584..535C. doi:10.1038/s41586-020-2612-2. PMC 7676152. PMID 32848221.
